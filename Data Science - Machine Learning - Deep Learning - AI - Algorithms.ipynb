{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science - Machine Learning - Deep Learning - AI - Algorithms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myrondza/Data-Science-Machine-Learning-Deep-Learning-AI-Guide-Algorithms/blob/master/Data%20Science%20-%20Machine%20Learning%20-%20Deep%20Learning%20-%20AI%20-%20Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lQrxvcnUOa9m"
      },
      "source": [
        "# Data Science Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CQV8OcdrOa9t"
      },
      "source": [
        "#  (Data Mining) - Data Source Connections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HLEA7Dd4Oa9x"
      },
      "source": [
        "### Microsoft SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R6J4aiRCOa94",
        "colab": {}
      },
      "source": [
        "import pymssql\n",
        "\n",
        "server = getenv(\"xxx.xxx.xx.xx\")\n",
        "user = getenv(\"username\")\n",
        "password = getenv(\"password\")\n",
        "\n",
        "conn = pymssql.connect(server, user, password, \"tempdb\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "                        IF OBJECT_ID('persons', 'U') IS NOT NULL\n",
        "                            DROP TABLE persons\n",
        "                        CREATE TABLE persons (\n",
        "                            id INT NOT NULL,\n",
        "                            name VARCHAR(100),\n",
        "                            salesrep VARCHAR(100),\n",
        "                            PRIMARY KEY(id)\n",
        "                        )\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "cursor.executemany(\n",
        "    \"INSERT INTO persons VALUES (%d, %s, %s)\",\n",
        "    [(1, 'John Smith', 'John Doe'),\n",
        "     (2, 'Jane Doe', 'Joe Dog'),\n",
        "     (3, 'Mike T.', 'Sarah H.')])\n",
        "\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "cursor.execute('SELECT * FROM persons')\n",
        "row = cursor.fetchone()\n",
        "while row:\n",
        "    print(\"ID=%d, Name=%s\" % (row[0], row[1]))\n",
        "    row = cursor.fetchone()\n",
        "\n",
        "conn.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFPr1LHIOa-G"
      },
      "source": [
        "#### TM1 Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k2ADwiUXOa-J",
        "colab": {}
      },
      "source": [
        "from TM1py import TM1Service\n",
        "ADDRESS = 'xxx.xxx.xx.xx'\n",
        "PORT = 12354\n",
        "USER = 'admin'\n",
        "PASSWORD = 'apple'\n",
        "SSL = False\n",
        "DECODE_B64 = False\n",
        "\n",
        "CUBE = \"\"\n",
        "VIEW = \"\"\n",
        "\n",
        "with TM1Service(address=ADDRESS, port=PORT, user=USER, password=PASSWORD, ssl=SSL, decode_b64=DECODE_B64) as tm1:\n",
        "    df = tm1.cubes.cells.execute_view_dataframe_pivot(\n",
        "        cube_name=CUBE,\n",
        "        view_name=VIEW)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxrvaJIM8AdG",
        "colab_type": "text"
      },
      "source": [
        "# (Data Cleaning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H3ZCRHGVOa-T"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-AYOWoH4Oa-W",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "silkVljCOa-e"
      },
      "source": [
        "## Pandas Data Frame "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X7lNb6B_WdwZ"
      },
      "source": [
        "Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NWScnE-nOa-h",
        "outputId": "84547785-1653-4d4a-b856-298644a7233c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "df = pd.read_csv(r'kc_house_data.csv', error_bad_lines=False)\n",
        "df.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id             date     price  ...     long  sqft_living15  sqft_lot15\n",
              "0  7129300520  20141013T000000  221900.0  ... -122.257           1340        5650\n",
              "\n",
              "[1 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yjAb9_C8Oa-r",
        "colab": {}
      },
      "source": [
        "X = df[[\"bedrooms\",\"sqft_living\",\"floors\",\"bathrooms\"]]\n",
        "y = df[\"price\"]\n",
        "#y = df[\"waterfront\"]\n",
        "#y = df[\"grade\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GjUkiZooOa-v",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NDJM6lK9Oa-z",
        "outputId": "a0cb5f9b-deaa-43ef-f795-407deb375e81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14480, 4)\n",
            "(14480,)\n",
            "(7133, 4)\n",
            "(7133,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAkplSGO8LFA",
        "colab_type": "text"
      },
      "source": [
        "# (Data Exploration)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0V1Wt7X1tCB",
        "colab_type": "text"
      },
      "source": [
        "#  (Predictive Modeling) - Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O1u0Pwh-Oa-5"
      },
      "source": [
        "## Supervised Algorithms (Machine Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FWM05R5YY25L"
      },
      "source": [
        "Given a set of data points {x(1),...,x(m)} associated to a set of outcomes {y(1),...,y(m)}, we want to build a classifier that learns how to predict y from x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IkgQSSZ-Oa-6"
      },
      "source": [
        "### Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8dPl6VBDOa-7"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "39jMs34jX28D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LTzhHkocOa-8",
        "outputId": "f2fa23ba-8923-4665-a4a8-7fb960e305af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import max_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "linreg = LinearRegression(\n",
        "    fit_intercept=True,\n",
        "    normalize=False,\n",
        "    copy_X=True,\n",
        "    n_jobs=None,\n",
        ")\n",
        "\n",
        "linreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linreg.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.5025801802472102\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.5025801802472102\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4190853.1986948266\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 174286.3120128403\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 74492754485.58958\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.15824984512419465\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 126220.20859889686\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.5024906747145044\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LcjrqtXYOa_C"
      },
      "source": [
        "#### Linear Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ywJosghMOa_D",
        "outputId": "17772a55-0fdb-47c0-a211-526c651c6733",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "\n",
        "linrid = linear_model.Ridge(\n",
        "    alpha=1.0,\n",
        "    fit_intercept=True,\n",
        "    normalize=False,\n",
        "    copy_X=True,\n",
        "    max_iter=None,\n",
        "    tol=0.001,\n",
        "    solver='auto',\n",
        "    random_state=None,\n",
        ")\n",
        "linrid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linrid.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.5025798594802962\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.5025798594802962\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4190861.3067016643\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 174286.19780452107\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 74492802611.21846\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.158249164482852\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 126217.24480640539\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.5024903533013774\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yQ6q-y6LOa_I"
      },
      "source": [
        "#### Linear Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e9fyR7pmOa_M",
        "outputId": "85035da5-d534-4075-b696-c5eac10f2e96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "\n",
        "linlass = linear_model.Lasso(\n",
        "    alpha=1.0,\n",
        "    fit_intercept=True,\n",
        "    normalize=False,\n",
        "    precompute=False,\n",
        "    copy_X=True,\n",
        "    max_iter=1000,\n",
        "    tol=0.0001,\n",
        "    warm_start=False,\n",
        "    positive=False,\n",
        "    random_state=None,\n",
        "    selection='cyclic',\n",
        ")\n",
        "\n",
        "linlass.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linlass.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.5025802829016262\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.5025802829016262\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4190849.4994220138\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 174286.1065858295\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 74492739745.50328\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.15824910236510256\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 126215.81307340605\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.5024907731580435\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e6YU3V5dOa_R"
      },
      "source": [
        "#### Support Vector Machines Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sNm7VQUFOa_S",
        "outputId": "6d87f80a-ab51-451d-d8d0-1fc07630fc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "svr = svm.SVR(\n",
        "    kernel='rbf',\n",
        "    degree=3,\n",
        "    gamma='auto_deprecated',\n",
        "    coef0=0.0,\n",
        "    tol=0.001,\n",
        "    C=1.0,\n",
        "    epsilon=0.1,\n",
        "    shrinking=True,\n",
        "    cache_size=200,\n",
        "    verbose=False,\n",
        "    max_iter=-1,\n",
        ")\n",
        "\n",
        "svr.fit(X_train, y_train)  \n",
        "\n",
        "y_pred = svr.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 2.9634962457336655e-05\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 2.9634962457336655e-05\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 6612478.372652433\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 227198.9448046691\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 158702470236.78464\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.2852188207333007\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 150510.01114453678\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : -0.05991461094270578\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JH76wHE8Oa_Y"
      },
      "source": [
        "#### Transformed Target Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AkZrZkPTOa_Z",
        "outputId": "e1432c13-1732-45bc-f309-be6f1eeeae1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "\n",
        "def func(x):\n",
        "    return np.log(x)\n",
        "def inverse_func(x):\n",
        "    return np.exp(x)\n",
        "\n",
        "regr = TransformedTargetRegressor( transformer = QuantileTransformer(output_distribution='normal'),\n",
        "                                   regressor=linreg,\n",
        "                                   #func=func,\n",
        "                                   #inverse_func=inverse_func\n",
        "                                 )\n",
        "# Either use transformer or function & inverese function\n",
        "\n",
        "regr.fit(X_train, y_train) \n",
        "\n",
        "y_pred = regr.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.11963992266389734\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.11963992266389734\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 6755529.695166179\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 178196.28431840078\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 132857992866.61635\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.1475434631407419\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 113654.11784739455\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.11269101476651688\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_PYLzFUdOa_e"
      },
      "source": [
        "#### Bayesian Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0HO7qTUROa_f",
        "outputId": "680d2e09-c7a3-47fd-c83e-a7a3883cb5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "\n",
        "linbayes = linear_model.BayesianRidge(\n",
        "    n_iter=300,\n",
        "    tol=0.001,\n",
        "    alpha_1=1e-06,\n",
        "    alpha_2=1e-06,\n",
        "    lambda_1=1e-06,\n",
        "    lambda_2=1e-06,\n",
        "    compute_score=False,\n",
        "    fit_intercept=True,\n",
        "    normalize=False,\n",
        "    copy_X=True,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "linbayes.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linbayes.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.5025528854309511\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.5025528854309511\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4191516.4445031728\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 174277.88125644284\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 74496848244.177\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.15819791385822218\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 126295.90384339419\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.5024633340276581\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z1AuptacOa_k"
      },
      "source": [
        "#### Huber Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sSH7RSVROa_l",
        "outputId": "173ec667-9862-4e1b-e9ce-e220c64e6e68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "\n",
        "linhub = linear_model.HuberRegressor(\n",
        "    epsilon=1.35,\n",
        "    max_iter=100,\n",
        "    alpha=0.0001,\n",
        "    warm_start=False,\n",
        "    fit_intercept=True,\n",
        "    tol=1e-05,\n",
        ")\n",
        "\n",
        "linhub.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linhub.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.4740211311371182\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.4740211311371182\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4734852.297902894\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 169708.0772657343\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 80388824246.9135\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.15027959150311426\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 118697.82961323732\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.4631130237060438\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6BqpLbETOa_p"
      },
      "source": [
        "#### RANdom SAmple Consensus Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QmG2UElVOa_q",
        "outputId": "6637794b-695f-430d-a035-02df1d4adec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from numpy import inf\n",
        "\n",
        "linran = linear_model.RANSACRegressor(\n",
        "    base_estimator=None,\n",
        "    min_samples=None,\n",
        "    residual_threshold=None,\n",
        "    is_data_valid=None,\n",
        "    is_model_valid=None,\n",
        "    max_trials=100,\n",
        "    max_skips=inf,\n",
        "    stop_n_inliers=inf,\n",
        "    stop_score=inf,\n",
        "    stop_probability=0.99,\n",
        "    loss='absolute_loss',\n",
        "    random_state=None,\n",
        ")\n",
        "\n",
        "linran.fit(X_train, y_train)\n",
        "\n",
        "y_pred = linran.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.37520435402368024\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.37520435402368024\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 5235219.298239896\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 193614.88621373053\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 113351261622.01985\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.2053681191889484\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 123273.95127144211\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.2429691977527838\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xrfNIhh5Oa_s"
      },
      "source": [
        "#### Decision Tree Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YY7Uge2ROa_t",
        "outputId": "fbd76d66-d76e-4ccc-f809-f89269d5b369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn import metrics\n",
        "\n",
        "dtree = DecisionTreeRegressor(\n",
        "    criterion='mse',\n",
        "    splitter='best',\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    min_weight_fraction_leaf=0.0,\n",
        "    max_features=None,\n",
        "    random_state=None,\n",
        "    max_leaf_nodes=None,\n",
        "    min_impurity_decrease=0.0,\n",
        "    min_impurity_split=None,\n",
        "    presort=False,\n",
        ")\n",
        "\n",
        "dtree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dtree.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.2392491572348504\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.2392491572348504\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 5420000.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 202820.2999407902\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 113909852129.01071\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.21368509200142008\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 128500.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.239238580081804\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w7ZoQNXHOa_x"
      },
      "source": [
        "#### Random Forest Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NugxquXVOa_z",
        "outputId": "d6a27e40-55a2-4a3f-f08b-376959b82d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "rfr = RandomForestRegressor(\n",
        "    n_estimators='warn',\n",
        "    criterion='mse',\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    min_weight_fraction_leaf=0.0,\n",
        "    max_features='auto',\n",
        "    max_leaf_nodes=None,\n",
        "    min_impurity_decrease=0.0,\n",
        "    min_impurity_split=None,\n",
        "    bootstrap=True,\n",
        "    oob_score=False,\n",
        "    n_jobs=None,\n",
        "    random_state=None,\n",
        "    verbose=0,\n",
        "    warm_start=False,\n",
        ")\n",
        "\n",
        "rfr.fit(X_train,y_train)\n",
        "\n",
        "y_pred = rfr.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.4516637920799279\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.4516637920799279\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4377000.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 181604.04387443163\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 82110170862.77086\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.1710767777571059\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 122402.48543123546\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.45161679163150925\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fS82NDIgOa_3"
      },
      "source": [
        "#### XGBoost Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "49b0QmYWOa_5",
        "outputId": "83fe7364-b9a3-4e52-9ea1-1d187898201e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=100,\n",
        "    silent=True,\n",
        "    objective='reg:linear',\n",
        "    booster='gbtree',\n",
        "    n_jobs=1,\n",
        "    nthread=None,\n",
        "    gamma=0,\n",
        "    min_child_weight=1,\n",
        "    max_delta_step=0,\n",
        "    subsample=1,\n",
        "    colsample_bytree=1,\n",
        "    colsample_bylevel=1,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=1,\n",
        "    scale_pos_weight=1,\n",
        "    base_score=0.5,\n",
        "    random_state=0,\n",
        "    seed=None,\n",
        "    missing=None,\n",
        "    importance_type='gain',\n",
        ")\n",
        "\n",
        "xgb.fit(X_train,y_train)\n",
        "\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.5373906994756107\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.5373906994756107\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4975684.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 165979.19164446936\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 69268602953.5168\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.14214645627777067\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 117154.5625\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.5373808344603559\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nwo7WVpgOa_-"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XaRL7cKcOa_-",
        "outputId": "fda0add0-d4df-48bb-91fb-9ff6fe464a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 25911
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "logreg = LogisticRegression(\n",
        "    penalty='l2',\n",
        "    dual=False,\n",
        "    tol=0.0001,\n",
        "    C=1.0,\n",
        "    fit_intercept=True,\n",
        "    intercept_scaling=1,\n",
        "    class_weight=None,\n",
        "    random_state=None,\n",
        "    solver='lbfgs',\n",
        "    max_iter=100,\n",
        "    multi_class='warn',\n",
        "    verbose=0,\n",
        "    warm_start=False,\n",
        "    n_jobs=None,\n",
        "    l1_ratio=None,\n",
        ")\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.32885442606741144\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.32885442606741144\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4420000.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 189388.72872564138\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 109475929934.12645\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.18338691437342883\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 123260.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.26885109279902364\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2vkVs-49ObAA"
      },
      "source": [
        "#### Multi-layer perceptron (MLP) Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jiq6oJ0fObAB",
        "outputId": "4a0374b7-8eb3-47b4-fc50-aad949dcd453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "mlpreg = MLPRegressor(\n",
        "    hidden_layer_sizes=(100,),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0001,\n",
        "    batch_size='auto',\n",
        "    learning_rate='constant',\n",
        "    learning_rate_init=0.001,\n",
        "    power_t=0.5,\n",
        "    max_iter=200,\n",
        "    shuffle=True,\n",
        "    random_state=None,\n",
        "    tol=0.0001,\n",
        "    verbose=False,\n",
        "    warm_start=False,\n",
        "    momentum=0.9,\n",
        "    nesterovs_momentum=True,\n",
        "    early_stopping=False,\n",
        "    validation_fraction=0.1,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-08,\n",
        "    n_iter_no_change=10,\n",
        ")\n",
        "\n",
        "mlpreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = mlpreg.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.4841194901326197\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.4841194901326197\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4440412.303482478\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 176192.58390430172\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 77246107344.6375\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.1611054350114478\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 128327.15221276396\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.48410205782636384\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dzKzBzpkObAE"
      },
      "source": [
        "#### Star Boost Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tIlTkIw3ObAF",
        "outputId": "3bb9878b-e64c-4472-b055-e01f5710385b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "!pip install starboost\n",
        "from sklearn import datasets\n",
        "from sklearn import tree\n",
        "import starboost as sb\n",
        "\n",
        "\n",
        "strboost = sb.BoostingRegressor(\n",
        "    loss=None,\n",
        "    base_estimator=tree.DecisionTreeRegressor(max_depth=3),\n",
        "    tree_flavor=False,\n",
        "    n_estimators=30,\n",
        "    init_estimator=None,\n",
        "    line_searcher=None,\n",
        "    learning_rate=0.1,\n",
        "    row_sampling=1.0,\n",
        "    col_sampling=1.0,\n",
        "    eval_metric=None,\n",
        "    early_stopping_rounds=None,\n",
        "    random_state=None,\n",
        ")\n",
        "\n",
        "strboost.fit(X_train, y_train)\n",
        "\n",
        "y_pred = strboost.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting starboost\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/4d/3f696e4ff21a029b677e0ae3104f3385973679d17e3cef234e775da00617/starboost-0.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from starboost) (0.21.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from starboost) (1.16.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from starboost) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.0->starboost) (0.13.2)\n",
            "Installing collected packages: starboost\n",
            "Successfully installed starboost-0.0.2\n",
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score : 0.5225639625191154\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Explained Variance Score Uniform Average : 0.5225639625191154\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Maximum Error (ME) : 4422148.5\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error (MAE) : 169562.46440400253\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Error (MSE) : 71492156643.59364\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Mean Squared Log Error (MSLE) : 0.15011786565761953\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Median Absolute Error (MedAE) : 125470.375\n",
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score (R2) : 0.522530548634233\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJWsd4hsObAJ"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YlyWMEMeObAK"
      },
      "source": [
        "#### Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cus2mDy9ObAL",
        "outputId": "34b87204-e793-4cbd-d993-d01a3bf4698b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import brier_score_loss\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import hinge_loss\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import zero_one_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dtree = DecisionTreeClassifier(\n",
        "    criterion='gini',\n",
        "    splitter='best',\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    min_weight_fraction_leaf=0.0,\n",
        "    max_features=None,\n",
        "    random_state=None,\n",
        "    max_leaf_nodes=None,\n",
        "    min_impurity_decrease=0.0,\n",
        "    min_impurity_split=None,\n",
        "    class_weight=None,\n",
        "    presort=False,\n",
        ")\n",
        "\n",
        "dtree.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dtree.predict(X_test)\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.985279685966634\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.011387798495256788\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.5206270627062706\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.014720314033366046\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      7070\n",
            "           1       0.06      0.05      0.05        63\n",
            "\n",
            "    accuracy                           0.99      7133\n",
            "   macro avg       0.53      0.52      0.52      7133\n",
            "weighted avg       0.98      0.99      0.98      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.04677268475210472\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[7025   45]\n",
            " [  60    3]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.05405405405405405\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.014720314033366046\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.0058881256133465\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.027777777777777776\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.5084266792864135\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.047212480683821056\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[   3   60]\n",
            "  [  45 7025]]\n",
            "\n",
            " [[7025   45]\n",
            "  [  60    3]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 0.0625    , 1.        ]), array([1.        , 0.04761905, 0.        ]), array([0, 1]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.9915314, 0.0625   ]), array([0.99363508, 0.04761905]), array([0.99258213, 0.05405405]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.0625\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.047619047619047616\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.5206270627062706\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0.        , 0.00636492, 1.        ]), array([0.        , 0.04761905, 1.        ]), array([2, 1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.014720314033366044\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YGCZBvOEObAO"
      },
      "source": [
        "#### Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YXmg0PfjObAP",
        "outputId": "b38d055e-0df4-48f0-f637-0bc72f739744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "rfc = RandomForestClassifier(\n",
        "    n_estimators='warn',\n",
        "    criterion='gini',\n",
        "    max_depth=None,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    min_weight_fraction_leaf=0.0,\n",
        "    max_features='auto',\n",
        "    max_leaf_nodes=None,\n",
        "    min_impurity_decrease=0.0,\n",
        "    min_impurity_split=None,\n",
        "    bootstrap=True,\n",
        "    oob_score=False,\n",
        "    n_jobs=None,\n",
        "    random_state=None,\n",
        "    verbose=0,\n",
        "    warm_start=False,\n",
        "    class_weight=None,\n",
        ")\n",
        "\n",
        "rfc.fit(X_train,y_train)\n",
        "\n",
        "y_pred = rfc.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.9892051030421982\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.009684058445098682\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.5068756875687569\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.010794896957801767\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      7070\n",
            "           1       0.06      0.02      0.03        63\n",
            "\n",
            "    accuracy                           0.99      7133\n",
            "   macro avg       0.53      0.51      0.51      7133\n",
            "weighted avg       0.98      0.99      0.99      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.02181691247054718\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[7055   15]\n",
            " [  62    1]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.02531645569620253\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.010794896957801767\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.0019627085377822\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.01282051282051282\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.3728442137066567\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.02719678932967194\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[   1   62]\n",
            "  [  15 7055]]\n",
            "\n",
            " [[7055   15]\n",
            "  [  62    1]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 0.0625    , 1.        ]), array([1.        , 0.01587302, 0.        ]), array([0, 1]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.99128846, 0.0625    ]), array([0.99787836, 0.01587302]), array([0.9945725 , 0.02531646]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.0625\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.015873015873015872\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.5068756875687568\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0.        , 0.00212164, 1.        ]), array([0.        , 0.01587302, 1.        ]), array([2, 1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.01079489695780178\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ul50DqyQObAS"
      },
      "source": [
        "#### XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRX8Tl6dObAT",
        "outputId": "09b52c0d-cfd2-419b-93b1-56f791474ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgc = XGBClassifier(\n",
        "    max_depth=3,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=100,\n",
        "    silent=True,\n",
        "    objective='binary:logistic',\n",
        "    booster='gbtree',\n",
        "    n_jobs=1,\n",
        "    nthread=None,\n",
        "    gamma=0,\n",
        "    min_child_weight=1,\n",
        "    max_delta_step=0,\n",
        "    subsample=1,\n",
        "    colsample_bytree=1,\n",
        "    colsample_bylevel=1,\n",
        "    reg_alpha=0,\n",
        "    reg_lambda=1,\n",
        "    scale_pos_weight=1,\n",
        "    base_score=0.5,\n",
        "    random_state=0,\n",
        "    seed=None,\n",
        "    missing=None\n",
        ")\n",
        "\n",
        "xgc.fit(X_train,y_train)\n",
        "\n",
        "y_pred = xgc.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.9911678115799804\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.5\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      7070\n",
            "           1       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.99      7133\n",
            "   macro avg       0.50      0.50      0.50      7133\n",
            "weighted avg       0.98      0.99      0.99      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[7070    0]\n",
            " [  63    0]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.30505298091677835\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[   0   63]\n",
            "  [   0 7070]]\n",
            "\n",
            " [[7070    0]\n",
            "  [  63    0]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 1.        ]), array([1., 0.]), array([0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.99116781, 0.        ]), array([1., 0.]), array([0.99556432, 0.        ]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.5\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0., 1.]), array([0., 1.]), array([1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.008832188420019649\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PhUoTJnIObAV"
      },
      "source": [
        "#### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3_yNI6IZObAV",
        "outputId": "594789b3-79f3-4bea-9038-9414fa9e573f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "\n",
        "naive = GaussianNB(\n",
        "    priors=None,\n",
        "    var_smoothing=1e-09)\n",
        "\n",
        "naive.fit(X_train, y_train)\n",
        "\n",
        "y_pred = naive.predict(X_test)\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.9798121407542408\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.025937001260228867\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.5807952223793807\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.020187859245759148\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      7070\n",
            "           1       0.11      0.17      0.13        63\n",
            "\n",
            "    accuracy                           0.98      7133\n",
            "   macro avg       0.55      0.58      0.56      7133\n",
            "weighted avg       0.98      0.98      0.98      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.12291691572026298\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[6978   92]\n",
            " [  52   11]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.1325301204819277\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.020187859245759148\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.0113556708257396\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.07096774193548387\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.697274269428112\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.12673582114682663\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[  11   52]\n",
            "  [  92 6978]]\n",
            "\n",
            " [[6978   92]\n",
            "  [  52   11]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 0.10679612, 1.        ]), array([1.        , 0.17460317, 0.        ]), array([0, 1]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.99260313, 0.10679612]), array([0.98698727, 0.17460317]), array([0.98978723, 0.13253012]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.10679611650485436\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.1746031746031746\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.5807952223793809\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0.        , 0.01301273, 1.        ]), array([0.        , 0.17460317, 1.        ]), array([2, 1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.020187859245759165\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X_DcQMRLObAZ"
      },
      "source": [
        "#### Stocastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0r8kbvT2ObAZ",
        "outputId": "9a934af5-ad63-4e86-9ea6-1a4be702e1bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "sgd = SGDClassifier(\n",
        "    loss='hinge',\n",
        "    penalty='l2',\n",
        "    alpha=0.0001,\n",
        "    l1_ratio=0.15,\n",
        "    fit_intercept=True,\n",
        "    max_iter=1000,\n",
        "    tol=0.001,\n",
        "    shuffle=True,\n",
        "    verbose=0,\n",
        "    epsilon=0.1,\n",
        "    n_jobs=None,\n",
        "    random_state=None,\n",
        "    learning_rate='optimal',\n",
        "    eta0=0.0,\n",
        "    power_t=0.5,\n",
        "    early_stopping=False,\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=5,\n",
        "    class_weight=None,\n",
        "    warm_start=False,\n",
        "    average=False,\n",
        ")\n",
        "\n",
        "sgd.fit(X_train, y_train)  \n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.9911678115799804\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.5\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      7070\n",
            "           1       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.99      7133\n",
            "   macro avg       0.50      0.50      0.50      7133\n",
            "weighted avg       0.98      0.99      0.99      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[7070    0]\n",
            " [  63    0]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.30505298091677835\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[   0   63]\n",
            "  [   0 7070]]\n",
            "\n",
            " [[7070    0]\n",
            "  [  63    0]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 1.        ]), array([1., 0.]), array([0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.99116781, 0.        ]), array([1., 0.]), array([0.99556432, 0.        ]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.5\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0., 1.]), array([0., 1.]), array([1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.008832188420019649\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "710uP6UyObAb"
      },
      "source": [
        "#### Bagging Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t6wWXd33ObAc",
        "outputId": "18df36ee-16d0-421e-98ce-9118e8fafd32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "bgclass = BaggingClassifier(\n",
        "    base_estimator=None,\n",
        "    n_estimators=10,\n",
        "    max_samples=1.0,\n",
        "    max_features=1.0,\n",
        "    bootstrap=True,\n",
        "    bootstrap_features=False,\n",
        "    oob_score=False,\n",
        "    warm_start=False,\n",
        "    n_jobs=None,\n",
        "    random_state=None,\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "bgclass.fit(X_train,y_train)\n",
        "\n",
        "y_pred = bgclass.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.9894854899761671\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.009825781801107752\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.507017130284457\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.01051451002383289\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99      7070\n",
            "           1       0.07      0.02      0.03        63\n",
            "\n",
            "    accuracy                           0.99      7133\n",
            "   macro avg       0.53      0.51      0.51      7133\n",
            "weighted avg       0.98      0.99      0.99      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.02283566250271707\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[7057   13]\n",
            " [  62    1]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.025974025974025972\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.01051451002383289\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.0016823216038133\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.013157894736842105\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.3631597678935792\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.029668528244599635\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[   1   62]\n",
            "  [  13 7057]]\n",
            "\n",
            " [[7057   13]\n",
            "  [  62    1]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 0.07142857, 1.        ]), array([1.        , 0.01587302, 0.        ]), array([0, 1]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.99129091, 0.07142857]), array([0.99816124, 0.01587302]), array([0.99471422, 0.02597403]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.07142857142857142\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.015873015873015872\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.507017130284457\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0.        , 0.00183876, 1.        ]), array([0.        , 0.01587302, 1.        ]), array([2, 1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.010514510023832857\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7hdxw0fDObAf"
      },
      "source": [
        "#### Adaboost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fQD0-ZG3ObAf",
        "outputId": "eba07089-7ffa-4bb0-d4c5-0852d32c0e32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "abclass = AdaBoostClassifier(\n",
        "    base_estimator=None,\n",
        "    n_estimators=50,\n",
        "    learning_rate=1.0,\n",
        "    algorithm='SAMME.R',\n",
        "    random_state=None,\n",
        ")\n",
        "\n",
        "abclass.fit(X_train,y_train)\n",
        "\n",
        "y_pred = abclass.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.9908874246460115\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.012660248921289158\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.5077243438629577\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.009112575353988505\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      7070\n",
            "           1       0.25      0.02      0.03        63\n",
            "\n",
            "    accuracy                           0.99      7133\n",
            "   macro avg       0.62      0.51      0.51      7133\n",
            "weighted avg       0.98      0.99      0.99      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.028826556795354952\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[7067    3]\n",
            " [  62    1]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.029850746268656716\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.009112575353988505\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.000280386933969\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.015151515151515152\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.3147375388281917\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.061055848801045344\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[   1   62]\n",
            "  [   3 7067]]\n",
            "\n",
            " [[7067    3]\n",
            "  [  62    1]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 0.25      , 1.        ]), array([1.        , 0.01587302, 0.        ]), array([0, 1]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.99130313, 0.25      ]), array([0.99957567, 0.01587302]), array([0.99542221, 0.02985075]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.25\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.015873015873015872\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.5077243438629576\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0.00000000e+00, 4.24328147e-04, 1.00000000e+00]), array([0.        , 0.01587302, 1.        ]), array([2, 1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.009112575353988461\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QzVgwwd0ObAi"
      },
      "source": [
        "#### Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dHOUv-2xTiSL",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "vclass = VotingClassifier(\n",
        "    estimators=[('rfr', rfr), ('dtree', dtree)],\n",
        "    voting='hard',\n",
        "    weights=None,\n",
        "    n_jobs=None,\n",
        "    flatten_transform=True,\n",
        ")\n",
        "\n",
        "vclass.fit(X_train,y_train)\n",
        "\n",
        "y_pred = vclass.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JGfn9nMOObAl"
      },
      "source": [
        "#### Multi-layer perceptron (MLP) Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EYcBx5twObAl",
        "outputId": "f2af5d67-500f-45ba-e4ad-994258455500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(100,),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0001,\n",
        "    batch_size='auto',\n",
        "    learning_rate='constant',\n",
        "    learning_rate_init=0.001,\n",
        "    power_t=0.5,\n",
        "    max_iter=200,\n",
        "    shuffle=True,\n",
        "    random_state=None,\n",
        "    tol=0.0001,\n",
        "    verbose=False,\n",
        "    warm_start=False,\n",
        "    momentum=0.9,\n",
        "    nesterovs_momentum=True,\n",
        "    early_stopping=False,\n",
        "    validation_fraction=0.1,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-08,\n",
        "    n_iter_no_change=10,\n",
        ")\n",
        "\n",
        "mlp.fit(X_train, y_train)                         \n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Accuracy Score : 0.9911678115799804\n",
            "--------------------------------------------------------------------------------------------------\n",
            "AUC Metric : nan\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Average Precision Score : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Balanced Accuracy Score : 0.5\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Brier Score Loss : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Classification Report :               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      7070\n",
            "           1       0.00      0.00      0.00        63\n",
            "\n",
            "    accuracy                           0.99      7133\n",
            "   macro avg       0.50      0.50      0.50      7133\n",
            "weighted avg       0.98      0.99      0.99      7133\n",
            "\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Cohen Kappa Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Confusion Matrix : [[7070    0]\n",
            " [  63    0]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "F1 Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hamming Loss : 0.008832188420019628\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Hinge Loss : 1.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Jaccard Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Log Loss : 0.30505298091677835\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Matthews Corr Coef : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Multilabel Confusion Matrix : [[[   0   63]\n",
            "  [   0 7070]]\n",
            "\n",
            " [[7070    0]\n",
            "  [  63    0]]]\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall Curve : (array([0.00883219, 1.        ]), array([1., 0.]), array([0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Recall FScore Support : (array([0.99116781, 0.        ]), array([1., 0.]), array([0.99556432, 0.        ]), array([7070,   63]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Precision Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Recall Score : 0.0\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC AUC Score : 0.5\n",
            "--------------------------------------------------------------------------------------------------\n",
            "ROC Curve : (array([0., 1.]), array([0., 1.]), array([1, 0]))\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Zero One Loss : 0.008832188420019649\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rl5P706XObAo"
      },
      "source": [
        "#### MultiOutput Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rNWucHnsObAp",
        "outputId": "79d576e6-f944-412e-ce2d-ab7ee5bbfdbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "X, y = make_classification(n_samples=10, n_features=100, n_informative=30, n_classes=3, random_state=1)\n",
        "y2 = shuffle(y, random_state=1)\n",
        "y3 = shuffle(y, random_state=2)\n",
        "Y = np.vstack((y, y2, y3)).T\n",
        "n_samples, n_features = X.shape\n",
        "n_outputs = Y.shape[1] \n",
        "n_classes = 3\n",
        "forest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
        "multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
        "multi_target_forest.fit(X, Y).predict(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 2, 0],\n",
              "       [1, 2, 1],\n",
              "       [2, 1, 0],\n",
              "       [0, 0, 2],\n",
              "       [0, 2, 1],\n",
              "       [0, 0, 2],\n",
              "       [1, 1, 0],\n",
              "       [1, 1, 1],\n",
              "       [0, 0, 2],\n",
              "       [2, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ohUiz2wHObAr"
      },
      "source": [
        "#### MultiOutput Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qb7iP6jNObAs",
        "outputId": "c3c73097-7a3c-4757-ff4f-dc7350fc44bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "X, y = make_regression(n_samples=10, n_targets=3, random_state=1)\n",
        "MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X, y).predict(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-154.75474165, -147.03498585,  -50.03812219],\n",
              "       [   7.12165031,    5.12914884,  -81.46081961],\n",
              "       [-187.8948621 , -100.44373091,   13.88978285],\n",
              "       [-141.62745778,   95.02891072, -191.48204257],\n",
              "       [  97.03260883,  165.34867495,  139.52003279],\n",
              "       [ 123.92529176,   21.25719016,   -7.84253   ],\n",
              "       [-122.25193977,  -85.16443186, -107.12274212],\n",
              "       [ -30.170388  ,  -94.80956739,   12.16979946],\n",
              "       [ 140.72667194,  176.50941682,  -17.50447799],\n",
              "       [ 149.37967282,  -81.15699552,   -5.72850319]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O2uKo7qNObAt"
      },
      "source": [
        "#### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vti7H4QAUK7I",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
        "model = SelectFromModel(\n",
        "    estimator,\n",
        "    threshold=None,\n",
        "    prefit=False,\n",
        "    norm_order=1,\n",
        "    max_features=None,\n",
        ")\n",
        "X_new = model.transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADBjVsdP1zaw",
        "colab_type": "text"
      },
      "source": [
        "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9BIKroXDObAv"
      },
      "source": [
        "## Semi - Supervised Algorithms (Machine Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WenMA__KObAv"
      },
      "source": [
        "### Label Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d4Bk4CNeObAw",
        "outputId": "7c88ca34-c988-4772-cf54-9bd5acf064bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.semi_supervised import LabelPropagation\n",
        "\n",
        "label_prop_model = LabelPropagation(\n",
        "    kernel='rbf',\n",
        "    gamma=20,\n",
        "    n_neighbors=7,\n",
        "    max_iter=1,\n",
        "    tol=0.001,\n",
        "    n_jobs=None,\n",
        ")\n",
        "\n",
        "label_prop_model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = label_prop_model.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score :\",metrics.r2_score(y_test,y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:288: ConvergenceWarning: max_iter=1 was reached without convergence.\n",
            "  category=ConvergenceWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score : -0.23311331133113344\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probabilities /= normalizer\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RstKqnOZObAy"
      },
      "source": [
        "### Label Spreading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xal0JxVqObAy",
        "outputId": "809e3970-a23d-48bf-9544-8c60b636b44b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from sklearn.semi_supervised import LabelSpreading\n",
        "\n",
        "label_prop_model = LabelSpreading(\n",
        "    kernel='rbf',\n",
        "    gamma=20,\n",
        "    n_neighbors=7,\n",
        "    max_iter=1,\n",
        "    tol=0.001,\n",
        "    n_jobs=None,\n",
        ")\n",
        "\n",
        "label_prop_model.fit(X_train,y_train)\n",
        "\n",
        "y_pred = label_prop_model.predict(X_test)\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"R2 Score :\",metrics.r2_score(y_test,y_pred))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:288: ConvergenceWarning: max_iter=1 was reached without convergence.\n",
            "  category=ConvergenceWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------------------------\n",
            "R2 Score : -0.23311331133113344\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
            "  probabilities /= normalizer\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5igebqhObA0"
      },
      "source": [
        "## Unsupervised Algorithms (Machine Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ErdgQA1lObA0"
      },
      "source": [
        "### K-Means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8IHvxCuqObA1",
        "outputId": "c213a55d-2ffd-4274-af86-2ee7808a80e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "from sklearn.metrics.cluster import calinski_harabasz_score\n",
        "from sklearn.metrics.cluster import davies_bouldin_score\n",
        "from sklearn.metrics.cluster import completeness_score\n",
        "from sklearn.metrics.cluster import contingency_matrix\n",
        "from sklearn.metrics.cluster import fowlkes_mallows_score\n",
        "from sklearn.metrics.cluster import homogeneity_completeness_v_measure\n",
        "from sklearn.metrics.cluster import homogeneity_score\n",
        "from sklearn.metrics.cluster import mutual_info_score\n",
        "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
        "from sklearn.metrics.cluster import silhouette_score\n",
        "from sklearn.metrics.cluster import silhouette_samples\n",
        "from sklearn.metrics.cluster import v_measure_score\n",
        "\n",
        "\n",
        "kmeans = KMeans(\n",
        "    n_clusters=4,\n",
        "    init='k-means++',\n",
        "    n_init=10,\n",
        "    max_iter=300,\n",
        "    tol=0.0001,\n",
        "    precompute_distances='auto',\n",
        "    verbose=0,\n",
        "    random_state=None,\n",
        "    copy_x=True,\n",
        "    n_jobs=None,\n",
        "    algorithm='auto',\n",
        ").fit(X_train)\n",
        "\n",
        "print(kmeans.labels_)\n",
        "print(kmeans.cluster_centers_)\n",
        "\n",
        "kmeans.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,kmeans.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,kmeans.labels_))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Completeness Score :\",completeness_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Score :\",silhouette_score(X_train,kmeans.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Samples :\",silhouette_samples(X_train,kmeans.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 3 3 ... 3 0 1]\n",
            "[[2.74295223e+00 1.23820889e+03 1.31959671e+00 1.50650940e+00]\n",
            " [3.97142857e+00 2.95975111e+03 1.72730159e+00 2.64920635e+00]\n",
            " [4.33989501e+00 4.46663780e+03 1.90879265e+00 3.49606299e+00]\n",
            " [3.46813187e+00 2.01567070e+03 1.47802198e+00 2.17861722e+00]]\n",
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Calinski Harabasz Score : 32526.736957525507\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Davies Bouldin Score : 0.5566293464169927\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Score : 0.5422620112860752\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Samples : [0.35219067 0.71658154 0.38709775 ... 0.73079125 0.47518937 0.70869416]\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_ePQav-eObA4"
      },
      "source": [
        "### Spectral Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dZi2JwaNVSq3",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "spec = SpectralClustering(\n",
        "    n_clusters=4,\n",
        "    eigen_solver=None,\n",
        "    random_state=None,\n",
        "    n_init=10,\n",
        "    gamma=1.0,\n",
        "    affinity='rbf',\n",
        "    n_neighbors=10,\n",
        "    eigen_tol=0.0,\n",
        "    assign_labels='kmeans',\n",
        "    degree=3,\n",
        "    coef0=1,\n",
        "    kernel_params=None,\n",
        "    n_jobs=None,\n",
        ").fit(X_train)\n",
        "\n",
        "print(spec.labels_)\n",
        "print(spec.cluster_centers_)\n",
        "\n",
        "spec.predict(X_test)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,spec.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,spec.labels_))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Completeness Score :\",completeness_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Score :\",silhouette_score(X_train,spec.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Samples :\",silhouette_samples(X_train,spec.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hFkxIsVRObA6"
      },
      "source": [
        "### DBSCAN Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cQuG0bvFObA6",
        "outputId": "e6fa99b6-16c1-4c40-c1e0-e103dbd2620f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(\n",
        "    eps=0.5,\n",
        "    min_samples=5,\n",
        "    metric='euclidean',\n",
        "    metric_params=None,\n",
        "    algorithm='auto',\n",
        "    leaf_size=30,\n",
        "    p=None,\n",
        "    n_jobs=None,\n",
        ").fit(X_train)\n",
        "\n",
        "print(dbscan.labels_)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,dbscan.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,dbscan.labels_))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Completeness Score :\",completeness_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Score :\",silhouette_score(X_train,dbscan.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Samples :\",silhouette_samples(X_train,dbscan.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   1   2 ... 369  -1 516]\n",
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Calinski Harabasz Score : 20.34504046130372\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Davies Bouldin Score : 4.8839357456327575\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Score : 0.1700204070337957\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Samples : [ 0.4850618   0.81076289  0.63390284 ...  0.87110883 -0.89222697\n",
            "  0.963909  ]\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4RGExIsgObA9"
      },
      "source": [
        "### Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kN0BfeOzObA9",
        "outputId": "76563fd8-c8c8-4937-8e0a-3c418394926f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "aggclus = AgglomerativeClustering(\n",
        "    n_clusters=2,\n",
        "    affinity='euclidean',\n",
        "    memory=None,\n",
        "    connectivity=None,\n",
        "    compute_full_tree='auto',\n",
        "    linkage='ward',\n",
        "    pooling_func='deprecated',\n",
        "    distance_threshold=None,\n",
        ").fit(X_train)\n",
        "\n",
        "print(aggclus.labels_)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,aggclus.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,aggclus.labels_))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Completeness Score :\",completeness_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Score :\",silhouette_score(X_train,aggclus.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Samples :\",silhouette_samples(X_train,aggclus.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 ... 1 1 0]\n",
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Calinski Harabasz Score : 23781.015897196357\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Davies Bouldin Score : 0.5953727648396083\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Score : 0.5918015713057287\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Samples : [0.43616478 0.38290124 0.72894623 ... 0.41220805 0.56112077 0.63895725]\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fs8vledkObBA"
      },
      "source": [
        "### Affinity Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U_Qmh130ObBA",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "affclus = AffinityPropagation(\n",
        "    damping=0.5,\n",
        "    max_iter=5,\n",
        "    convergence_iter=15,\n",
        "    copy=True,\n",
        "    preference=None,\n",
        "    affinity='euclidean',\n",
        "    verbose=False,\n",
        ").fit(X_train)\n",
        "\n",
        "print(affclus.labels_)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,affclus.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,affclus.labels_))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Completeness Score :\",completeness_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Score :\",silhouette_score(X_train,affclus.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Samples :\",silhouette_samples(X_train,affclus.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "19B06bMOObBC"
      },
      "source": [
        "### OPTICS Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JvcnHZL7ObBD",
        "outputId": "5a0abec4-88fa-41d2-be74-972c12bfafd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "from sklearn.cluster import OPTICS\n",
        "\n",
        "optics = OPTICS(\n",
        "    min_samples=5,\n",
        "    max_eps=1,\n",
        "    metric='minkowski',\n",
        "    p=2,\n",
        "    metric_params=None,\n",
        "    cluster_method='xi',\n",
        "    eps=None,\n",
        "    xi=0.05,\n",
        "    predecessor_correction=True,\n",
        "    min_cluster_size=None,\n",
        "    algorithm='auto',\n",
        "    leaf_size=30,\n",
        "    n_jobs=None,\n",
        ").fit(X_train)\n",
        "\n",
        "print(optics.labels_)\n",
        "\n",
        "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,optics.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,optics.labels_))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Completeness Score :\",completeness_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Score :\",silhouette_score(X_train,optics.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "print(\"Silhouette Samples :\",silhouette_samples(X_train,optics.labels_))\n",
        "print(\"--------------------------------------------------------------------------------------------------\")\n",
        "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
        "#print(\"--------------------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/optics_.py:795: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[  0   3   8 ... 126  -1 943]\n",
            "*************************************| Error / Accuracy Metrics |************************************\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Calinski Harabasz Score : 14.270531803286424\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Davies Bouldin Score : 5.1442510762486675\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Score : 0.21567074450206808\n",
            "--------------------------------------------------------------------------------------------------\n",
            "Silhouette Samples : [-0.01008472  0.81553195  0.53972157 ...  1.         -0.87959254\n",
            "  0.93652039]\n",
            "--------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eMOXa3BNObBF",
        "outputId": "206acb3c-a6a7-4acd-b13c-ca2f131b4414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "lof = LocalOutlierFactor(\n",
        "    n_neighbors=20,\n",
        "    algorithm='auto',\n",
        "    leaf_size=30,\n",
        "    metric='minkowski',\n",
        "    p=2,\n",
        "    metric_params=None,\n",
        "    contamination='legacy',\n",
        "    novelty=False,\n",
        "    n_jobs=None,\n",
        ").fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/lof.py:236: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y8VydnOWXBWQ",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(linreg,X,y, cv=5) \n",
        "print(scores)\n",
        "\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QHpw-P3IObBI",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=2)\n",
        "for X_ktrain, X_ktest in kf.split(X):\n",
        "    print(\"%s %s\" % (X_ktrain,X_ktest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rvCeHsYIObBJ",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=None)\n",
        "for X_rtrain, X_rtest in rkf.split(X):\n",
        "    print(\"%s %s\" % (X_rtrain, X_rtest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H36W7jwEObBK",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "model_stored = pickle.dumps(linreg)\n",
        "model_loaded = pickle.loads(model_stored)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4dukVfsaObBM",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "estimators = [(\n",
        "    \n",
        "                'reduce_dim', \n",
        "                PCA(\n",
        "                n_components=None,\n",
        "                copy=True,\n",
        "                whiten=False,\n",
        "                svd_solver='auto',\n",
        "                tol=0.0,\n",
        "                iterated_power='auto',\n",
        "                random_state=None,\n",
        "    )\n",
        "\n",
        "),(\n",
        "    \n",
        "                'linreg', \n",
        "                LinearRegression(\n",
        "                fit_intercept=True,\n",
        "                normalize=False,\n",
        "                copy_X=True,\n",
        "                n_jobs=None,\n",
        "                )\n",
        "\n",
        ")]\n",
        "\n",
        "\n",
        "pipe = Pipeline(estimators)\n",
        "pipe \n",
        "\n",
        "Pipeline(memory=None,\n",
        "         steps=[('reduce_dim', PCA(copy=True)),\n",
        "                ('linreg', LinearRegression(fit_intercept=True,normalize=False,copy_X=True,n_jobs=None,))], \n",
        "                 verbose=False)\n",
        "\n",
        "print(pipe.steps[0])\n",
        "print(pipe[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSQOOMcQ4QIs",
        "colab_type": "text"
      },
      "source": [
        "#  (Predictive Modeling) - Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3495hNF2ObD-"
      },
      "source": [
        "## Neural Networks (Layers , Activation Functions , Optimizers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rULeBfxpbREv",
        "colab_type": "text"
      },
      "source": [
        "### Vanishing Gradients Problem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLep1sRrbdiL",
        "colab_type": "text"
      },
      "source": [
        "What Are Vanishing Gradients?\n",
        "\n",
        "The vanishing gradients problem is one example of unstable behavior that you may encounter when training a deep neural network.\n",
        "\n",
        "It describes the situation where a deep multilayer feed-forward network or a recurrent neural network is unable to propagate useful **gradient information** from the **output end** of the model back to the layers near the **input end** of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIGVy3U-dFsl",
        "colab_type": "text"
      },
      "source": [
        "A problem with training networks with many layers (e.g. deep neural networks) is that the gradient diminishes dramatically as it is propagated backward through the network.\n",
        "\n",
        "The error may be so small by the time it reaches layers close to the input of the model that it may have **very little effect**\n",
        "\n",
        "Deep models using the hyperbolic tangent activation function do not train easily, and much of this poor performance is blamed on the vanishing gradient problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkv1c9UByfTW",
        "colab_type": "text"
      },
      "source": [
        "Deep models using the **hyperbolic tangent activation function** do not train easily, and much of this **poor performance** is blamed on the vanishing gradient problem.\n",
        "The number of hidden layers can be increased from 1 to 5\n",
        "\n",
        "\n",
        "How to Fix Vanishing Gradients?\n",
        "\n",
        "1) When using the **rectified linear activation** function (ReLU), it is good practice to use the He weight initialization scheme. We can define the MLP with five hidden layers using ReLU and He initialization, listed below.\n",
        "\n",
        "2 ) This is because the activation function looks and acts like a linear function, making it easier to train and less likely to saturate, but is, in fact, a nonlinear function, forcing negative inputs to the value 0. It is claimed as one possible approach to addressing the vanishing gradients problem when training deeper models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSFE4Nf6bRVC",
        "colab_type": "text"
      },
      "source": [
        "### Exploding Gradients Problem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0UXol2PZNBL",
        "colab_type": "text"
      },
      "source": [
        "What Are Exploding Gradients?\n",
        "\n",
        "An **error gradient** is the **direction and magnitude calculated** during the training of a neural network that is used to update the network **weights** in the right direction and by the right amount.\n",
        "\n",
        "In deep networks or recurrent neural networks, **error gradients can accumulate** during an update and result in very large gradients. These in turn result in large updates to the network weights, and in turn, an **unstable network**.\n",
        "\n",
        "At an extreme, the values of weights can become so large as to overflow and result in **NaN values**.\n",
        "\n",
        "The explosion occurs through exponential growth by repeatedly multiplying gradients through the network layers that have values larger than 1.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hFVNz7ZZ1qZ",
        "colab_type": "text"
      },
      "source": [
        "How do You Know if You Have Exploding Gradients?\n",
        "\n",
        "There are some subtle signs that you may be suffering from exploding gradients during the training of your network, such as:\n",
        "\n",
        "1) The model is unable to get traction on your training data (e.g. poor loss).\n",
        "\n",
        "2) The model is unstable, resulting in large changes in loss from update to update.\n",
        "\n",
        "3) The model loss goes to NaN during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G6V1RN3aQc9",
        "colab_type": "text"
      },
      "source": [
        "How to Fix Exploding Gradients?\n",
        "\n",
        "1. Re-Design the Network Model\n",
        "\n",
        "In deep neural networks, exploding gradients may be addressed by redesigning the network to have fewer layers.\n",
        "There may also be some benefit in using a smaller batch size while training the network.\n",
        "In recurrent neural networks, updating across fewer prior time steps during training, called truncated Backpropagation through time, may reduce the exploding gradient problem.\n",
        "\n",
        "2. Use Long Short-Term Memory Networks\n",
        "\n",
        "In recurrent neural networks, gradient exploding can occur given the inherent instability in the training of this type of network, e.g. via Backpropagation through time that essentially transforms the recurrent network into a deep multilayer Perceptron neural network.\n",
        "\n",
        "Exploding gradients can be reduced by using the Long Short-Term Memory (LSTM) memory units and perhaps related gated-type neuron structures.\n",
        "Adopting LSTM memory units is a new best practice for recurrent neural networks for sequence prediction.\n",
        "\n",
        "3. Use Gradient Clipping\n",
        "\n",
        "Exploding gradients can still occur in very deep Multilayer Perceptron networks with a large batch size and LSTMs with very long input sequence lengths.\n",
        "If exploding gradients are still occurring, you can check for and limit the size of gradients during the training of your network.\n",
        "\n",
        "4. Use Weight Regularization\n",
        "\n",
        "Another approach, if exploding gradients are still occurring, is to check the size of network weights and apply a penalty to the networks loss function for large weight values.\n",
        "\n",
        "(Using an L1 or L2 penalty on the recurrent weights can help with exploding gradients)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J4Zcq987ObD_",
        "outputId": "136a0815-b012-4a85-92d5-9842ea0f1ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14480, 4)\n",
            "(14480,)\n",
            "(7133, 4)\n",
            "(7133,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jpciJN59ObEA"
      },
      "source": [
        "### Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "79C1LACWYhab",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Dense(\n",
        "    units,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IX5AsGRSObEB"
      },
      "source": [
        "### Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u6lWGZoYObEB",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Conv1D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=1,\n",
        "    padding='valid',\n",
        "    data_format='channels_last',\n",
        "    dilation_rate=1,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None\n",
        ")\n",
        "\n",
        "tf.keras.layers.Conv2D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format=None,\n",
        "    dilation_rate=(1, 1),\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QdvvRfKsObEC"
      },
      "source": [
        "### Pooling Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WPQQrcwYObED",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.MaxPooling1D(\n",
        "    pool_size=2,\n",
        "    strides=None,\n",
        "    padding='valid',\n",
        "    data_format='channels_last'\n",
        ")\n",
        "\n",
        "tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=None,\n",
        "    padding='valid',\n",
        "    data_format=None\n",
        ")\n",
        "\n",
        "tf.keras.layers.MaxPooling3D(\n",
        "    pool_size=(2, 2, 2),\n",
        "    strides=None,\n",
        "    padding='valid',\n",
        "    data_format=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nbmZ-sT1ObEF"
      },
      "source": [
        "### Locally Connected Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ff2NJAp4ObEF",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.LocallyConnected1D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=1,\n",
        "    padding='valid',\n",
        "    data_format=None,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    implementation=1\n",
        ")\n",
        "\n",
        "tf.keras.layers.LocallyConnected2D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format=None,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    implementation=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cXz-SbzBObEH"
      },
      "source": [
        "### Flatten Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pfhniZPkObEH",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(64, (3, 3),input_shape=(3, 32, 32), padding='same',))\n",
        "# now: model.output_shape == (None, 64, 32, 32)\n",
        "model.add(Flatten())\n",
        "# now: model.output_shape == (None, 65536)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OmFKvJz5ObEJ"
      },
      "source": [
        "### Recurrent Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sFsKH8_QObEJ",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.RNN(\n",
        "    cell,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    time_major=False\n",
        ")\n",
        "\n",
        "tf.keras.layers.SimpleRNN(\n",
        "    units,\n",
        "    activation='tanh',\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    recurrent_initializer='orthogonal',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False\n",
        ")\n",
        "\n",
        "tf.keras.layers.GRU(\n",
        "    units,\n",
        "    activation='tanh',\n",
        "    recurrent_activation='sigmoid',\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    recurrent_initializer='orthogonal',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    implementation=2,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    time_major=False,\n",
        "    reset_after=True\n",
        ")\n",
        "\n",
        "tf.keras.layers.LSTM(\n",
        "    units,\n",
        "    activation='tanh',\n",
        "    recurrent_activation='sigmoid',\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    recurrent_initializer='orthogonal',\n",
        "    bias_initializer='zeros',\n",
        "    unit_forget_bias=True,\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    implementation=2,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    time_major=False,\n",
        "    unroll=False\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vgWny6BXObEL"
      },
      "source": [
        "### Advanced Activation Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QFDPNbAlObEM",
        "outputId": "09c5f108-c8c4-4413-c398-0a60956a3915",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        "tf.keras.layers.ELU(alpha=1.0) # Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n",
        "tf.keras.layers.Softmax(axis=-1)\n",
        "tf.keras.layers.LeakyReLU(alpha=0.3) #Rectifier Nonlinearities Improve Neural Network Acoustic Models\n",
        "tf.keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None) #Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n",
        "tf.keras.layers.ThresholdedReLU(theta=1.0) #Zero-Bias Autoencoders and the Benefits of Co-Adapting Features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.advanced_activations.ThresholdedReLU at 0x14db90c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2XK3N72_ObEO"
      },
      "source": [
        "### Embedding Layer - A Theoretically Grounded Application of Dropout in Recurrent Neural Networks (RNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K0ip5KODObEO",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "okUYaaQrObEP"
      },
      "source": [
        "### Accelerating Deep Network Training (Reducing Internal Covariate Shift)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UNEffp3eObEQ",
        "outputId": "66a60d26-45fa-4f32-909e-2ec5f0285580",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.BatchNormalization(\n",
        "    axis=-1,\n",
        "    momentum=0.99,\n",
        "    epsilon=0.001,\n",
        "    center=True,\n",
        "    scale=True,\n",
        "    beta_initializer='zeros',\n",
        "    gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros',\n",
        "    moving_variance_initializer='ones',\n",
        "    beta_regularizer=None,\n",
        "    gamma_regularizer=None,\n",
        "    beta_constraint=None,\n",
        "    gamma_constraint=None,\n",
        "    renorm=False,\n",
        "    renorm_clipping=None,\n",
        "    renorm_momentum=0.99,\n",
        "    fused=None,\n",
        "    trainable=True,\n",
        "    virtual_batch_size=None,\n",
        "    adjustment=None,\n",
        "    name=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14db90f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7mNrnRKXObES"
      },
      "source": [
        "### Prevent Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MttI9j8UObES",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
        "tf.keras.layers.GaussianNoise(stddev)\n",
        "tf.keras.layers.GaussianDropout(rate)\n",
        "tf.keras.layers.AlphaDropout(rate, noise_shape=None, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aa4fIuAoObET"
      },
      "source": [
        "### Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uEjSJjvXObET",
        "colab": {}
      },
      "source": [
        "tf.keras.activations.elu(x, alpha=1.0)\n",
        "tf.keras.activations.exponential(x)\n",
        "tf.keras.activations.hard_sigmoid(x)\n",
        "tf.keras.activations.linear(x)\n",
        "tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
        "tf.keras.activations.selu(x)\n",
        "tf.keras.activations.sigmoid(x)\n",
        "tf.keras.activations.tanh(x)\n",
        "tf.keras.activations.softmax(x, axis=-1)\n",
        "tf.keras.activations.softplus(x)\n",
        "tf.keras.activations.softsign(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "irVTV48QObEU"
      },
      "source": [
        "### Regularizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ohlEPZPdObEU",
        "colab": {}
      },
      "source": [
        "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "\n",
        "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# A linear layer with L1 & L2 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qd2PHdWlObEV"
      },
      "source": [
        "### Metrics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QhyYQxWPObEV",
        "outputId": "6551a91f-66b9-4bf0-e78f-93580f4c9873",
        "colab": {}
      },
      "source": [
        "tf.keras.metrics.CategoricalAccuracy()\n",
        "tf.keras.metrics.Accuracy()\n",
        "tf.keras.metrics.AUC()\n",
        "tf.keras.metrics.BinaryAccuracy()\n",
        "tf.keras.metrics.BinaryCrossentropy()\n",
        "tf.keras.metrics.CategoricalAccuracy()\n",
        "tf.keras.metrics.CategoricalCrossentropy()\n",
        "tf.keras.metrics.CategoricalHinge()\n",
        "tf.keras.metrics.CosineSimilarity()\n",
        "tf.keras.metrics.Hinge()\n",
        "\n",
        "tf.keras.metrics.KLD(y_true, y_pred)\n",
        "tf.keras.metrics.MAE(y_true, y_pred)\n",
        "tf.keras.metrics.MAPE(y_true, y_pred)\n",
        "tf.keras.metrics.Mean()\n",
        "tf.keras.metrics.MSE(y_true, y_pred)\n",
        "tf.keras.metrics.MSLE(y_true, y_pred)\n",
        "\n",
        "tf.keras.metrics.Poisson()\n",
        "tf.keras.metrics.RootMeanSquaredError()\n",
        "tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.metrics.CategoricalCrossentropy at 0x14d8d7240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vb7QEs_aObEX"
      },
      "source": [
        "### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P4g-lZGcObEX",
        "colab": {}
      },
      "source": [
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction='auto',\n",
        "    name='categorical_crossentropy',\n",
        ")\n",
        "\n",
        "tf.keras.losses.BinaryCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction='auto',\n",
        "    name='binary_crossentropy',\n",
        ")\n",
        "\n",
        "tf.keras.losses.CategoricalHinge(\n",
        "    reduction='auto',\n",
        "    name='categorical_hinge',\n",
        ")\n",
        "\n",
        "tf.keras.losses.CosineSimilarity(\n",
        "    axis=-1,\n",
        "    reduction='auto',\n",
        "    name='cosine_similarity',\n",
        ")\n",
        "\n",
        "tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    reduction='auto',\n",
        "    name=None,\n",
        ")\n",
        "\n",
        "tf.keras.losses.KLD(y_true, y_pred)\n",
        "tf.keras.losses.LogCosh(reduction='auto', name='logcosh')\n",
        "tf.keras.losses.Poisson(reduction='auto', name='poisson')\n",
        "tf.keras.losses.SquaredHinge(reduction='auto', name='squared_hinge')\n",
        "\n",
        "tf.keras.losses.MAE(y_true, y_pred)\n",
        "tf.keras.losses.MAPE(y_true, y_pred)\n",
        "tf.keras.losses.MSE(y_true, y_pred)\n",
        "tf.keras.losses.MSLE(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LAE1NtZoObEY"
      },
      "source": [
        "### Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r8CnsWBiObEZ",
        "outputId": "64633ad8-b956-43c3-9e3f-dbb140665381",
        "colab": {}
      },
      "source": [
        "tf.keras.optimizers.Adadelta(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.95,\n",
        "    epsilon=1e-07,\n",
        "    name='Adadelta'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adagrad(\n",
        "    learning_rate=0.001,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    name='Adagrad'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name='Adam'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    name='Adamax'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Nadam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    name='Nadam'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    name='SGD'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Ftrl(\n",
        "    learning_rate=0.001,\n",
        "    learning_rate_power=-0.5,\n",
        "    initial_accumulator_value=0.1,\n",
        "    l1_regularization_strength=0.0,\n",
        "    l2_regularization_strength=0.0,\n",
        "    name='Ftrl',\n",
        "    l2_shrinkage_regularization_strength=0.0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl at 0x14cdec160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Gaaz7R5jEB",
        "colab_type": "text"
      },
      "source": [
        "## Deep Neural Networks (DNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LoY_I2gObEb"
      },
      "source": [
        "### Deep Neural Network (DNN) for Regression :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ST2RjxqsObEb",
        "outputId": "fb136113-2134-4067-e970-fe5d655e4211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3553
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def regression_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(64,input_dim=4))\n",
        "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(16,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(1))\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),loss = \"mse\",metrics =[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = regression_model()\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/100\n",
            "14480/14480 [==============================] - 0s 15us/sample - loss: 24077.8424 - acc: 0.0854 - val_loss: 0.0215 - val_acc: 0.9867\n",
            "Epoch 2/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0125 - acc: 0.9927 - val_loss: 0.0129 - val_acc: 0.9909\n",
            "Epoch 3/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0130 - acc: 0.9927 - val_loss: 0.0827 - val_acc: 0.9256\n",
            "Epoch 4/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 885.8289 - acc: 0.5742 - val_loss: 1.7083 - val_acc: 0.9912\n",
            "Epoch 5/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 529.4218 - acc: 0.5157 - val_loss: 524.7122 - val_acc: 0.0088\n",
            "Epoch 6/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 445.0928 - acc: 0.4961 - val_loss: 778.1347 - val_acc: 0.9912\n",
            "Epoch 7/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 489.3062 - acc: 0.5047 - val_loss: 656.0197 - val_acc: 0.0088\n",
            "Epoch 8/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 443.5343 - acc: 0.4941 - val_loss: 274.9792 - val_acc: 0.9912\n",
            "Epoch 9/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 493.4202 - acc: 0.5052 - val_loss: 367.5925 - val_acc: 0.0088\n",
            "Epoch 10/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 444.4734 - acc: 0.4959 - val_loss: 1475.0523 - val_acc: 0.9912\n",
            "Epoch 11/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 205.4427 - acc: 0.5036 - val_loss: 1232.3436 - val_acc: 0.0088\n",
            "Epoch 12/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 400.1292 - acc: 0.4953 - val_loss: 1233.9900 - val_acc: 0.9912\n",
            "Epoch 13/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 376.9817 - acc: 0.5044 - val_loss: 1360.1720 - val_acc: 0.0088\n",
            "Epoch 14/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 314.5192 - acc: 0.4953 - val_loss: 468.7754 - val_acc: 0.9912\n",
            "Epoch 15/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 334.1401 - acc: 0.5059 - val_loss: 639.5700 - val_acc: 0.0088\n",
            "Epoch 16/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 295.6788 - acc: 0.4961 - val_loss: 569.7871 - val_acc: 0.9912\n",
            "Epoch 17/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 298.8173 - acc: 0.5055 - val_loss: 352.0087 - val_acc: 0.0088\n",
            "Epoch 18/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 281.8611 - acc: 0.4946 - val_loss: 401.5198 - val_acc: 0.9912\n",
            "Epoch 19/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 266.5429 - acc: 0.5054 - val_loss: 176.2505 - val_acc: 0.0088\n",
            "Epoch 20/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 242.1960 - acc: 0.4959 - val_loss: 147.6920 - val_acc: 0.9912\n",
            "Epoch 21/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 220.3410 - acc: 0.5047 - val_loss: 206.6050 - val_acc: 0.0088\n",
            "Epoch 22/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 189.7994 - acc: 0.4950 - val_loss: 301.5651 - val_acc: 0.9912\n",
            "Epoch 23/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 180.6182 - acc: 0.5050 - val_loss: 293.9100 - val_acc: 0.0088\n",
            "Epoch 24/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 178.5386 - acc: 0.4950 - val_loss: 150.0191 - val_acc: 0.9912\n",
            "Epoch 25/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 170.8329 - acc: 0.5046 - val_loss: 107.5187 - val_acc: 0.0088\n",
            "Epoch 26/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 142.4293 - acc: 0.4953 - val_loss: 190.5522 - val_acc: 0.9912\n",
            "Epoch 27/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 139.9497 - acc: 0.5052 - val_loss: 92.6311 - val_acc: 0.0088\n",
            "Epoch 28/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 126.8358 - acc: 0.4957 - val_loss: 56.4212 - val_acc: 0.9912\n",
            "Epoch 29/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 123.6298 - acc: 0.5061 - val_loss: 82.6105 - val_acc: 0.0088\n",
            "Epoch 30/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 114.9083 - acc: 0.4953 - val_loss: 70.5810 - val_acc: 0.9912\n",
            "Epoch 31/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 44.9153 - acc: 0.5484 - val_loss: 10.1310 - val_acc: 0.0088\n",
            "Epoch 32/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 59.9246 - acc: 0.4950 - val_loss: 35.9701 - val_acc: 0.9912\n",
            "Epoch 33/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 59.2736 - acc: 0.5041 - val_loss: 30.5245 - val_acc: 0.0088\n",
            "Epoch 34/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 52.3890 - acc: 0.4956 - val_loss: 50.2321 - val_acc: 0.9912\n",
            "Epoch 35/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 51.0632 - acc: 0.5046 - val_loss: 50.1428 - val_acc: 0.0088\n",
            "Epoch 36/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 69.2107 - acc: 0.4988 - val_loss: 0.1704 - val_acc: 0.9912\n",
            "Epoch 37/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 40.8213 - acc: 0.6321 - val_loss: 1.6098 - val_acc: 0.0457\n",
            "Epoch 38/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 20.4210 - acc: 0.5533 - val_loss: 45.4473 - val_acc: 0.9912\n",
            "Epoch 39/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 30.4005 - acc: 0.5048 - val_loss: 54.2613 - val_acc: 0.0088\n",
            "Epoch 40/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 28.6482 - acc: 0.4961 - val_loss: 81.3055 - val_acc: 0.9912\n",
            "Epoch 41/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 26.3997 - acc: 0.5052 - val_loss: 40.5506 - val_acc: 0.0088\n",
            "Epoch 42/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 25.3494 - acc: 0.4942 - val_loss: 29.0293 - val_acc: 0.9912\n",
            "Epoch 43/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 22.2986 - acc: 0.5054 - val_loss: 20.9288 - val_acc: 0.0088\n",
            "Epoch 44/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 18.6805 - acc: 0.4945 - val_loss: 26.0849 - val_acc: 0.9912\n",
            "Epoch 45/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 15.6222 - acc: 0.5052 - val_loss: 8.0814 - val_acc: 0.0093\n",
            "Epoch 46/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 15.1460 - acc: 0.4958 - val_loss: 9.2317 - val_acc: 0.9912\n",
            "Epoch 47/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 13.9966 - acc: 0.5044 - val_loss: 12.1245 - val_acc: 0.0088\n",
            "Epoch 48/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 12.7135 - acc: 0.4970 - val_loss: 7.1570 - val_acc: 0.9912\n",
            "Epoch 49/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 54.1629 - acc: 0.5758 - val_loss: 0.0090 - val_acc: 0.9912\n",
            "Epoch 50/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 51/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 1.1837 - acc: 0.8816 - val_loss: 56.9383 - val_acc: 0.0088\n",
            "Epoch 52/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 85.7221 - acc: 0.8539 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 53/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0093 - val_acc: 0.9912\n",
            "Epoch 54/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.5465 - acc: 0.9118 - val_loss: 50.9197 - val_acc: 0.0088\n",
            "Epoch 55/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8.5894 - acc: 0.5582 - val_loss: 25.2660 - val_acc: 0.9912\n",
            "Epoch 56/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 9.4278 - acc: 0.5153 - val_loss: 11.9390 - val_acc: 0.0088\n",
            "Epoch 57/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 13.9960 - acc: 0.4952 - val_loss: 83.8669 - val_acc: 0.9912\n",
            "Epoch 58/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 16.4968 - acc: 0.9229 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 59/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 60/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 7.7343 - acc: 0.8420 - val_loss: 0.0239 - val_acc: 0.9912\n",
            "Epoch 61/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 10.5067 - acc: 0.9228 - val_loss: 0.0091 - val_acc: 0.9912\n",
            "Epoch 62/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0079 - acc: 0.9931 - val_loss: 0.0656 - val_acc: 0.9790\n",
            "Epoch 63/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 5.5607 - acc: 0.6419 - val_loss: 0.4022 - val_acc: 0.9912\n",
            "Epoch 64/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 5.1891 - acc: 0.5273 - val_loss: 0.6166 - val_acc: 0.2679\n",
            "Epoch 65/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 4.2680 - acc: 0.5261 - val_loss: 1.6739 - val_acc: 0.9912\n",
            "Epoch 66/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 9.6510 - acc: 0.6428 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 67/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0092 - val_acc: 0.9912\n",
            "Epoch 68/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 11.8590 - acc: 0.7831 - val_loss: 0.0250 - val_acc: 0.9912\n",
            "Epoch 69/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0082 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 70/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0093 - val_acc: 0.9912\n",
            "Epoch 71/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 4.0881 - acc: 0.7123 - val_loss: 0.2091 - val_acc: 0.9912\n",
            "Epoch 72/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 3.1308 - acc: 0.5959 - val_loss: 1.0191 - val_acc: 0.1196\n",
            "Epoch 73/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 2.6344 - acc: 0.5194 - val_loss: 0.6827 - val_acc: 0.9912\n",
            "Epoch 74/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 2.1284 - acc: 0.5317 - val_loss: 0.8738 - val_acc: 0.1584\n",
            "Epoch 75/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 7.1973 - acc: 0.7328 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 76/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 0.9912\n",
            "Epoch 77/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0127 - val_acc: 0.9912\n",
            "Epoch 78/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 1.4043 - acc: 0.7458 - val_loss: 0.0846 - val_acc: 0.9525\n",
            "Epoch 79/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 1.1813 - acc: 0.7028 - val_loss: 0.1987 - val_acc: 0.9912\n",
            "Epoch 80/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 10.5459 - acc: 0.6604 - val_loss: 0.9719 - val_acc: 0.9912\n",
            "Epoch 81/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.1346 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 82/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 83/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0082 - acc: 0.9931 - val_loss: 0.1458 - val_acc: 0.9912\n",
            "Epoch 84/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 4.6700 - acc: 0.7562 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 85/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 86/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0078 - acc: 0.9931 - val_loss: 0.0651 - val_acc: 0.9781\n",
            "Epoch 87/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.2396 - acc: 0.8775 - val_loss: 0.2659 - val_acc: 0.9912\n",
            "Epoch 88/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.3328 - acc: 0.7990 - val_loss: 0.3569 - val_acc: 0.4966\n",
            "Epoch 89/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 15.8533 - acc: 0.8258 - val_loss: 1.0061 - val_acc: 0.9912\n",
            "Epoch 90/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.3246 - acc: 0.9931 - val_loss: 0.0319 - val_acc: 0.9912\n",
            "Epoch 91/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0119 - acc: 0.9931 - val_loss: 0.0090 - val_acc: 0.9912\n",
            "Epoch 92/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 0.9912\n",
            "Epoch 93/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 94/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 95/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 96/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 97/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 98/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 99/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 100/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00735136],\n",
              "       [0.00735136],\n",
              "       [0.00735136],\n",
              "       ...,\n",
              "       [0.00735136],\n",
              "       [0.00735136],\n",
              "       [0.00735136]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OZ-XxPgbObEd"
      },
      "source": [
        "### Deep Neural Network (DNN) for Binary Classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HCLzs7HnObEd",
        "outputId": "891615f5-7106-4fa8-fb67-58bec7a8330c",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def binaryclass_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128,input_dim=4))\n",
        "    model.add(layers.Dense(64,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(1,activation=tf.nn.sigmoid))  \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),loss = 'binary_crossentropy',metrics =[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = binaryclass_model()\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/100\n",
            "14480/14480 [==============================] - 1s 39us/sample - loss: 8295368.5436 - accuracy: 0.0000e+00 - val_loss: 8402822.8707 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2729 - accuracy: 0.0000e+00 - val_loss: 8402822.3857 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4691 - accuracy: 0.0000e+00 - val_loss: 8402822.7523 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4298 - accuracy: 0.0000e+00 - val_loss: 8402822.7397 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2298 - accuracy: 0.0000e+00 - val_loss: 8402822.7931 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6033 - accuracy: 0.0000e+00 - val_loss: 8402822.5061 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.8906 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3238 - accuracy: 0.0000e+00 - val_loss: 8402822.7584 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4254 - accuracy: 0.0000e+00 - val_loss: 8402822.5364 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3796 - accuracy: 0.0000e+00 - val_loss: 8402822.4399 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5370 - accuracy: 0.0000e+00 - val_loss: 8402822.7419 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4442 - accuracy: 0.0000e+00 - val_loss: 8402822.9446 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6094 - accuracy: 0.0000e+00 - val_loss: 8402822.4560 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4685 - accuracy: 0.0000e+00 - val_loss: 8402822.2721 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.1481 - accuracy: 0.0000e+00 - val_loss: 8402822.8129 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.3481 - accuracy: 0.0000e+00 - val_loss: 8402822.6361 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.4729 - accuracy: 0.0000e+00 - val_loss: 8402822.4647 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6961 - accuracy: 0.0000e+00 - val_loss: 8402822.9023 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2696 - accuracy: 0.0000e+00 - val_loss: 8402822.4947 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3624 - accuracy: 0.0000e+00 - val_loss: 8402822.5883 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3442 - accuracy: 0.0000e+00 - val_loss: 8402822.5619 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4680 - accuracy: 0.0000e+00 - val_loss: 8402822.5850 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3812 - accuracy: 0.0000e+00 - val_loss: 8402822.5723 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4149 - accuracy: 0.0000e+00 - val_loss: 8402822.6846 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3961 - accuracy: 0.0000e+00 - val_loss: 8402822.8864 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3906 - accuracy: 0.0000e+00 - val_loss: 8402822.7906 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3956 - accuracy: 0.0000e+00 - val_loss: 8402823.0008 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.1845 - accuracy: 0.0000e+00 - val_loss: 8402822.5109 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2751 - accuracy: 0.0000e+00 - val_loss: 8402822.5022 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4354 - accuracy: 0.0000e+00 - val_loss: 8402822.7374 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6829 - accuracy: 0.0000e+00 - val_loss: 8402822.5280 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4674 - accuracy: 0.0000e+00 - val_loss: 8402822.8786 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5105 - accuracy: 0.0000e+00 - val_loss: 8402822.7837 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4856 - accuracy: 0.0000e+00 - val_loss: 8402822.5204 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.5409 - accuracy: 0.0000e+00 - val_loss: 8402822.6317 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2227 - accuracy: 0.0000e+00 - val_loss: 8402822.9075 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4144 - accuracy: 0.0000e+00 - val_loss: 8402822.6752 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4188 - accuracy: 0.0000e+00 - val_loss: 8402822.5311 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3591 - accuracy: 0.0000e+00 - val_loss: 8402822.7861 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4878 - accuracy: 0.0000e+00 - val_loss: 8402822.7582 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4840 - accuracy: 0.0000e+00 - val_loss: 8402822.2678 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2033 - accuracy: 0.0000e+00 - val_loss: 8402822.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5044 - accuracy: 0.0000e+00 - val_loss: 8402822.6345 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4337 - accuracy: 0.0000e+00 - val_loss: 8402822.9141 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1923 - accuracy: 0.0000e+00 - val_loss: 8402823.0918 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4083 - accuracy: 0.0000e+00 - val_loss: 8402822.9626 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1785 - accuracy: 0.0000e+00 - val_loss: 8402822.6171 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4177 - accuracy: 0.0000e+00 - val_loss: 8402822.4830 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5586 - accuracy: 0.0000e+00 - val_loss: 8402822.9157 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4431 - accuracy: 0.0000e+00 - val_loss: 8402822.5925 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3072 - accuracy: 0.0000e+00 - val_loss: 8402822.5470 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3116 - accuracy: 0.0000e+00 - val_loss: 8402822.5311 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3536 - accuracy: 0.0000e+00 - val_loss: 8402822.7465 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4884 - accuracy: 0.0000e+00 - val_loss: 8402822.8428 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4707 - accuracy: 0.0000e+00 - val_loss: 8402822.7341 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6420 - accuracy: 0.0000e+00 - val_loss: 8402822.7165 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2199 - accuracy: 0.0000e+00 - val_loss: 8402822.7922 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3646 - accuracy: 0.0000e+00 - val_loss: 8402822.8089 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4862 - accuracy: 0.0000e+00 - val_loss: 8402822.7189 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5287 - accuracy: 0.0000e+00 - val_loss: 8402822.6590 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3536 - accuracy: 0.0000e+00 - val_loss: 8402822.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3961 - accuracy: 0.0000e+00 - val_loss: 8402822.5271 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3138 - accuracy: 0.0000e+00 - val_loss: 8402822.1523 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4061 - accuracy: 0.0000e+00 - val_loss: 8402822.7015 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "14480/14480 [==============================] - 0s 10us/sample - loss: 8295368.5044 - accuracy: 0.0000e+00 - val_loss: 8402822.6449 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2022 - accuracy: 0.0000e+00 - val_loss: 8402823.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3315 - accuracy: 0.0000e+00 - val_loss: 8402822.8184 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5204 - accuracy: 0.0000e+00 - val_loss: 8402822.6126 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5238 - accuracy: 0.0000e+00 - val_loss: 8402822.8909 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3431 - accuracy: 0.0000e+00 - val_loss: 8402822.9244 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4177 - accuracy: 0.0000e+00 - val_loss: 8402822.6037 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4000 - accuracy: 0.0000e+00 - val_loss: 8402822.4586 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4265 - accuracy: 0.0000e+00 - val_loss: 8402822.9352 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5033 - accuracy: 0.0000e+00 - val_loss: 8402822.4707 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4669 - accuracy: 0.0000e+00 - val_loss: 8402822.7307 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5215 - accuracy: 0.0000e+00 - val_loss: 8402822.4659 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4160 - accuracy: 0.0000e+00 - val_loss: 8402822.4670 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4320 - accuracy: 0.0000e+00 - val_loss: 8402822.8773 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2989 - accuracy: 0.0000e+00 - val_loss: 8402822.7346 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2608 - accuracy: 0.0000e+00 - val_loss: 8402822.5990 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5381 - accuracy: 0.0000e+00 - val_loss: 8402822.7458 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.3983 - accuracy: 0.0000e+00 - val_loss: 8402822.9714 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5204 - accuracy: 0.0000e+00 - val_loss: 8402823.1312 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4155 - accuracy: 0.0000e+00 - val_loss: 8402822.9336 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2580 - accuracy: 0.0000e+00 - val_loss: 8402822.7873 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5050 - accuracy: 0.0000e+00 - val_loss: 8402823.0310 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4552 - accuracy: 0.0000e+00 - val_loss: 8402822.4691 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3823 - accuracy: 0.0000e+00 - val_loss: 8402822.7336 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4166 - accuracy: 0.0000e+00 - val_loss: 8402822.7264 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3818 - accuracy: 0.0000e+00 - val_loss: 8402822.6480 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.6267 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3602 - accuracy: 0.0000e+00 - val_loss: 8402822.5260 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4265 - accuracy: 0.0000e+00 - val_loss: 8402822.3326 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1669 - accuracy: 0.0000e+00 - val_loss: 8402822.9249 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4851 - accuracy: 0.0000e+00 - val_loss: 8402822.7352 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.5182 - accuracy: 0.0000e+00 - val_loss: 8402822.5558 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.4110 - accuracy: 0.0000e+00 - val_loss: 8402822.6736 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1492 - accuracy: 0.0000e+00 - val_loss: 8402822.4661 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3878 - accuracy: 0.0000e+00 - val_loss: 8402822.6316 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n9aVIWn1ObEf"
      },
      "source": [
        "### Deep Neural Network (DNN) for Multi-Class Classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O3998DVwObEf",
        "outputId": "60ed0a5e-f8ac-4675-d64d-6759563af2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3655
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def multiclass_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128,input_dim=4))\n",
        "    model.add(layers.Dense(64,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(14,activation=tf.nn.softmax))  \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),loss = 'sparse_categorical_crossentropy',metrics =[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = multiclass_model()\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/100\n",
            "14480/14480 [==============================] - 1s 37us/sample - loss: 85.2323 - acc: 0.7825 - val_loss: 18.4541 - val_acc: 0.9912\n",
            "Epoch 2/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 10.4217 - acc: 0.9931 - val_loss: 11.4321 - val_acc: 0.9912\n",
            "Epoch 3/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 5.5147 - acc: 0.9231 - val_loss: 17.2698 - val_acc: 0.9912\n",
            "Epoch 4/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 7.8217 - acc: 0.9931 - val_loss: 5.1975 - val_acc: 0.9912\n",
            "Epoch 5/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 36.9202 - acc: 0.8541 - val_loss: 19.9685 - val_acc: 0.9912\n",
            "Epoch 6/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 10.7934 - acc: 0.9931 - val_loss: 10.4356 - val_acc: 0.9912\n",
            "Epoch 7/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 8.3069 - acc: 0.9231 - val_loss: 10.3582 - val_acc: 0.9912\n",
            "Epoch 8/100\n",
            "14480/14480 [==============================] - 0s 33us/sample - loss: 34.4879 - acc: 0.8539 - val_loss: 24.6847 - val_acc: 0.9912\n",
            "Epoch 9/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 12.3716 - acc: 0.9931 - val_loss: 6.1752 - val_acc: 0.9912\n",
            "Epoch 10/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 9.8100 - acc: 0.9228 - val_loss: 9.6859 - val_acc: 0.9912\n",
            "Epoch 11/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 12.7904 - acc: 0.9226 - val_loss: 254.5598 - val_acc: 0.0088\n",
            "Epoch 12/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 30.7963 - acc: 0.9233 - val_loss: 10.6206 - val_acc: 0.9912\n",
            "Epoch 13/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 2.6273 - acc: 0.9931 - val_loss: 1.1685 - val_acc: 0.9912\n",
            "Epoch 14/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 8.9070 - acc: 0.9235 - val_loss: 5.9908 - val_acc: 0.9912\n",
            "Epoch 15/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 15.2661 - acc: 0.9227 - val_loss: 4.8545 - val_acc: 0.9912\n",
            "Epoch 16/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 22.8889 - acc: 0.8532 - val_loss: 3.3279 - val_acc: 0.9912\n",
            "Epoch 17/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 1.8561 - acc: 0.9931 - val_loss: 2.0649 - val_acc: 0.9912\n",
            "Epoch 18/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.9337 - acc: 0.9931 - val_loss: 0.5554 - val_acc: 0.9912\n",
            "Epoch 19/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.2126 - acc: 0.9931 - val_loss: 0.0977 - val_acc: 0.9912\n",
            "Epoch 20/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0718 - acc: 0.9931 - val_loss: 0.0996 - val_acc: 0.9912\n",
            "Epoch 21/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0739 - acc: 0.9931 - val_loss: 0.2651 - val_acc: 0.9912\n",
            "Epoch 22/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.1111 - acc: 0.9931 - val_loss: 0.8191 - val_acc: 0.9912\n",
            "Epoch 23/100\n",
            "14480/14480 [==============================] - 0s 32us/sample - loss: 0.1733 - acc: 0.9931 - val_loss: 0.4577 - val_acc: 0.9912\n",
            "Epoch 24/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 2.7704 - acc: 0.8539 - val_loss: 0.3340 - val_acc: 0.9912\n",
            "Epoch 25/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0947 - acc: 0.9931 - val_loss: 0.1504 - val_acc: 0.9912\n",
            "Epoch 26/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0817 - acc: 0.9931 - val_loss: 0.2651 - val_acc: 0.9912\n",
            "Epoch 27/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.1948 - acc: 0.9931 - val_loss: 1.3744 - val_acc: 0.9912\n",
            "Epoch 28/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.3107 - acc: 0.9931 - val_loss: 0.0869 - val_acc: 0.9912\n",
            "Epoch 29/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0765 - acc: 0.9931 - val_loss: 0.1248 - val_acc: 0.9912\n",
            "Epoch 30/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0830 - acc: 0.9931 - val_loss: 0.1181 - val_acc: 0.9912\n",
            "Epoch 31/100\n",
            "14480/14480 [==============================] - 0s 26us/sample - loss: 1.2972 - acc: 0.9931 - val_loss: 1.4498 - val_acc: 0.9912\n",
            "Epoch 32/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 1.3433 - acc: 0.9931 - val_loss: 1.2246 - val_acc: 0.9912\n",
            "Epoch 33/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 1.1346 - acc: 0.9931 - val_loss: 1.0337 - val_acc: 0.9912\n",
            "Epoch 34/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 0.9535 - acc: 0.9931 - val_loss: 0.8656 - val_acc: 0.9912\n",
            "Epoch 35/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.7945 - acc: 0.9931 - val_loss: 0.7193 - val_acc: 0.9912\n",
            "Epoch 36/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.6568 - acc: 0.9931 - val_loss: 0.5938 - val_acc: 0.9912\n",
            "Epoch 37/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.5395 - acc: 0.9931 - val_loss: 0.4879 - val_acc: 0.9912\n",
            "Epoch 38/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.4412 - acc: 0.9931 - val_loss: 0.4001 - val_acc: 0.9912\n",
            "Epoch 39/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.3601 - acc: 0.9931 - val_loss: 0.3282 - val_acc: 0.9912\n",
            "Epoch 40/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.2939 - acc: 0.9931 - val_loss: 0.2701 - val_acc: 0.9912\n",
            "Epoch 41/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.2406 - acc: 0.9931 - val_loss: 0.2236 - val_acc: 0.9912\n",
            "Epoch 42/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.1981 - acc: 0.9931 - val_loss: 0.1868 - val_acc: 0.9912\n",
            "Epoch 43/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.1644 - acc: 0.9931 - val_loss: 0.1577 - val_acc: 0.9912\n",
            "Epoch 44/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.1379 - acc: 0.9931 - val_loss: 0.1349 - val_acc: 0.9912\n",
            "Epoch 45/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 0.1170 - acc: 0.9931 - val_loss: 0.1170 - val_acc: 0.9912\n",
            "Epoch 46/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.1007 - acc: 0.9931 - val_loss: 0.1029 - val_acc: 0.9912\n",
            "Epoch 47/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0879 - acc: 0.9931 - val_loss: 0.0918 - val_acc: 0.9912\n",
            "Epoch 48/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0778 - acc: 0.9931 - val_loss: 0.0832 - val_acc: 0.9912\n",
            "Epoch 49/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0700 - acc: 0.9931 - val_loss: 0.0764 - val_acc: 0.9912\n",
            "Epoch 50/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0638 - acc: 0.9931 - val_loss: 0.0712 - val_acc: 0.9912\n",
            "Epoch 51/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 0.0591 - acc: 0.9931 - val_loss: 0.0672 - val_acc: 0.9912\n",
            "Epoch 52/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0554 - acc: 0.9931 - val_loss: 0.0641 - val_acc: 0.9912\n",
            "Epoch 53/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0526 - acc: 0.9931 - val_loss: 0.0618 - val_acc: 0.9912\n",
            "Epoch 54/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 0.0504 - acc: 0.9931 - val_loss: 0.0598 - val_acc: 0.9912\n",
            "Epoch 55/100\n",
            "14480/14480 [==============================] - 0s 26us/sample - loss: 0.0486 - acc: 0.9931 - val_loss: 0.0582 - val_acc: 0.9912\n",
            "Epoch 56/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0472 - acc: 0.9931 - val_loss: 0.0571 - val_acc: 0.9912\n",
            "Epoch 57/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0462 - acc: 0.9931 - val_loss: 0.0560 - val_acc: 0.9912\n",
            "Epoch 58/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0453 - acc: 0.9931 - val_loss: 0.0553 - val_acc: 0.9912\n",
            "Epoch 59/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0446 - acc: 0.9931 - val_loss: 0.0547 - val_acc: 0.9912\n",
            "Epoch 60/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 0.0441 - acc: 0.9931 - val_loss: 0.0540 - val_acc: 0.9912\n",
            "Epoch 61/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0436 - acc: 0.9931 - val_loss: 0.0534 - val_acc: 0.9912\n",
            "Epoch 62/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0432 - acc: 0.9931 - val_loss: 0.0531 - val_acc: 0.9912\n",
            "Epoch 63/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0429 - acc: 0.9931 - val_loss: 0.0526 - val_acc: 0.9912\n",
            "Epoch 64/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0427 - acc: 0.9931 - val_loss: 0.0524 - val_acc: 0.9912\n",
            "Epoch 65/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0425 - acc: 0.9931 - val_loss: 0.0521 - val_acc: 0.9912\n",
            "Epoch 66/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0423 - acc: 0.9931 - val_loss: 0.0519 - val_acc: 0.9912\n",
            "Epoch 67/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0422 - acc: 0.9931 - val_loss: 0.0517 - val_acc: 0.9912\n",
            "Epoch 68/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0420 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 69/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0419 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 70/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0418 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 71/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0418 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 72/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0417 - acc: 0.9931 - val_loss: 0.0514 - val_acc: 0.9912\n",
            "Epoch 73/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0417 - acc: 0.9931 - val_loss: 0.0514 - val_acc: 0.9912\n",
            "Epoch 74/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0416 - acc: 0.9931 - val_loss: 0.0513 - val_acc: 0.9912\n",
            "Epoch 75/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0416 - acc: 0.9931 - val_loss: 0.0512 - val_acc: 0.9912\n",
            "Epoch 76/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0415 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
            "Epoch 77/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0415 - acc: 0.9931 - val_loss: 0.0512 - val_acc: 0.9912\n",
            "Epoch 78/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
            "Epoch 79/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
            "Epoch 80/100\n",
            "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
            "Epoch 81/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 82/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 83/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 84/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 85/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 86/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 87/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 88/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 89/100\n",
            "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 90/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 91/100\n",
            "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 92/100\n",
            "14480/14480 [==============================] - 0s 24us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
            "Epoch 93/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 94/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 95/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0507 - val_acc: 0.9912\n",
            "Epoch 96/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 97/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 98/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
            "Epoch 99/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 100/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       ...,\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804076e-07,\n",
              "        7.7093949e-07, 7.5853706e-07]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6zr63na53LE",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wUar-316ObEg"
      },
      "source": [
        "### Convolutional Neural Network (CNN) for Multi-Class Classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wu4yq5_BObEg",
        "outputId": "96dcb77c-2ea5-4b79-c1ed-136ddd41153e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "X_train = np.random.random((100, 100, 100, 3))\n",
        "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
        "X_test = np.random.random((20, 100, 100, 3))\n",
        "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "def cnn_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
        "# this applies 32 convolution filters of size 3x3 each.\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(100, 100, 3)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (3, 3), activation=tf.nn.relu))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation=tf.nn.relu))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation=tf.nn.relu))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = cnn_model()\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=10)\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 5s 50ms/sample - loss: 2.2897\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.3151\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.3100\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2882\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2574\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.3003\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2794\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 5s 49ms/sample - loss: 2.2688\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2722\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 5s 49ms/sample - loss: 2.2781\n",
            "20/20 [==============================] - 0s 15ms/sample - loss: 2.3009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFahUvtn6JXL",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Neural Network (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCTkprTVObEh"
      },
      "source": [
        "### Recurrent Neural Network (LSTM) for Regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HhjGHgX6ObEi",
        "outputId": "6edffa0f-b69b-4791-ed69-8756cd08bf65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
        "\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14480, 4)\n",
            "(14480,)\n",
            "(7133, 4)\n",
            "(7133,)\n",
            "(14480, 1, 4)\n",
            "(14480,)\n",
            "(7133, 1, 4)\n",
            "(7133,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1yOS2w5xObEj",
        "outputId": "2183b9ae-2bf3-46cc-8a1a-eb95dc83d04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def lstm_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.LSTM(128,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.LSTM(32))\n",
        "    model.add(layers.Dense(1))  \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),loss = \"mse\",metrics =[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = lstm_model()\n",
        "model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0616 17:49:14.839148 140373151274880 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/10\n",
            "14480/14480 [==============================] - 7s 481us/sample - loss: 416599474139.7923 - acc: 0.0000e+00 - val_loss: 446471973033.6857 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "14480/14480 [==============================] - 5s 365us/sample - loss: 416586449457.2199 - acc: 0.0000e+00 - val_loss: 446459547576.2209 - val_acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "14480/14480 [==============================] - 5s 354us/sample - loss: 416574177243.7923 - acc: 0.0000e+00 - val_loss: 446447106407.7567 - val_acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "14480/14480 [==============================] - 5s 360us/sample - loss: 416561902025.1227 - acc: 0.0000e+00 - val_loss: 446434691070.5644 - val_acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "14480/14480 [==============================] - 5s 359us/sample - loss: 416549629775.4873 - acc: 0.0000e+00 - val_loss: 446422231067.2761 - val_acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "14480/14480 [==============================] - 5s 352us/sample - loss: 416537372769.3083 - acc: 0.0000e+00 - val_loss: 446409802667.4443 - val_acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "14480/14480 [==============================] - 5s 355us/sample - loss: 416525070177.5911 - acc: 0.0000e+00 - val_loss: 446397377657.8809 - val_acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "14480/14480 [==============================] - 5s 347us/sample - loss: 416512829754.5547 - acc: 0.0000e+00 - val_loss: 446384939176.8243 - val_acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "14480/14480 [==============================] - 5s 351us/sample - loss: 416500522129.9624 - acc: 0.0000e+00 - val_loss: 446372482660.2753 - val_acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "14480/14480 [==============================] - 5s 334us/sample - loss: 416488261901.2950 - acc: 0.0000e+00 - val_loss: 446360081168.9758 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[119.00605],\n",
              "       [119.00605],\n",
              "       [119.00605],\n",
              "       ...,\n",
              "       [119.00605],\n",
              "       [119.00605],\n",
              "       [119.00605]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScnDrGeBpi8p",
        "colab_type": "text"
      },
      "source": [
        "## Frameworks (Deep Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d74w-SsfpqX0",
        "colab_type": "text"
      },
      "source": [
        "### Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mu4ovjTvmQX",
        "colab_type": "text"
      },
      "source": [
        "What is Tensorflow?\n",
        "\n",
        "TensorFlow is an end-to-end open source platform for machine learning\n",
        "\n",
        "TensorFlow makes it easy for beginners and experts to create machine learning models. See the sections below to get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MXi2dVisqpE",
        "colab_type": "text"
      },
      "source": [
        "#### Importing Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtPFxwnKqegy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1b5239f-f67b-48ba-fbe0-33e6669fd607"
      },
      "source": [
        "#!pip install tensorflow==2.0.0b1\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iHuobprscqY",
        "colab_type": "text"
      },
      "source": [
        "#### Eager Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2lqO8Knqmdc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1c2f87d-befc-4de5-b264-d77e2fc37d44"
      },
      "source": [
        "# The Code Compiles and will be executed in eager mode\n",
        "\n",
        "h=tf.constant(\"Hello\")\n",
        "w=tf.constant(\"World\")\n",
        "\n",
        "tf.strings.join([h,w])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=2, shape=(), dtype=string, numpy=b'HelloWorld'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgYGnpNQsidj",
        "colab_type": "text"
      },
      "source": [
        "#### Graph Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC0o-kwkqpQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "241ee148-baa5-4fd4-9da7-a2a84b91c69f"
      },
      "source": [
        "# The Code Compiles inside the Function (@tf.function) into graph code before it is executed\n",
        "\n",
        "import tensorflow as tf\n",
        "h=tf.constant(\"Hello\")\n",
        "w=tf.constant(\"World\")\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def concat(x,y):\n",
        "    hw = x + y\n",
        "    return hw\n",
        "\n",
        "print(concat(h,w))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'HelloWorld', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04-GIRKrS5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9698aac7-df62-4a24-dbe1-5ffe076021c5"
      },
      "source": [
        "# The Code Compiles and will not be executed in graph mode\n",
        "def concat(x,y):\n",
        "    hw = x + y\n",
        "    return hw\n",
        "\n",
        "print(concat(h,w))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'HelloWorld', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvbObk4brV8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a2750447-b9bb-4a13-b29f-3773a035151a"
      },
      "source": [
        "W = tf.Variable(tf.zeros(shape=(2,2)), name=\"W\")\n",
        "b = tf.Variable(tf.ones(shape=(2)), name=\"b\")\n",
        "\n",
        "@tf.function\n",
        "def forward(x):\n",
        "    return W * x + b\n",
        "\n",
        "output = forward([1,0])\n",
        "print(output)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y6FexD2rYqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d13c54b2-3db9-4c5f-91ee-6ca47777b3d2"
      },
      "source": [
        "W = tf.Variable(1, name=\"W\")\n",
        "b = tf.Variable(5, name=\"b\")\n",
        "\n",
        "@tf.function\n",
        "def forward(x):\n",
        "    return W * x + b\n",
        "\n",
        "output = forward(4)\n",
        "print(output)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqtk3_2arb3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4066f2e8-574a-46a2-ed5e-6d698868a707"
      },
      "source": [
        "W.numpy()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8wsidmurfWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r1 = tf.reshape(W,[1,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J0ksXSZrlE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "823adf08-d0c7-443e-a12b-863c3218e568"
      },
      "source": [
        "r1.numpy()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHpr14iRpuM-",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuLSr0UvvD6J",
        "colab_type": "text"
      },
      "source": [
        "What  is Pytorch?\n",
        "\n",
        "It’s a Python-based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "A replacement for NumPy to use the power of GPUs\n",
        "a deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng69EaiRuJIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dn2DyQCuKEX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "881a4245-ef97-4156-de45-098ed94e5acc"
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.7127e-36, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n",
            "        [9.2198e-39, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWE68deQuPtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4db3d77b-5448-4329-b67d-6632a40a0159"
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3183, 0.0442, 0.3516],\n",
            "        [0.9268, 0.0550, 0.2144],\n",
            "        [0.8796, 0.3361, 0.6043],\n",
            "        [0.6161, 0.7851, 0.8815],\n",
            "        [0.2953, 0.3483, 0.0673]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHjXIxj9uZhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f1502571-21b0-4b22-ba6c-b81bde1c079c"
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIWDQrP2udrd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0c7ec88-1fe6-436b-de28-3daba06b042d"
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx236rVDuhec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4a9e2bda-6833-4ec4-bf12-d70f7ef77786"
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)    \n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvdiXePYuoxN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ece5ccb4-5d16-47d9-82ab-351ca5262f75"
      },
      "source": [
        "x = torch.randn_like(x, dtype=torch.float) \n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0069, -0.2150,  0.8116],\n",
            "        [-0.4522,  1.1726, -0.3885],\n",
            "        [-0.1883, -1.3238,  1.5475],\n",
            "        [ 1.6086, -0.4931,  0.2757],\n",
            "        [-0.3276, -0.2421,  0.5482]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTRwYsuqu1q0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fb1b990-8515-451e-aa06-03650c2eeb19"
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFR60upIu79B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ee61148a-a7bd-4284-bebf-4cabf5886fbf"
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8492, 1.1307, 1.0533],\n",
            "        [0.6561, 0.8633, 1.4646],\n",
            "        [0.9527, 1.4221, 1.1873],\n",
            "        [1.7161, 1.5844, 1.0095],\n",
            "        [0.4096, 1.1961, 1.3020]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxlAzvDvv7Z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9a990d4e-78d1-4e72-f19a-6a52877c8686"
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8492, 1.1307, 1.0533],\n",
            "        [0.6561, 0.8633, 1.4646],\n",
            "        [0.9527, 1.4221, 1.1873],\n",
            "        [1.7161, 1.5844, 1.0095],\n",
            "        [0.4096, 1.1961, 1.3020]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqI5TPvXwErS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "19230e9d-f8f3-4b1a-d847-186503785bbb"
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8492, 1.1307, 1.0533],\n",
            "        [0.6561, 0.8633, 1.4646],\n",
            "        [0.9527, 1.4221, 1.1873],\n",
            "        [1.7161, 1.5844, 1.0095],\n",
            "        [0.4096, 1.1961, 1.3020]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Q1TEoJwYOL",
        "colab_type": "text"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use torch.view :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gXr7VPEwFUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a17763d-e08c-478d-bd4f-f6afcde6b41f"
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brxtim1TwTt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55b1b39b-f1b4-45fa-af9a-82f7dd1ab5e1"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "\n",
        "np.add(a, 1, out=a)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ0ttGvhxJE0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "bba26f61-22b4-4a80-b4a3-79e8777b723c"
      },
      "source": [
        "device = torch.device(\"cuda\")          # a CUDA device object\n",
        "y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "z = x + y\n",
        "print(z)\n",
        "print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4023,  1.3189,  1.7710,  1.6037],\n",
            "        [-0.2375,  1.5496,  0.9762,  1.9441],\n",
            "        [-0.7012, -1.6130,  1.1936, -0.2889],\n",
            "        [-0.1726,  0.5142,  0.8320,  2.0435]], device='cuda:0')\n",
            "tensor([[ 0.4023,  1.3189,  1.7710,  1.6037],\n",
            "        [-0.2375,  1.5496,  0.9762,  1.9441],\n",
            "        [-0.7012, -1.6130,  1.1936, -0.2889],\n",
            "        [-0.1726,  0.5142,  0.8320,  2.0435]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9oV9gj8Sd9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44e64286-85e2-4742-d62e-0899916a6ae5"
      },
      "source": [
        "x = torch.empty(1,5)\n",
        "x = x.new_ones(1,5,requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVUKSJ58TgIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8134f44e-54d0-4a0b-87c8-a58cba7aa7cc"
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3., 3., 3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKlanh40Tlwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ef54383-1832-4bb8-dd37-90e311c68d76"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7feb3e3ccd30>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1hBk80JTq7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dfb0eb89-d0f8-4caf-d40c-c6cb9100e5a2"
      },
      "source": [
        "z = y.mean()\n",
        "print(z)\n",
        "print(z.backward())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3., grad_fn=<MeanBackward0>)\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp33QE7sURtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7471bdd-ba05-4909-be25-c76e4d5fa075"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr0EE3OYpwiM",
        "colab_type": "text"
      },
      "source": [
        "### Caffe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLK6nnZS932v",
        "colab_type": "text"
      },
      "source": [
        "# (Data Visualizations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXNM3g4Y-NIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f70dba-1aae-445a-bcd6-d23d73ea1b19"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaboarn as sns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c1bb61312bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaboarn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaboarn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9EePLg8-ZKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z_cGCgDrObBN"
      },
      "source": [
        "# Neuro-linguistic programming (NLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "864O-bK8ObBO",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    input='content',\n",
        "    encoding='utf-8',\n",
        "    decode_error='strict',\n",
        "    strip_accents=None,\n",
        "    lowercase=True,\n",
        "    preprocessor=None,\n",
        "    tokenizer=None,\n",
        "    stop_words=None,\n",
        "    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
        "    ngram_range=(1, 1),\n",
        "    analyzer='word',\n",
        "    max_df=1.0,\n",
        "    min_df=1,\n",
        "    max_features=None,\n",
        "    vocabulary=None,\n",
        "    binary=False,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ym76sSuBObBQ",
        "outputId": "e71746bf-e9be-4b0d-b1d6-4a9dae2b29fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "corpus = ['This is an example of NLP',\n",
        "          'This is the first document.',\n",
        "          'And the second one.',\n",
        "          'Is this the first document?']\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "X    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x12 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 20 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mXCp3TN6ObBU",
        "outputId": "86810646-5489-415d-b0c6-cfc5e0a6780d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "analyze = vectorizer.build_analyzer()\n",
        "analyze(\"This is a text document to analyze.\") == (['this', 'is', 'text', 'document', 'analyze'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OftttK-PObBW",
        "outputId": "5358770f-3cbf-473d-9104-c4ee9f8aacfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "vectorizer.get_feature_names()\n",
        "X.toarray()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x1Dh_cpwObBY",
        "outputId": "e2565d8b-9395-4bc5-ac3d-4039d2402435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vectorizer.transform(['Something completely new.']).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6MewG2mHObBb",
        "outputId": "471a76db-fcbd-40f8-f028-b06baef20d5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),\n",
        "                                     token_pattern=r'\\b\\w+\\b', min_df=1)\n",
        "analyze = bigram_vectorizer.build_analyzer()\n",
        "analyze('Bi-grams are cool!') == (['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rqg0t56yObBe",
        "outputId": "6fb6a8bc-f3e1-41e4-f8b5-548be9dd1a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X2 = bigram_vectorizer.fit_transform(corpus).toarray()\n",
        "X2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "        0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "        1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "61OekX4MObBj",
        "outputId": "72ef1934-21d8-4a97-f7a7-7e229c66acdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "\n",
        "TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False,\n",
        "                 use_idf=True)\n",
        "\n",
        "tfidf = transformer.fit_transform(X.toarray())\n",
        "tfidf.toarray() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.46714844, 0.        , 0.        , 0.46714844, 0.        ,\n",
              "        0.25208067, 0.46714844, 0.46714844, 0.        , 0.        ,\n",
              "        0.        , 0.25208067],\n",
              "       [0.        , 0.        , 0.51741994, 0.        , 0.51741994,\n",
              "        0.3935112 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3935112 , 0.3935112 ],\n",
              "       [0.        , 0.55121857, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.55121857, 0.55121857,\n",
              "        0.29744623, 0.        ],\n",
              "       [0.        , 0.        , 0.51741994, 0.        , 0.51741994,\n",
              "        0.3935112 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3935112 , 0.3935112 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tCf6J99mObBn",
        "outputId": "654f1a4f-e363-4b9c-a0f7-04118af73966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
        "counts = ngram_vectorizer.fit_transform(['words', 'wprds'])\n",
        "ngram_vectorizer.get_feature_names() == ([' w', 'ds', 'or', 'pr', 'rd', 's ', 'wo', 'wp'])\n",
        "\n",
        "counts.toarray().astype(int)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 1, 1, 1, 0],\n",
              "       [1, 1, 0, 1, 1, 1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CGuNGLTCObBp",
        "outputId": "1e2ebd2f-bb4d-47b1-ad28-3d819b0564b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(5, 5))\n",
        "ngram_vectorizer.fit_transform(['jumpy fox'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x4 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 4 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GcXic02dObBr"
      },
      "source": [
        "## Vader Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xhg1U3L-ObBs",
        "outputId": "2f111793-c03a-4516-ceeb-9d1a83df8e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sentences = [\"The food was good.\",\n",
        "             \"The service was not very good!\", \n",
        "             \"Not bad at all\",\n",
        "             \"The service was horrible\"]\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "for sentence in sentences:\n",
        "    vs = analyzer.polarity_scores(sentence)\n",
        "    print(\"{:-<50} {}\".format(sentence, str(vs)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n",
            "The food was good.-------------------------------- {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
            "The service was not very good!-------------------- {'neg': 0.368, 'neu': 0.632, 'pos': 0.0, 'compound': -0.4432}\n",
            "Not bad at all------------------------------------ {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n",
            "The service was horrible-------------------------- {'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "96g1Opq2ObBu"
      },
      "source": [
        "## Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SXGi9aZSObBv",
        "outputId": "c1cef993-06a6-4e4f-c9df-b359ed16cf00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "!pip install spacy\n",
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "\n",
        "# Process whole documents\n",
        "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
        "        \"Google in 2007, few people outside of the company took him \"\n",
        "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
        "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
        "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
        "        \"this week.\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Analyze syntax\n",
        "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
        "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
        "\n",
        "# Find named entities, phrases and concepts\n",
        "\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.4)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.6.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy) (4.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
            "Verbs: ['start', 'work', 'drive', 'take', 'can', 'tell', 'would', 'shake', 'turn', 'be', 'talk', 'say']\n",
            "Sebastian Thrun PERSON\n",
            "Google ORG\n",
            "2007 DATE\n",
            "American NORP\n",
            "Thrun PERSON\n",
            "Recode ORG\n",
            "earlier this week DATE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ax8C7TJEObBy",
        "outputId": "a92a702a-64ba-48fe-8d69-ba216dfc92b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vqKXW_CdObBz",
        "outputId": "0c087014-06f6-4688-957b-c92299ffba3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple\n",
            "is\n",
            "looking\n",
            "at\n",
            "buying\n",
            "U.K.\n",
            "startup\n",
            "for\n",
            "$\n",
            "1\n",
            "billion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YH4TLd5XObB1",
        "outputId": "95d26ff9-f155-490e-83c0-0f404fb3bbef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "prefix_re = re.compile(r'''^[[(\"']''')\n",
        "suffix_re = re.compile(r'''[])\"']$''')\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "simple_url_re = re.compile(r'''^https?://''')\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
        "                                suffix_search=suffix_re.search,\n",
        "                                infix_finditer=infix_re.finditer,\n",
        "                                token_match=simple_url_re.match)\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n",
        "doc = nlp(u\"hello-world.\")\n",
        "\n",
        "print([t.text for t in doc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello', '-', 'world.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7XkQhjFsObB3",
        "outputId": "15285b24-cc7e-4745-edd4-92787218406b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "doc = nlp(\"I live in New York\")\n",
        "\n",
        "print(\"Before:\", [token.text for token in doc])\n",
        "\n",
        "with doc.retokenize() as retokenizer:\n",
        "    retokenizer.merge(doc[3:5], attrs={\"LEMMA\": \"new york\"})\n",
        "    \n",
        "print(\"After:\", [token.text for token in doc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before: ['I', 'live', 'in', 'New', 'York']\n",
            "After: ['I', 'live', 'in', 'New York']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-8ZcdbCObB6",
        "outputId": "12d2f7d5-1274-45f8-b851-7d8f17a5a180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "doc = nlp(u\"This is a sentence. This is another sentence.\")\n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a sentence.\n",
            "This is another sentence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vVqamYu8ObB8",
        "outputId": "6bab806c-e59c-4ba3-b25d-8ed25d7037fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from spacy.lang.en import English\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = English()  # We only want the tokenizer, so no need to load a model\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "pos_emoji = [u\"😀\", u\"😃\", u\"😂\", u\"🤣\", u\"😊\", u\"😍\"]  # Positive emoji\n",
        "neg_emoji = [u\"😞\", u\"😠\", u\"😩\", u\"😢\", u\"😭\", u\"😒\"]  # Negative emoji\n",
        "\n",
        "# Add patterns to match one or more emoji tokens\n",
        "pos_patterns = [[{\"ORTH\": emoji}] for emoji in pos_emoji]\n",
        "neg_patterns = [[{\"ORTH\": emoji}] for emoji in neg_emoji]\n",
        "\n",
        "# Function to label the sentiment\n",
        "def label_sentiment(matcher, doc, i, matches):\n",
        "    match_id, start, end = matches[i]\n",
        "    if doc.vocab.strings[match_id] == \"HAPPY\":  # Don't forget to get string!\n",
        "        doc.sentiment += 0.1  # Add 0.1 for positive sentiment\n",
        "    elif doc.vocab.strings[match_id] == \"SAD\":\n",
        "        doc.sentiment -= 0.1  # Subtract 0.1 for negative sentiment\n",
        "\n",
        "matcher.add(\"HAPPY\", label_sentiment, *pos_patterns)  # Add positive pattern\n",
        "matcher.add(\"SAD\", label_sentiment, *neg_patterns)  # Add negative pattern\n",
        "\n",
        "# Add pattern for valid hashtag, i.e. '#' plus any ASCII token\n",
        "matcher.add(\"HASHTAG\", None, [{\"ORTH\": \"#\"}, {\"IS_ASCII\": True}])\n",
        "\n",
        "doc = nlp(u\"Hello world 😀 #MondayMotivation\")\n",
        "matches = matcher(doc)\n",
        "for match_id, start, end in matches:\n",
        "    string_id = doc.vocab.strings[match_id]  # Look up string ID\n",
        "    span = doc[start:end]\n",
        "    print(string_id, span.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HAPPY 😀\n",
            "HASHTAG #MondayMotivation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "omAbFScpObB-",
        "outputId": "5f6263e1-6f77-4b94-db1c-494531accdbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "doc = nlp(\"Dr Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Alex Smith', 'PERSON'), ('first', 'ORDINAL'), ('Acme Corp Inc.', 'ORG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l-U3ecwVObCA",
        "outputId": "12a35b94-c64e-4772-bbeb-9e2c89e7861d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "import spacy\n",
        "from spacy.pipeline import merge_entities\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "\n",
        "def extract_person_orgs(doc):\n",
        "    person_entities = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "    for ent in person_entities:\n",
        "        head = ent.root.head\n",
        "        if head.lemma_ == \"work\":\n",
        "            preps = [token for token in head.children if token.dep_ == \"prep\"]\n",
        "            for prep in preps:\n",
        "                orgs = [token for token in prep.children if token.ent_type_ == \"ORG\"]\n",
        "                print({'person': ent, 'orgs': orgs, 'past': head.tag_ == \"VBD\"})\n",
        "    return doc\n",
        "\n",
        "# To make the entities easier to work with, we'll merge them into single tokens\n",
        "nlp.add_pipe(merge_entities)\n",
        "nlp.add_pipe(extract_person_orgs)\n",
        "\n",
        "doc = nlp(\"Alex Smith worked at Acme Corp Inc.\")\n",
        "# If you're not in a Jupyter / IPython environment, use displacy.serve\n",
        "displacy.render(doc, options={'fine_grained': True})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'person': Alex Smith, 'orgs': [Acme Corp Inc.], 'past': True}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"61ef71ef3d4248f4996491a946b1ace0-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Alex Smith</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NNP</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">worked</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VBD</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">at</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">IN</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Acme Corp Inc.</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NNP</tspan>\\n</text>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-61ef71ef3d4248f4996491a946b1ace0-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-61ef71ef3d4248f4996491a946b1ace0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-61ef71ef3d4248f4996491a946b1ace0-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-61ef71ef3d4248f4996491a946b1ace0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-61ef71ef3d4248f4996491a946b1ace0-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-61ef71ef3d4248f4996491a946b1ace0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\\n</g>\\n</svg>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bublqtX5ObCB",
        "outputId": "71b86262-9b5e-492b-b530-7392a054c20c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "text = \"\"\"But Google is starting from behind. The company made a late push\n",
        "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
        "software, which runs on its Echo and Dot devices, have clear leads in\n",
        "consumer adoption.\"\"\"\n",
        "\n",
        "nlp = spacy.load(\"en\")\n",
        "doc = nlp(text)\n",
        "displacy.serve(doc, style=\"ent\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_MHy51afObCD"
      },
      "source": [
        "## NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Oc0_AxXZObCD",
        "outputId": "2545e0eb-4895-467f-9066-6397b4dfc6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "   \n",
        "ps = PorterStemmer() \n",
        "  \n",
        "# choose some words to be stemmed \n",
        "words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \n",
        "  \n",
        "for w in words: \n",
        "    print(w, \" : \", ps.stem(w)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "program  :  program\n",
            "programs  :  program\n",
            "programer  :  program\n",
            "programing  :  program\n",
            "programers  :  program\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "py6XbQ36ObCF",
        "outputId": "371a0ec6-575e-4c16-9706-80132169eb4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "   \n",
        "ps = PorterStemmer() \n",
        "   \n",
        "sentence = \"Programers program with programing languages\"\n",
        "words = word_tokenize(sentence) \n",
        "   \n",
        "for w in words: \n",
        "    print(w, \" : \", ps.stem(w)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Programers  :  program\n",
            "program  :  program\n",
            "with  :  with\n",
            "programing  :  program\n",
            "languages  :  languag\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JTOYTn3QObCK",
        "outputId": "0bd30b59-8ff3-4643-d073-72de52ad4578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import random \n",
        "from nltk.corpus import names \n",
        "import nltk \n",
        "nltk.download('names')\n",
        "  \n",
        "def gender_features(word): \n",
        "    return {'last_letter':word[-1]} \n",
        "  \n",
        "# preparing a list of examples and corresponding class labels. \n",
        "labeled_names = ([(name, 'male') for name in names.words('male.txt')]+\n",
        "             [(name, 'female') for name in names.words('female.txt')]) \n",
        "  \n",
        "random.shuffle(labeled_names) \n",
        "  \n",
        "# we use the feature extractor to process the names data. \n",
        "featuresets = [(gender_features(n), gender)  \n",
        "               for (n, gender)in labeled_names] \n",
        "  \n",
        "# Divide the resulting list of feature \n",
        "# sets into a training set and a test set. \n",
        "train_set, test_set = featuresets[500:], featuresets[:500] \n",
        "  \n",
        "# The training set is used to  \n",
        "# train a new \"naive Bayes\" classifier. \n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
        "  \n",
        "print(classifier.classify(gender_features('Myron'))) \n",
        "  \n",
        "# output should be 'male' \n",
        "print(nltk.classify.accuracy(classifier, train_set)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n",
            "male\n",
            "0.7634336378291241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YDCHJb5iObCM",
        "outputId": "429e5ad1-7e6b-408c-858b-591d2a65448d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "classifier.show_most_informative_features(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'a'            female : male   =     36.5 : 1.0\n",
            "             last_letter = 'k'              male : female =     32.4 : 1.0\n",
            "             last_letter = 'f'              male : female =     16.1 : 1.0\n",
            "             last_letter = 'p'              male : female =     11.3 : 1.0\n",
            "             last_letter = 'v'              male : female =     10.6 : 1.0\n",
            "             last_letter = 'd'              male : female =     10.1 : 1.0\n",
            "             last_letter = 'm'              male : female =      9.6 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.6 : 1.0\n",
            "             last_letter = 'r'              male : female =      6.6 : 1.0\n",
            "             last_letter = 'w'              male : female =      5.4 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bTAo2IYbObDv",
        "outputId": "fb20226c-d8a0-4c85-851a-0e53e8ec209d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('wordnet')  \n",
        "lemmatizer = WordNetLemmatizer() \n",
        "  \n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
        "  \n",
        "# a denotes adjective in \"pos\" \n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YDATTLs8ObDw"
      },
      "source": [
        "## TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zs-4OueQObDx",
        "outputId": "9eabe4ce-a22e-4a5f-e9c3-4338fd2a311f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('brown')\n",
        " \n",
        "text = \"The service was good\"\n",
        "\n",
        "blob = TextBlob(text)\n",
        "blob.tags          \n",
        "\n",
        "blob.noun_phrases   \n",
        "for sentence in blob.sentences:\n",
        "    print(sentence.sentiment.polarity)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g3eXb6KdObDz",
        "outputId": "6dd3d554-a948-4d56-f628-91d734ac6c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from textblob import Word\n",
        "w = Word('falibility')\n",
        "w.spellcheck()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fallibility', 1.0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "43WlBL-tObD0",
        "outputId": "bdc7e445-7aa0-4d7b-e5db-c84e63d2f4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "en_blob = TextBlob(u'Good Morning')\n",
        "print(en_blob.translate(to='es'))\n",
        "print(en_blob.translate(to='fr'))\n",
        "print(en_blob.translate(to='zh-CN'))\n",
        "print(en_blob.translate(to='ar'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buenos días\n",
            "Bonjour\n",
            "早上好\n",
            "صباح الخير\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NPB4VPnyObD2",
        "outputId": "d6a47109-a964-4be7-ec4d-22ea480ee208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "b = TextBlob(u\"بسيط هو أفضل من مجمع\")\n",
        "b.detect_language()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0UjbZuKJObD4",
        "outputId": "13b2ca05-d818-4871-f973-e4636b875520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "blob = TextBlob(\"Now is better than never.\")\n",
        "blob.ngrams(n=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WordList(['Now', 'is', 'better']),\n",
              " WordList(['is', 'better', 'than']),\n",
              " WordList(['better', 'than', 'never'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "77avOTNWObD6",
        "outputId": "3f181dbe-a60e-4940-c666-7c1cd327a172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from textblob import Word\n",
        "from textblob.wordnet import VERB\n",
        "word = Word(\"octopus\")\n",
        "word.synsets\n",
        "Word(\"hack\").get_synsets(pos=VERB)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('chop.v.05'),\n",
              " Synset('hack.v.02'),\n",
              " Synset('hack.v.03'),\n",
              " Synset('hack.v.04'),\n",
              " Synset('hack.v.05'),\n",
              " Synset('hack.v.06'),\n",
              " Synset('hack.v.07'),\n",
              " Synset('hack.v.08')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n6h9Ma-3ObD8",
        "outputId": "1f14b50c-f2a4-4587-d970-57c0755ef702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        " Word(\"rain\").definitions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['water falling in drops from vapor condensed in the atmosphere',\n",
              " 'drops of fresh water that fall as precipitation from clouds',\n",
              " 'anything happening rapidly or in quick successive',\n",
              " 'precipitate as rain']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D3hMYdWosj5",
        "colab_type": "text"
      },
      "source": [
        "## Google Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FceEkwcco1TP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cad05474-0571-4c21-cb74-2427dbf3ee83"
      },
      "source": [
        "#!pip install googletrans\n",
        "from googletrans import Translator\n",
        "translator = Translator(service_urls=[\n",
        "      'translate.google.com',\n",
        "      'translate.google.co.uk',\n",
        "      'translate.google.co.in'\n",
        "    ])\n",
        "translations = translator.translate(['صباح الخير', '早上好', 'Buenos días'], dest='en')\n",
        "for translation in translations:\n",
        "    print(translation.origin, ' -> ', translation.text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "صباح الخير  ->  good morning\n",
            "早上好  ->  Good morning\n",
            "Buenos días  ->  Good Morning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJxGQ-gipENU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46b6d2b0-efab-47d7-c450-8668b111851a"
      },
      "source": [
        "from googletrans import Translator\n",
        "translator = Translator(service_urls=[\n",
        "      'translate.google.com',\n",
        "      'translate.google.co.uk',\n",
        "      'translate.google.co.in'\n",
        "    ])\n",
        "translations = translator.translate('안녕하세요', dest='ja')\n",
        "print(translations)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translated(src=ko, dest=ja, text=こんにちは, pronunciation=Kon'nichiwa, extra_data=\"{'translat...\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGMBFv5DpFuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25e8cd9a-085b-41be-d285-e06d5156be99"
      },
      "source": [
        "a = translator.detect('안녕하세요')\n",
        "print(a)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected(lang=ko, confidence=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szu7Ovv2pJ0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def google_translator(x):\n",
        "    translator = Translator()\n",
        "    translations=translator.translate(x, dest='en')\n",
        "    return translations.text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLMJuG20pNWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19d17364-bad0-4601-ca2e-cd04f7a01a29"
      },
      "source": [
        "a = google_translator('안녕하세요')\n",
        "print(a)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWBVFp5Q5IEE",
        "colab_type": "text"
      },
      "source": [
        "# Ethical AI (Detecting Bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lFr0XvElObEl"
      },
      "source": [
        "## Microsofts Model Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n9vChjzMObEm",
        "outputId": "322626ec-0d49-4ba8-dec0-e67516a7c39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!pip install interpret\n",
        "from interpret.glassbox import LinearRegression\n",
        "\n",
        "ebm = LinearRegression()\n",
        "ebm.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<interpret.glassbox.linear.LinearRegression at 0x7faa8b2e9240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bMETx3n6ObEn",
        "outputId": "c145ab23-c62c-4145-bcd9-e6e9181c1fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "from interpret import show\n",
        "\n",
        "ebm_global = ebm.explain_global()\n",
        "show(ebm_global)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!-- http://127.0.0.1:7554/140370454905744/ -->\n",
              "<iframe src=\"http://127.0.0.1:7554/140370454905744/\" width=100% height=800 frameBorder=\"0\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IXyrP-fvObEp",
        "outputId": "f7b215b0-ff7c-4c86-de07-74237a9f9e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "ebm_local = ebm.explain_local(X_test, y_test)\n",
        "show(ebm_local)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<!-- http://127.0.0.1:7554/140370458563976/ -->\n",
              "<iframe src=\"http://127.0.0.1:7554/140370458563976/\" width=100% height=800 frameBorder=\"0\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ixxaSvvNObEr",
        "outputId": "ae019085-e083-458d-afae-4464b3744d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "#!pip install xai\n",
        "import xai.data\n",
        "df = xai.data.pd.read_csv(\"kc_house_data.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7129300520</td>\n",
              "      <td>20141013T000000</td>\n",
              "      <td>221900.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1180</td>\n",
              "      <td>5650</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1180</td>\n",
              "      <td>0</td>\n",
              "      <td>1955</td>\n",
              "      <td>0</td>\n",
              "      <td>98178</td>\n",
              "      <td>47.5112</td>\n",
              "      <td>-122.257</td>\n",
              "      <td>1340</td>\n",
              "      <td>5650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6414100192</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>538000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2570</td>\n",
              "      <td>7242</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2170</td>\n",
              "      <td>400</td>\n",
              "      <td>1951</td>\n",
              "      <td>1991</td>\n",
              "      <td>98125</td>\n",
              "      <td>47.7210</td>\n",
              "      <td>-122.319</td>\n",
              "      <td>1690</td>\n",
              "      <td>7639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5631500400</td>\n",
              "      <td>20150225T000000</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>770</td>\n",
              "      <td>10000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>770</td>\n",
              "      <td>0</td>\n",
              "      <td>1933</td>\n",
              "      <td>0</td>\n",
              "      <td>98028</td>\n",
              "      <td>47.7379</td>\n",
              "      <td>-122.233</td>\n",
              "      <td>2720</td>\n",
              "      <td>8062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2487200875</td>\n",
              "      <td>20141209T000000</td>\n",
              "      <td>604000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1960</td>\n",
              "      <td>5000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>1050</td>\n",
              "      <td>910</td>\n",
              "      <td>1965</td>\n",
              "      <td>0</td>\n",
              "      <td>98136</td>\n",
              "      <td>47.5208</td>\n",
              "      <td>-122.393</td>\n",
              "      <td>1360</td>\n",
              "      <td>5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954400510</td>\n",
              "      <td>20150218T000000</td>\n",
              "      <td>510000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1680</td>\n",
              "      <td>8080</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1680</td>\n",
              "      <td>0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0</td>\n",
              "      <td>98074</td>\n",
              "      <td>47.6168</td>\n",
              "      <td>-122.045</td>\n",
              "      <td>1800</td>\n",
              "      <td>7503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id             date     price  ...     long  sqft_living15  sqft_lot15\n",
              "0  7129300520  20141013T000000  221900.0  ... -122.257           1340        5650\n",
              "1  6414100192  20141209T000000  538000.0  ... -122.319           1690        7639\n",
              "2  5631500400  20150225T000000  180000.0  ... -122.233           2720        8062\n",
              "3  2487200875  20141209T000000  604000.0  ... -122.393           1360        5000\n",
              "4  1954400510  20150218T000000  510000.0  ... -122.045           1800        7503\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y6oMh45AObEt",
        "outputId": "20a8c1f9-bbba-442e-b286-02da964ccc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "ims = xai.imbalance_plot(df, \"grade\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0616 17:55:52.548324 140373151274880 __init__.py:991] No categorical_cols passed so inferred using np.object, np.int8 and np.bool: Index(['date'], dtype='object'). If you see an error these are not correct, please provide them as a string array as: categorical_cols=['col1', 'col2', ...]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAE6CAYAAAD9Sp7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2rNgvGWfObEu",
        "outputId": "d652b17b-9cbd-463c-df21-c7cc98e125dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "bal_df = xai.balance(df, \"grade\", upsample=0.8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAE6CAYAAAD9Sp7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlvL/AZqxpOZ3Kt+VAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ZzIOUP97V4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}