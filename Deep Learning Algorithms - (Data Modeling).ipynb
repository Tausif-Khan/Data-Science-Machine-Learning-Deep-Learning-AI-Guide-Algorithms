{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning Algorithms.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myrondza/Data-Science-Machine-Learning-Deep-Learning-AI-Guide-Algorithms/blob/master/Deep_Learning_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSQOOMcQ4QIs",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScnDrGeBpi8p",
        "colab_type": "text"
      },
      "source": [
        "## Frameworks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d74w-SsfpqX0",
        "colab_type": "text"
      },
      "source": [
        "### Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mu4ovjTvmQX",
        "colab_type": "text"
      },
      "source": [
        "What is Tensorflow?\n",
        "\n",
        "TensorFlow is an end-to-end open source platform for machine learning\n",
        "\n",
        "TensorFlow makes it easy for beginners and experts to create machine learning models. See the sections below to get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MXi2dVisqpE",
        "colab_type": "text"
      },
      "source": [
        "#### Importing Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtPFxwnKqegy",
        "colab_type": "code",
        "outputId": "e1b5239f-f67b-48ba-fbe0-33e6669fd607",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!pip install tensorflow==2.0.0b1\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iHuobprscqY",
        "colab_type": "text"
      },
      "source": [
        "#### Eager Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2lqO8Knqmdc",
        "colab_type": "code",
        "outputId": "e1c2f87d-befc-4de5-b264-d77e2fc37d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The Code Compiles and will be executed in eager mode\n",
        "\n",
        "h=tf.constant(\"Hello\")\n",
        "w=tf.constant(\"World\")\n",
        "\n",
        "tf.strings.join([h,w])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=2, shape=(), dtype=string, numpy=b'HelloWorld'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgYGnpNQsidj",
        "colab_type": "text"
      },
      "source": [
        "#### Graph Mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC0o-kwkqpQ7",
        "colab_type": "code",
        "outputId": "241ee148-baa5-4fd4-9da7-a2a84b91c69f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The Code Compiles inside the Function (@tf.function) into graph code before it is executed\n",
        "\n",
        "import tensorflow as tf\n",
        "h=tf.constant(\"Hello\")\n",
        "w=tf.constant(\"World\")\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def concat(x,y):\n",
        "    hw = x + y\n",
        "    return hw\n",
        "\n",
        "print(concat(h,w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'HelloWorld', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C04-GIRKrS5A",
        "colab_type": "code",
        "outputId": "9698aac7-df62-4a24-dbe1-5ffe076021c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The Code Compiles and will not be executed in graph mode\n",
        "def concat(x,y):\n",
        "    hw = x + y\n",
        "    return hw\n",
        "\n",
        "print(concat(h,w))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'HelloWorld', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvbObk4brV8R",
        "colab_type": "code",
        "outputId": "a2750447-b9bb-4a13-b29f-3773a035151a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "W = tf.Variable(tf.zeros(shape=(2,2)), name=\"W\")\n",
        "b = tf.Variable(tf.ones(shape=(2)), name=\"b\")\n",
        "\n",
        "@tf.function\n",
        "def forward(x):\n",
        "    return W * x + b\n",
        "\n",
        "output = forward([1,0])\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]], shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y6FexD2rYqf",
        "colab_type": "code",
        "outputId": "d13c54b2-3db9-4c5f-91ee-6ca47777b3d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W = tf.Variable(1, name=\"W\")\n",
        "b = tf.Variable(5, name=\"b\")\n",
        "\n",
        "@tf.function\n",
        "def forward(x):\n",
        "    return W * x + b\n",
        "\n",
        "output = forward(4)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqtk3_2arb3A",
        "colab_type": "code",
        "outputId": "4066f2e8-574a-46a2-ed5e-6d698868a707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "W.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8wsidmurfWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r1 = tf.reshape(W,[1,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J0ksXSZrlE8",
        "colab_type": "code",
        "outputId": "823adf08-d0c7-443e-a12b-863c3218e568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r1.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHpr14iRpuM-",
        "colab_type": "text"
      },
      "source": [
        "### Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuLSr0UvvD6J",
        "colab_type": "text"
      },
      "source": [
        "What  is Pytorch?\n",
        "\n",
        "Itâ€™s a Python-based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "A replacement for NumPy to use the power of GPUs\n",
        "a deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng69EaiRuJIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dn2DyQCuKEX",
        "colab_type": "code",
        "outputId": "881a4245-ef97-4156-de45-098ed94e5acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3.7127e-36, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 0.0000e+00],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n",
            "        [9.2198e-39, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWE68deQuPtO",
        "colab_type": "code",
        "outputId": "4db3d77b-5448-4329-b67d-6632a40a0159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3183, 0.0442, 0.3516],\n",
            "        [0.9268, 0.0550, 0.2144],\n",
            "        [0.8796, 0.3361, 0.6043],\n",
            "        [0.6161, 0.7851, 0.8815],\n",
            "        [0.2953, 0.3483, 0.0673]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHjXIxj9uZhc",
        "colab_type": "code",
        "outputId": "f1502571-21b0-4b22-ba6c-b81bde1c079c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIWDQrP2udrd",
        "colab_type": "code",
        "outputId": "b0c7ec88-1fe6-436b-de28-3daba06b042d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx236rVDuhec",
        "colab_type": "code",
        "outputId": "4a9e2bda-6833-4ec4-bf12-d70f7ef77786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)    \n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvdiXePYuoxN",
        "colab_type": "code",
        "outputId": "ece5ccb4-5d16-47d9-82ab-351ca5262f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.randn_like(x, dtype=torch.float) \n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0069, -0.2150,  0.8116],\n",
            "        [-0.4522,  1.1726, -0.3885],\n",
            "        [-0.1883, -1.3238,  1.5475],\n",
            "        [ 1.6086, -0.4931,  0.2757],\n",
            "        [-0.3276, -0.2421,  0.5482]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTRwYsuqu1q0",
        "colab_type": "code",
        "outputId": "7fb1b990-8515-451e-aa06-03650c2eeb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFR60upIu79B",
        "colab_type": "code",
        "outputId": "ee61148a-a7bd-4284-bebf-4cabf5886fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8492, 1.1307, 1.0533],\n",
            "        [0.6561, 0.8633, 1.4646],\n",
            "        [0.9527, 1.4221, 1.1873],\n",
            "        [1.7161, 1.5844, 1.0095],\n",
            "        [0.4096, 1.1961, 1.3020]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxlAzvDvv7Z0",
        "colab_type": "code",
        "outputId": "9a990d4e-78d1-4e72-f19a-6a52877c8686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8492, 1.1307, 1.0533],\n",
            "        [0.6561, 0.8633, 1.4646],\n",
            "        [0.9527, 1.4221, 1.1873],\n",
            "        [1.7161, 1.5844, 1.0095],\n",
            "        [0.4096, 1.1961, 1.3020]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqI5TPvXwErS",
        "colab_type": "code",
        "outputId": "19230e9d-f8f3-4b1a-d847-186503785bbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8492, 1.1307, 1.0533],\n",
            "        [0.6561, 0.8633, 1.4646],\n",
            "        [0.9527, 1.4221, 1.1873],\n",
            "        [1.7161, 1.5844, 1.0095],\n",
            "        [0.4096, 1.1961, 1.3020]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Q1TEoJwYOL",
        "colab_type": "text"
      },
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use torch.view :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gXr7VPEwFUT",
        "colab_type": "code",
        "outputId": "2a17763d-e08c-478d-bd4f-f6afcde6b41f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brxtim1TwTt6",
        "colab_type": "code",
        "outputId": "55b1b39b-f1b4-45fa-af9a-82f7dd1ab5e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "\n",
        "np.add(a, 1, out=a)\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ0ttGvhxJE0",
        "colab_type": "code",
        "outputId": "bba26f61-22b4-4a80-b4a3-79e8777b723c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "device = torch.device(\"cuda\")          # a CUDA device object\n",
        "y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "z = x + y\n",
        "print(z)\n",
        "print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.4023,  1.3189,  1.7710,  1.6037],\n",
            "        [-0.2375,  1.5496,  0.9762,  1.9441],\n",
            "        [-0.7012, -1.6130,  1.1936, -0.2889],\n",
            "        [-0.1726,  0.5142,  0.8320,  2.0435]], device='cuda:0')\n",
            "tensor([[ 0.4023,  1.3189,  1.7710,  1.6037],\n",
            "        [-0.2375,  1.5496,  0.9762,  1.9441],\n",
            "        [-0.7012, -1.6130,  1.1936, -0.2889],\n",
            "        [-0.1726,  0.5142,  0.8320,  2.0435]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9oV9gj8Sd9J",
        "colab_type": "code",
        "outputId": "44e64286-85e2-4742-d62e-0899916a6ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.empty(1,5)\n",
        "x = x.new_ones(1,5,requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVUKSJ58TgIm",
        "colab_type": "code",
        "outputId": "8134f44e-54d0-4a0b-87c8-a58cba7aa7cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3., 3., 3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKlanh40Tlwx",
        "colab_type": "code",
        "outputId": "6ef54383-1832-4bb8-dd37-90e311c68d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7feb3e3ccd30>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1hBk80JTq7Q",
        "colab_type": "code",
        "outputId": "dfb0eb89-d0f8-4caf-d40c-c6cb9100e5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "z = y.mean()\n",
        "print(z)\n",
        "print(z.backward())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3., grad_fn=<MeanBackward0>)\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp33QE7sURtE",
        "colab_type": "code",
        "outputId": "b7471bdd-ba05-4909-be25-c76e4d5fa075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4000, 0.4000, 0.4000, 0.4000, 0.4000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3495hNF2ObD-"
      },
      "source": [
        "## Neural Networks (Layers , Activation Functions , Optimizers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-gm_xxyM79wo"
      },
      "source": [
        "### Vanishing Gradients Problem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NoHHUus779wq"
      },
      "source": [
        "What Are Vanishing Gradients?\n",
        "\n",
        "The vanishing gradients problem is one example of unstable behavior that you may encounter when training a deep neural network.\n",
        "\n",
        "It describes the situation where a deep multilayer feed-forward network or a recurrent neural network is unable to propagate useful **gradient information** from the **output end** of the model back to the layers near the **input end** of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DZcMr0Dh79ws"
      },
      "source": [
        "A problem with training networks with many layers (e.g. deep neural networks) is that the gradient diminishes dramatically as it is propagated backward through the network.\n",
        "\n",
        "The error may be so small by the time it reaches layers close to the input of the model that it may have **very little effect**\n",
        "\n",
        "Deep models using the hyperbolic tangent activation function do not train easily, and much of this poor performance is blamed on the vanishing gradient problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rd2l6F6P79w0"
      },
      "source": [
        "Deep models using the **hyperbolic tangent activation function** do not train easily, and much of this **poor performance** is blamed on the vanishing gradient problem.\n",
        "The number of hidden layers can be increased from 1 to 5\n",
        "\n",
        "\n",
        "How to Fix Vanishing Gradients?\n",
        "\n",
        "1) When using the **rectified linear activation** function (ReLU), it is good practice to use the He weight initialization scheme. We can define the MLP with five hidden layers using ReLU and He initialization, listed below.\n",
        "\n",
        "2 ) This is because the activation function looks and acts like a linear function, making it easier to train and less likely to saturate, but is, in fact, a nonlinear function, forcing negative inputs to the value 0. It is claimed as one possible approach to addressing the vanishing gradients problem when training deeper models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ST2cKjtT79w1"
      },
      "source": [
        "### Exploding Gradients Problem "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6aySdMFb79xA"
      },
      "source": [
        "What Are Exploding Gradients?\n",
        "\n",
        "An **error gradient** is the **direction and magnitude calculated** during the training of a neural network that is used to update the network **weights** in the right direction and by the right amount.\n",
        "\n",
        "In deep networks or recurrent neural networks, **error gradients can accumulate** during an update and result in very large gradients. These in turn result in large updates to the network weights, and in turn, an **unstable network**.\n",
        "\n",
        "At an extreme, the values of weights can become so large as to overflow and result in **NaN values**.\n",
        "\n",
        "The explosion occurs through exponential growth by repeatedly multiplying gradients through the network layers that have values larger than 1.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KGYdciL779xC"
      },
      "source": [
        "How do You Know if You Have Exploding Gradients?\n",
        "\n",
        "There are some subtle signs that you may be suffering from exploding gradients during the training of your network, such as:\n",
        "\n",
        "1) The model is unable to get traction on your training data (e.g. poor loss).\n",
        "\n",
        "2) The model is unstable, resulting in large changes in loss from update to update.\n",
        "\n",
        "3) The model loss goes to NaN during training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ywYSvGC179xF"
      },
      "source": [
        "How to Fix Exploding Gradients?\n",
        "\n",
        "1. Re-Design the Network Model\n",
        "\n",
        "In deep neural networks, exploding gradients may be addressed by redesigning the network to have fewer layers.\n",
        "There may also be some benefit in using a smaller batch size while training the network.\n",
        "In recurrent neural networks, updating across fewer prior time steps during training, called truncated Backpropagation through time, may reduce the exploding gradient problem.\n",
        "\n",
        "2. Use Long Short-Term Memory Networks\n",
        "\n",
        "In recurrent neural networks, gradient exploding can occur given the inherent instability in the training of this type of network, e.g. via Backpropagation through time that essentially transforms the recurrent network into a deep multilayer Perceptron neural network.\n",
        "\n",
        "Exploding gradients can be reduced by using the Long Short-Term Memory (LSTM) memory units and perhaps related gated-type neuron structures.\n",
        "Adopting LSTM memory units is a new best practice for recurrent neural networks for sequence prediction.\n",
        "\n",
        "3. Use Gradient Clipping\n",
        "\n",
        "Exploding gradients can still occur in very deep Multilayer Perceptron networks with a large batch size and LSTMs with very long input sequence lengths.\n",
        "If exploding gradients are still occurring, you can check for and limit the size of gradients during the training of your network.\n",
        "\n",
        "4. Use Weight Regularization\n",
        "\n",
        "Another approach, if exploding gradients are still occurring, is to check the size of network weights and apply a penalty to the networks loss function for large weight values.\n",
        "\n",
        "(Using an L1 or L2 penalty on the recurrent weights can help with exploding gradients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "76Ovi_FG79xM"
      },
      "source": [
        "### Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJy1gITW79xP",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Dense(\n",
        "    units,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lN-6cs4K79xW"
      },
      "source": [
        "### Convolutional Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JRNsAWC279xY",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Conv1D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=1,\n",
        "    padding='valid',\n",
        "    data_format='channels_last',\n",
        "    dilation_rate=1,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None\n",
        ")\n",
        "\n",
        "tf.keras.layers.Conv2D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format=None,\n",
        "    dilation_rate=(1, 1),\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D9aEjvZP79xd"
      },
      "source": [
        "### Pooling Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JR0tjJCT79xf",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.MaxPooling1D(\n",
        "    pool_size=2,\n",
        "    strides=None,\n",
        "    padding='valid',\n",
        "    data_format='channels_last'\n",
        ")\n",
        "\n",
        "tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2),\n",
        "    strides=None,\n",
        "    padding='valid',\n",
        "    data_format=None\n",
        ")\n",
        "\n",
        "tf.keras.layers.MaxPooling3D(\n",
        "    pool_size=(2, 2, 2),\n",
        "    strides=None,\n",
        "    padding='valid',\n",
        "    data_format=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F_o1dBN579xk"
      },
      "source": [
        "### Locally Connected Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w-eWMIWw79xl",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.LocallyConnected1D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=1,\n",
        "    padding='valid',\n",
        "    data_format=None,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    implementation=1\n",
        ")\n",
        "\n",
        "tf.keras.layers.LocallyConnected2D(\n",
        "    filters,\n",
        "    kernel_size,\n",
        "    strides=(1, 1),\n",
        "    padding='valid',\n",
        "    data_format=None,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    implementation=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NkwWZNNS79xt"
      },
      "source": [
        "### Flatten Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ekLVSU8879xv",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(64, (3, 3),input_shape=(3, 32, 32), padding='same',))\n",
        "# now: model.output_shape == (None, 64, 32, 32)\n",
        "model.add(Flatten())\n",
        "# now: model.output_shape == (None, 65536)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6tq032v579x0"
      },
      "source": [
        "### Recurrent Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Aw5fC2a979x2",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.RNN(\n",
        "    cell,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    time_major=False\n",
        ")\n",
        "\n",
        "tf.keras.layers.SimpleRNN(\n",
        "    units,\n",
        "    activation='tanh',\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    recurrent_initializer='orthogonal',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False\n",
        ")\n",
        "\n",
        "tf.keras.layers.GRU(\n",
        "    units,\n",
        "    activation='tanh',\n",
        "    recurrent_activation='sigmoid',\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    recurrent_initializer='orthogonal',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    implementation=2,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    unroll=False,\n",
        "    time_major=False,\n",
        "    reset_after=True\n",
        ")\n",
        "\n",
        "tf.keras.layers.LSTM(\n",
        "    units,\n",
        "    activation='tanh',\n",
        "    recurrent_activation='sigmoid',\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    recurrent_initializer='orthogonal',\n",
        "    bias_initializer='zeros',\n",
        "    unit_forget_bias=True,\n",
        "    kernel_regularizer=None,\n",
        "    recurrent_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    recurrent_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    dropout=0.0,\n",
        "    recurrent_dropout=0.0,\n",
        "    implementation=2,\n",
        "    return_sequences=False,\n",
        "    return_state=False,\n",
        "    go_backwards=False,\n",
        "    stateful=False,\n",
        "    time_major=False,\n",
        "    unroll=False\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mf-WE6GU79yB"
      },
      "source": [
        "### Advanced Activation Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "09c5f108-c8c4-4413-c398-0a60956a3915",
        "id": "V7_jGd2t79yD",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
        "tf.keras.layers.ELU(alpha=1.0) # Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n",
        "tf.keras.layers.Softmax(axis=-1)\n",
        "tf.keras.layers.LeakyReLU(alpha=0.3) #Rectifier Nonlinearities Improve Neural Network Acoustic Models\n",
        "tf.keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None) #Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n",
        "tf.keras.layers.ThresholdedReLU(theta=1.0) #Zero-Bias Autoencoders and the Benefits of Co-Adapting Features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.advanced_activations.ThresholdedReLU at 0x14db90c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fcNgh76U79yV"
      },
      "source": [
        "### Embedding Layer - A Theoretically Grounded Application of Dropout in Recurrent Neural Networks (RNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AoIap6SD79yY",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AUCqYgAT79ye"
      },
      "source": [
        "### Accelerating Deep Network Training (Reducing Internal Covariate Shift)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "66a60d26-45fa-4f32-909e-2ec5f0285580",
        "id": "U4E1ClI_79yg",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.BatchNormalization(\n",
        "    axis=-1,\n",
        "    momentum=0.99,\n",
        "    epsilon=0.001,\n",
        "    center=True,\n",
        "    scale=True,\n",
        "    beta_initializer='zeros',\n",
        "    gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros',\n",
        "    moving_variance_initializer='ones',\n",
        "    beta_regularizer=None,\n",
        "    gamma_regularizer=None,\n",
        "    beta_constraint=None,\n",
        "    gamma_constraint=None,\n",
        "    renorm=False,\n",
        "    renorm_clipping=None,\n",
        "    renorm_momentum=0.99,\n",
        "    fused=None,\n",
        "    trainable=True,\n",
        "    virtual_batch_size=None,\n",
        "    adjustment=None,\n",
        "    name=None\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14db90f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h-mjBw8h79yt"
      },
      "source": [
        "### Prevent Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fF25k3dQ79yu",
        "colab": {}
      },
      "source": [
        "tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
        "tf.keras.layers.GaussianNoise(stddev)\n",
        "tf.keras.layers.GaussianDropout(rate)\n",
        "tf.keras.layers.AlphaDropout(rate, noise_shape=None, seed=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3iYSg8H_79y2"
      },
      "source": [
        "### Activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "89UfTTAb79y4",
        "colab": {}
      },
      "source": [
        "tf.keras.activations.elu(x, alpha=1.0)\n",
        "tf.keras.activations.exponential(x)\n",
        "tf.keras.activations.hard_sigmoid(x)\n",
        "tf.keras.activations.linear(x)\n",
        "tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
        "tf.keras.activations.selu(x)\n",
        "tf.keras.activations.sigmoid(x)\n",
        "tf.keras.activations.tanh(x)\n",
        "tf.keras.activations.softmax(x, axis=-1)\n",
        "tf.keras.activations.softplus(x)\n",
        "tf.keras.activations.softsign(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4mxfamJW79zE"
      },
      "source": [
        "### Regularizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xs0jRDQ-79zG",
        "colab": {}
      },
      "source": [
        "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
        "\n",
        "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
        "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "\n",
        "# A linear layer with L1 & L2 regularization of factor 0.01 applied to the kernel matrix:\n",
        "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kFdAzz7b79zP"
      },
      "source": [
        "### Metrics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6551a91f-66b9-4bf0-e78f-93580f4c9873",
        "id": "TM5EP7xK79zS",
        "colab": {}
      },
      "source": [
        "tf.keras.metrics.CategoricalAccuracy()\n",
        "tf.keras.metrics.Accuracy()\n",
        "tf.keras.metrics.AUC()\n",
        "tf.keras.metrics.BinaryAccuracy()\n",
        "tf.keras.metrics.BinaryCrossentropy()\n",
        "tf.keras.metrics.CategoricalAccuracy()\n",
        "tf.keras.metrics.CategoricalCrossentropy()\n",
        "tf.keras.metrics.CategoricalHinge()\n",
        "tf.keras.metrics.CosineSimilarity()\n",
        "tf.keras.metrics.Hinge()\n",
        "\n",
        "tf.keras.metrics.KLD(y_true, y_pred)\n",
        "tf.keras.metrics.MAE(y_true, y_pred)\n",
        "tf.keras.metrics.MAPE(y_true, y_pred)\n",
        "tf.keras.metrics.Mean()\n",
        "tf.keras.metrics.MSE(y_true, y_pred)\n",
        "tf.keras.metrics.MSLE(y_true, y_pred)\n",
        "\n",
        "tf.keras.metrics.Poisson()\n",
        "tf.keras.metrics.RootMeanSquaredError()\n",
        "tf.keras.metrics.SparseCategoricalCrossentropy()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.metrics.CategoricalCrossentropy at 0x14d8d7240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uhMIotrO79zZ"
      },
      "source": [
        "### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kVhZDQ3_79zb",
        "colab": {}
      },
      "source": [
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction='auto',\n",
        "    name='categorical_crossentropy',\n",
        ")\n",
        "\n",
        "tf.keras.losses.BinaryCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction='auto',\n",
        "    name='binary_crossentropy',\n",
        ")\n",
        "\n",
        "tf.keras.losses.CategoricalHinge(\n",
        "    reduction='auto',\n",
        "    name='categorical_hinge',\n",
        ")\n",
        "\n",
        "tf.keras.losses.CosineSimilarity(\n",
        "    axis=-1,\n",
        "    reduction='auto',\n",
        "    name='cosine_similarity',\n",
        ")\n",
        "\n",
        "tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    reduction='auto',\n",
        "    name=None,\n",
        ")\n",
        "\n",
        "tf.keras.losses.KLD(y_true, y_pred)\n",
        "tf.keras.losses.LogCosh(reduction='auto', name='logcosh')\n",
        "tf.keras.losses.Poisson(reduction='auto', name='poisson')\n",
        "tf.keras.losses.SquaredHinge(reduction='auto', name='squared_hinge')\n",
        "\n",
        "tf.keras.losses.MAE(y_true, y_pred)\n",
        "tf.keras.losses.MAPE(y_true, y_pred)\n",
        "tf.keras.losses.MSE(y_true, y_pred)\n",
        "tf.keras.losses.MSLE(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ge-q4vR-79zl"
      },
      "source": [
        "### Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "64633ad8-b956-43c3-9e3f-dbb140665381",
        "id": "budFpPxb79zq",
        "colab": {}
      },
      "source": [
        "tf.keras.optimizers.Adadelta(\n",
        "    learning_rate=0.001,\n",
        "    rho=0.95,\n",
        "    epsilon=1e-07,\n",
        "    name='Adadelta'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adagrad(\n",
        "    learning_rate=0.001,\n",
        "    initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07,\n",
        "    name='Adagrad'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name='Adam'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Adamax(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    name='Adamax'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Nadam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    name='Nadam'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.SGD(\n",
        "    learning_rate=0.01,\n",
        "    momentum=0.0,\n",
        "    nesterov=False,\n",
        "    name='SGD'\n",
        ")\n",
        "\n",
        "tf.keras.optimizers.Ftrl(\n",
        "    learning_rate=0.001,\n",
        "    learning_rate_power=-0.5,\n",
        "    initial_accumulator_value=0.1,\n",
        "    l1_regularization_strength=0.0,\n",
        "    l2_regularization_strength=0.0,\n",
        "    name='Ftrl',\n",
        "    l2_shrinkage_regularization_strength=0.0\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl at 0x14cdec160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmG6Cim9OB1S",
        "colab_type": "text"
      },
      "source": [
        "##TensorFlow (Basic Architectures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9BpJERtS3mU",
        "colab_type": "text"
      },
      "source": [
        "Sequential Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Gaaz7R5jEB",
        "colab_type": "text"
      },
      "source": [
        "### Deep Neural Networks (DNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LoY_I2gObEb"
      },
      "source": [
        "#### Deep Neural Network (DNN) for Regression :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ST2RjxqsObEb",
        "outputId": "fb136113-2134-4067-e970-fe5d655e4211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3553
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def regression_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(64,input_dim=4))\n",
        "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(16,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(1))\n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),loss = \"mse\",metrics =[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = regression_model()\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/100\n",
            "14480/14480 [==============================] - 0s 15us/sample - loss: 24077.8424 - acc: 0.0854 - val_loss: 0.0215 - val_acc: 0.9867\n",
            "Epoch 2/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0125 - acc: 0.9927 - val_loss: 0.0129 - val_acc: 0.9909\n",
            "Epoch 3/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0130 - acc: 0.9927 - val_loss: 0.0827 - val_acc: 0.9256\n",
            "Epoch 4/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 885.8289 - acc: 0.5742 - val_loss: 1.7083 - val_acc: 0.9912\n",
            "Epoch 5/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 529.4218 - acc: 0.5157 - val_loss: 524.7122 - val_acc: 0.0088\n",
            "Epoch 6/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 445.0928 - acc: 0.4961 - val_loss: 778.1347 - val_acc: 0.9912\n",
            "Epoch 7/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 489.3062 - acc: 0.5047 - val_loss: 656.0197 - val_acc: 0.0088\n",
            "Epoch 8/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 443.5343 - acc: 0.4941 - val_loss: 274.9792 - val_acc: 0.9912\n",
            "Epoch 9/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 493.4202 - acc: 0.5052 - val_loss: 367.5925 - val_acc: 0.0088\n",
            "Epoch 10/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 444.4734 - acc: 0.4959 - val_loss: 1475.0523 - val_acc: 0.9912\n",
            "Epoch 11/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 205.4427 - acc: 0.5036 - val_loss: 1232.3436 - val_acc: 0.0088\n",
            "Epoch 12/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 400.1292 - acc: 0.4953 - val_loss: 1233.9900 - val_acc: 0.9912\n",
            "Epoch 13/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 376.9817 - acc: 0.5044 - val_loss: 1360.1720 - val_acc: 0.0088\n",
            "Epoch 14/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 314.5192 - acc: 0.4953 - val_loss: 468.7754 - val_acc: 0.9912\n",
            "Epoch 15/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 334.1401 - acc: 0.5059 - val_loss: 639.5700 - val_acc: 0.0088\n",
            "Epoch 16/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 295.6788 - acc: 0.4961 - val_loss: 569.7871 - val_acc: 0.9912\n",
            "Epoch 17/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 298.8173 - acc: 0.5055 - val_loss: 352.0087 - val_acc: 0.0088\n",
            "Epoch 18/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 281.8611 - acc: 0.4946 - val_loss: 401.5198 - val_acc: 0.9912\n",
            "Epoch 19/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 266.5429 - acc: 0.5054 - val_loss: 176.2505 - val_acc: 0.0088\n",
            "Epoch 20/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 242.1960 - acc: 0.4959 - val_loss: 147.6920 - val_acc: 0.9912\n",
            "Epoch 21/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 220.3410 - acc: 0.5047 - val_loss: 206.6050 - val_acc: 0.0088\n",
            "Epoch 22/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 189.7994 - acc: 0.4950 - val_loss: 301.5651 - val_acc: 0.9912\n",
            "Epoch 23/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 180.6182 - acc: 0.5050 - val_loss: 293.9100 - val_acc: 0.0088\n",
            "Epoch 24/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 178.5386 - acc: 0.4950 - val_loss: 150.0191 - val_acc: 0.9912\n",
            "Epoch 25/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 170.8329 - acc: 0.5046 - val_loss: 107.5187 - val_acc: 0.0088\n",
            "Epoch 26/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 142.4293 - acc: 0.4953 - val_loss: 190.5522 - val_acc: 0.9912\n",
            "Epoch 27/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 139.9497 - acc: 0.5052 - val_loss: 92.6311 - val_acc: 0.0088\n",
            "Epoch 28/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 126.8358 - acc: 0.4957 - val_loss: 56.4212 - val_acc: 0.9912\n",
            "Epoch 29/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 123.6298 - acc: 0.5061 - val_loss: 82.6105 - val_acc: 0.0088\n",
            "Epoch 30/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 114.9083 - acc: 0.4953 - val_loss: 70.5810 - val_acc: 0.9912\n",
            "Epoch 31/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 44.9153 - acc: 0.5484 - val_loss: 10.1310 - val_acc: 0.0088\n",
            "Epoch 32/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 59.9246 - acc: 0.4950 - val_loss: 35.9701 - val_acc: 0.9912\n",
            "Epoch 33/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 59.2736 - acc: 0.5041 - val_loss: 30.5245 - val_acc: 0.0088\n",
            "Epoch 34/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 52.3890 - acc: 0.4956 - val_loss: 50.2321 - val_acc: 0.9912\n",
            "Epoch 35/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 51.0632 - acc: 0.5046 - val_loss: 50.1428 - val_acc: 0.0088\n",
            "Epoch 36/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 69.2107 - acc: 0.4988 - val_loss: 0.1704 - val_acc: 0.9912\n",
            "Epoch 37/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 40.8213 - acc: 0.6321 - val_loss: 1.6098 - val_acc: 0.0457\n",
            "Epoch 38/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 20.4210 - acc: 0.5533 - val_loss: 45.4473 - val_acc: 0.9912\n",
            "Epoch 39/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 30.4005 - acc: 0.5048 - val_loss: 54.2613 - val_acc: 0.0088\n",
            "Epoch 40/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 28.6482 - acc: 0.4961 - val_loss: 81.3055 - val_acc: 0.9912\n",
            "Epoch 41/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 26.3997 - acc: 0.5052 - val_loss: 40.5506 - val_acc: 0.0088\n",
            "Epoch 42/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 25.3494 - acc: 0.4942 - val_loss: 29.0293 - val_acc: 0.9912\n",
            "Epoch 43/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 22.2986 - acc: 0.5054 - val_loss: 20.9288 - val_acc: 0.0088\n",
            "Epoch 44/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 18.6805 - acc: 0.4945 - val_loss: 26.0849 - val_acc: 0.9912\n",
            "Epoch 45/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 15.6222 - acc: 0.5052 - val_loss: 8.0814 - val_acc: 0.0093\n",
            "Epoch 46/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 15.1460 - acc: 0.4958 - val_loss: 9.2317 - val_acc: 0.9912\n",
            "Epoch 47/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 13.9966 - acc: 0.5044 - val_loss: 12.1245 - val_acc: 0.0088\n",
            "Epoch 48/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 12.7135 - acc: 0.4970 - val_loss: 7.1570 - val_acc: 0.9912\n",
            "Epoch 49/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 54.1629 - acc: 0.5758 - val_loss: 0.0090 - val_acc: 0.9912\n",
            "Epoch 50/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 51/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 1.1837 - acc: 0.8816 - val_loss: 56.9383 - val_acc: 0.0088\n",
            "Epoch 52/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 85.7221 - acc: 0.8539 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 53/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0093 - val_acc: 0.9912\n",
            "Epoch 54/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.5465 - acc: 0.9118 - val_loss: 50.9197 - val_acc: 0.0088\n",
            "Epoch 55/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8.5894 - acc: 0.5582 - val_loss: 25.2660 - val_acc: 0.9912\n",
            "Epoch 56/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 9.4278 - acc: 0.5153 - val_loss: 11.9390 - val_acc: 0.0088\n",
            "Epoch 57/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 13.9960 - acc: 0.4952 - val_loss: 83.8669 - val_acc: 0.9912\n",
            "Epoch 58/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 16.4968 - acc: 0.9229 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 59/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 60/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 7.7343 - acc: 0.8420 - val_loss: 0.0239 - val_acc: 0.9912\n",
            "Epoch 61/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 10.5067 - acc: 0.9228 - val_loss: 0.0091 - val_acc: 0.9912\n",
            "Epoch 62/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0079 - acc: 0.9931 - val_loss: 0.0656 - val_acc: 0.9790\n",
            "Epoch 63/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 5.5607 - acc: 0.6419 - val_loss: 0.4022 - val_acc: 0.9912\n",
            "Epoch 64/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 5.1891 - acc: 0.5273 - val_loss: 0.6166 - val_acc: 0.2679\n",
            "Epoch 65/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 4.2680 - acc: 0.5261 - val_loss: 1.6739 - val_acc: 0.9912\n",
            "Epoch 66/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 9.6510 - acc: 0.6428 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 67/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0092 - val_acc: 0.9912\n",
            "Epoch 68/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 11.8590 - acc: 0.7831 - val_loss: 0.0250 - val_acc: 0.9912\n",
            "Epoch 69/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0082 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 70/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0093 - val_acc: 0.9912\n",
            "Epoch 71/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 4.0881 - acc: 0.7123 - val_loss: 0.2091 - val_acc: 0.9912\n",
            "Epoch 72/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 3.1308 - acc: 0.5959 - val_loss: 1.0191 - val_acc: 0.1196\n",
            "Epoch 73/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 2.6344 - acc: 0.5194 - val_loss: 0.6827 - val_acc: 0.9912\n",
            "Epoch 74/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 2.1284 - acc: 0.5317 - val_loss: 0.8738 - val_acc: 0.1584\n",
            "Epoch 75/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 7.1973 - acc: 0.7328 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 76/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 0.9912\n",
            "Epoch 77/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0127 - val_acc: 0.9912\n",
            "Epoch 78/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 1.4043 - acc: 0.7458 - val_loss: 0.0846 - val_acc: 0.9525\n",
            "Epoch 79/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 1.1813 - acc: 0.7028 - val_loss: 0.1987 - val_acc: 0.9912\n",
            "Epoch 80/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 10.5459 - acc: 0.6604 - val_loss: 0.9719 - val_acc: 0.9912\n",
            "Epoch 81/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.1346 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 82/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
            "Epoch 83/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0082 - acc: 0.9931 - val_loss: 0.1458 - val_acc: 0.9912\n",
            "Epoch 84/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 4.6700 - acc: 0.7562 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 85/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 86/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0078 - acc: 0.9931 - val_loss: 0.0651 - val_acc: 0.9781\n",
            "Epoch 87/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.2396 - acc: 0.8775 - val_loss: 0.2659 - val_acc: 0.9912\n",
            "Epoch 88/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.3328 - acc: 0.7990 - val_loss: 0.3569 - val_acc: 0.4966\n",
            "Epoch 89/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 15.8533 - acc: 0.8258 - val_loss: 1.0061 - val_acc: 0.9912\n",
            "Epoch 90/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.3246 - acc: 0.9931 - val_loss: 0.0319 - val_acc: 0.9912\n",
            "Epoch 91/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0119 - acc: 0.9931 - val_loss: 0.0090 - val_acc: 0.9912\n",
            "Epoch 92/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 0.9912\n",
            "Epoch 93/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 94/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 95/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 96/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 97/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 98/100\n",
            "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 99/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
            "Epoch 100/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00735136],\n",
              "       [0.00735136],\n",
              "       [0.00735136],\n",
              "       ...,\n",
              "       [0.00735136],\n",
              "       [0.00735136],\n",
              "       [0.00735136]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OZ-XxPgbObEd"
      },
      "source": [
        "#### Deep Neural Network (DNN) for Binary Classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HCLzs7HnObEd",
        "outputId": "891615f5-7106-4fa8-fb67-58bec7a8330c",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def binaryclass_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128,input_dim=4))\n",
        "    model.add(layers.Dense(64,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(1,activation=tf.nn.sigmoid))  \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),loss = 'binary_crossentropy',metrics =[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = binaryclass_model()\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/100\n",
            "14480/14480 [==============================] - 1s 39us/sample - loss: 8295368.5436 - accuracy: 0.0000e+00 - val_loss: 8402822.8707 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2729 - accuracy: 0.0000e+00 - val_loss: 8402822.3857 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4691 - accuracy: 0.0000e+00 - val_loss: 8402822.7523 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4298 - accuracy: 0.0000e+00 - val_loss: 8402822.7397 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2298 - accuracy: 0.0000e+00 - val_loss: 8402822.7931 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6033 - accuracy: 0.0000e+00 - val_loss: 8402822.5061 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.8906 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3238 - accuracy: 0.0000e+00 - val_loss: 8402822.7584 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4254 - accuracy: 0.0000e+00 - val_loss: 8402822.5364 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3796 - accuracy: 0.0000e+00 - val_loss: 8402822.4399 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5370 - accuracy: 0.0000e+00 - val_loss: 8402822.7419 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4442 - accuracy: 0.0000e+00 - val_loss: 8402822.9446 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6094 - accuracy: 0.0000e+00 - val_loss: 8402822.4560 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4685 - accuracy: 0.0000e+00 - val_loss: 8402822.2721 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.1481 - accuracy: 0.0000e+00 - val_loss: 8402822.8129 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.3481 - accuracy: 0.0000e+00 - val_loss: 8402822.6361 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.4729 - accuracy: 0.0000e+00 - val_loss: 8402822.4647 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6961 - accuracy: 0.0000e+00 - val_loss: 8402822.9023 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2696 - accuracy: 0.0000e+00 - val_loss: 8402822.4947 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3624 - accuracy: 0.0000e+00 - val_loss: 8402822.5883 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3442 - accuracy: 0.0000e+00 - val_loss: 8402822.5619 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4680 - accuracy: 0.0000e+00 - val_loss: 8402822.5850 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3812 - accuracy: 0.0000e+00 - val_loss: 8402822.5723 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4149 - accuracy: 0.0000e+00 - val_loss: 8402822.6846 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3961 - accuracy: 0.0000e+00 - val_loss: 8402822.8864 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3906 - accuracy: 0.0000e+00 - val_loss: 8402822.7906 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3956 - accuracy: 0.0000e+00 - val_loss: 8402823.0008 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.1845 - accuracy: 0.0000e+00 - val_loss: 8402822.5109 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2751 - accuracy: 0.0000e+00 - val_loss: 8402822.5022 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4354 - accuracy: 0.0000e+00 - val_loss: 8402822.7374 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6829 - accuracy: 0.0000e+00 - val_loss: 8402822.5280 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4674 - accuracy: 0.0000e+00 - val_loss: 8402822.8786 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5105 - accuracy: 0.0000e+00 - val_loss: 8402822.7837 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4856 - accuracy: 0.0000e+00 - val_loss: 8402822.5204 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.5409 - accuracy: 0.0000e+00 - val_loss: 8402822.6317 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2227 - accuracy: 0.0000e+00 - val_loss: 8402822.9075 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4144 - accuracy: 0.0000e+00 - val_loss: 8402822.6752 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4188 - accuracy: 0.0000e+00 - val_loss: 8402822.5311 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3591 - accuracy: 0.0000e+00 - val_loss: 8402822.7861 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4878 - accuracy: 0.0000e+00 - val_loss: 8402822.7582 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4840 - accuracy: 0.0000e+00 - val_loss: 8402822.2678 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2033 - accuracy: 0.0000e+00 - val_loss: 8402822.3530 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5044 - accuracy: 0.0000e+00 - val_loss: 8402822.6345 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.3642 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4337 - accuracy: 0.0000e+00 - val_loss: 8402822.9141 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1923 - accuracy: 0.0000e+00 - val_loss: 8402823.0918 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4083 - accuracy: 0.0000e+00 - val_loss: 8402822.9626 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1785 - accuracy: 0.0000e+00 - val_loss: 8402822.6171 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 49/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4177 - accuracy: 0.0000e+00 - val_loss: 8402822.4830 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5586 - accuracy: 0.0000e+00 - val_loss: 8402822.9157 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4431 - accuracy: 0.0000e+00 - val_loss: 8402822.5925 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3072 - accuracy: 0.0000e+00 - val_loss: 8402822.5470 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3116 - accuracy: 0.0000e+00 - val_loss: 8402822.5311 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3536 - accuracy: 0.0000e+00 - val_loss: 8402822.7465 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4884 - accuracy: 0.0000e+00 - val_loss: 8402822.8428 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4707 - accuracy: 0.0000e+00 - val_loss: 8402822.7341 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6420 - accuracy: 0.0000e+00 - val_loss: 8402822.7165 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2199 - accuracy: 0.0000e+00 - val_loss: 8402822.7922 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3646 - accuracy: 0.0000e+00 - val_loss: 8402822.8089 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4862 - accuracy: 0.0000e+00 - val_loss: 8402822.7189 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5287 - accuracy: 0.0000e+00 - val_loss: 8402822.6590 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3536 - accuracy: 0.0000e+00 - val_loss: 8402822.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3961 - accuracy: 0.0000e+00 - val_loss: 8402822.5271 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3138 - accuracy: 0.0000e+00 - val_loss: 8402822.1523 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4061 - accuracy: 0.0000e+00 - val_loss: 8402822.7015 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "14480/14480 [==============================] - 0s 10us/sample - loss: 8295368.5044 - accuracy: 0.0000e+00 - val_loss: 8402822.6449 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2022 - accuracy: 0.0000e+00 - val_loss: 8402823.1485 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3315 - accuracy: 0.0000e+00 - val_loss: 8402822.8184 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5204 - accuracy: 0.0000e+00 - val_loss: 8402822.6126 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5238 - accuracy: 0.0000e+00 - val_loss: 8402822.8909 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3431 - accuracy: 0.0000e+00 - val_loss: 8402822.9244 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4177 - accuracy: 0.0000e+00 - val_loss: 8402822.6037 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4000 - accuracy: 0.0000e+00 - val_loss: 8402822.4586 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4265 - accuracy: 0.0000e+00 - val_loss: 8402822.9352 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5033 - accuracy: 0.0000e+00 - val_loss: 8402822.4707 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4669 - accuracy: 0.0000e+00 - val_loss: 8402822.7307 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5215 - accuracy: 0.0000e+00 - val_loss: 8402822.4659 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4160 - accuracy: 0.0000e+00 - val_loss: 8402822.4670 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4320 - accuracy: 0.0000e+00 - val_loss: 8402822.8773 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2989 - accuracy: 0.0000e+00 - val_loss: 8402822.7346 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2608 - accuracy: 0.0000e+00 - val_loss: 8402822.5990 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5381 - accuracy: 0.0000e+00 - val_loss: 8402822.7458 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.3983 - accuracy: 0.0000e+00 - val_loss: 8402822.9714 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5204 - accuracy: 0.0000e+00 - val_loss: 8402823.1312 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4155 - accuracy: 0.0000e+00 - val_loss: 8402822.9336 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2580 - accuracy: 0.0000e+00 - val_loss: 8402822.7873 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5050 - accuracy: 0.0000e+00 - val_loss: 8402823.0310 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4552 - accuracy: 0.0000e+00 - val_loss: 8402822.4691 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3823 - accuracy: 0.0000e+00 - val_loss: 8402822.7336 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4166 - accuracy: 0.0000e+00 - val_loss: 8402822.7264 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3818 - accuracy: 0.0000e+00 - val_loss: 8402822.6480 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.6267 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3602 - accuracy: 0.0000e+00 - val_loss: 8402822.5260 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4265 - accuracy: 0.0000e+00 - val_loss: 8402822.3326 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1669 - accuracy: 0.0000e+00 - val_loss: 8402822.9249 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4851 - accuracy: 0.0000e+00 - val_loss: 8402822.7352 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.5182 - accuracy: 0.0000e+00 - val_loss: 8402822.5558 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.4110 - accuracy: 0.0000e+00 - val_loss: 8402822.6736 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1492 - accuracy: 0.0000e+00 - val_loss: 8402822.4661 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3878 - accuracy: 0.0000e+00 - val_loss: 8402822.6316 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n9aVIWn1ObEf"
      },
      "source": [
        "#### Deep Neural Network (DNN) for Multi-Class Classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O3998DVwObEf",
        "outputId": "60ed0a5e-f8ac-4675-d64d-6759563af2d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3655
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def multiclass_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128,input_dim=4))\n",
        "    model.add(layers.Dense(64,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
        "    model.add(layers.Dense(14,activation=tf.nn.softmax))  \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),loss = 'sparse_categorical_crossentropy',metrics =[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = multiclass_model()\n",
        "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/100\n",
            "14480/14480 [==============================] - 1s 37us/sample - loss: 85.2323 - acc: 0.7825 - val_loss: 18.4541 - val_acc: 0.9912\n",
            "Epoch 2/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 10.4217 - acc: 0.9931 - val_loss: 11.4321 - val_acc: 0.9912\n",
            "Epoch 3/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 5.5147 - acc: 0.9231 - val_loss: 17.2698 - val_acc: 0.9912\n",
            "Epoch 4/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 7.8217 - acc: 0.9931 - val_loss: 5.1975 - val_acc: 0.9912\n",
            "Epoch 5/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 36.9202 - acc: 0.8541 - val_loss: 19.9685 - val_acc: 0.9912\n",
            "Epoch 6/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 10.7934 - acc: 0.9931 - val_loss: 10.4356 - val_acc: 0.9912\n",
            "Epoch 7/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 8.3069 - acc: 0.9231 - val_loss: 10.3582 - val_acc: 0.9912\n",
            "Epoch 8/100\n",
            "14480/14480 [==============================] - 0s 33us/sample - loss: 34.4879 - acc: 0.8539 - val_loss: 24.6847 - val_acc: 0.9912\n",
            "Epoch 9/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 12.3716 - acc: 0.9931 - val_loss: 6.1752 - val_acc: 0.9912\n",
            "Epoch 10/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 9.8100 - acc: 0.9228 - val_loss: 9.6859 - val_acc: 0.9912\n",
            "Epoch 11/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 12.7904 - acc: 0.9226 - val_loss: 254.5598 - val_acc: 0.0088\n",
            "Epoch 12/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 30.7963 - acc: 0.9233 - val_loss: 10.6206 - val_acc: 0.9912\n",
            "Epoch 13/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 2.6273 - acc: 0.9931 - val_loss: 1.1685 - val_acc: 0.9912\n",
            "Epoch 14/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 8.9070 - acc: 0.9235 - val_loss: 5.9908 - val_acc: 0.9912\n",
            "Epoch 15/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 15.2661 - acc: 0.9227 - val_loss: 4.8545 - val_acc: 0.9912\n",
            "Epoch 16/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 22.8889 - acc: 0.8532 - val_loss: 3.3279 - val_acc: 0.9912\n",
            "Epoch 17/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 1.8561 - acc: 0.9931 - val_loss: 2.0649 - val_acc: 0.9912\n",
            "Epoch 18/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.9337 - acc: 0.9931 - val_loss: 0.5554 - val_acc: 0.9912\n",
            "Epoch 19/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.2126 - acc: 0.9931 - val_loss: 0.0977 - val_acc: 0.9912\n",
            "Epoch 20/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0718 - acc: 0.9931 - val_loss: 0.0996 - val_acc: 0.9912\n",
            "Epoch 21/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0739 - acc: 0.9931 - val_loss: 0.2651 - val_acc: 0.9912\n",
            "Epoch 22/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.1111 - acc: 0.9931 - val_loss: 0.8191 - val_acc: 0.9912\n",
            "Epoch 23/100\n",
            "14480/14480 [==============================] - 0s 32us/sample - loss: 0.1733 - acc: 0.9931 - val_loss: 0.4577 - val_acc: 0.9912\n",
            "Epoch 24/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 2.7704 - acc: 0.8539 - val_loss: 0.3340 - val_acc: 0.9912\n",
            "Epoch 25/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0947 - acc: 0.9931 - val_loss: 0.1504 - val_acc: 0.9912\n",
            "Epoch 26/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0817 - acc: 0.9931 - val_loss: 0.2651 - val_acc: 0.9912\n",
            "Epoch 27/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.1948 - acc: 0.9931 - val_loss: 1.3744 - val_acc: 0.9912\n",
            "Epoch 28/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.3107 - acc: 0.9931 - val_loss: 0.0869 - val_acc: 0.9912\n",
            "Epoch 29/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0765 - acc: 0.9931 - val_loss: 0.1248 - val_acc: 0.9912\n",
            "Epoch 30/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0830 - acc: 0.9931 - val_loss: 0.1181 - val_acc: 0.9912\n",
            "Epoch 31/100\n",
            "14480/14480 [==============================] - 0s 26us/sample - loss: 1.2972 - acc: 0.9931 - val_loss: 1.4498 - val_acc: 0.9912\n",
            "Epoch 32/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 1.3433 - acc: 0.9931 - val_loss: 1.2246 - val_acc: 0.9912\n",
            "Epoch 33/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 1.1346 - acc: 0.9931 - val_loss: 1.0337 - val_acc: 0.9912\n",
            "Epoch 34/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 0.9535 - acc: 0.9931 - val_loss: 0.8656 - val_acc: 0.9912\n",
            "Epoch 35/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.7945 - acc: 0.9931 - val_loss: 0.7193 - val_acc: 0.9912\n",
            "Epoch 36/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.6568 - acc: 0.9931 - val_loss: 0.5938 - val_acc: 0.9912\n",
            "Epoch 37/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.5395 - acc: 0.9931 - val_loss: 0.4879 - val_acc: 0.9912\n",
            "Epoch 38/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.4412 - acc: 0.9931 - val_loss: 0.4001 - val_acc: 0.9912\n",
            "Epoch 39/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.3601 - acc: 0.9931 - val_loss: 0.3282 - val_acc: 0.9912\n",
            "Epoch 40/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.2939 - acc: 0.9931 - val_loss: 0.2701 - val_acc: 0.9912\n",
            "Epoch 41/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.2406 - acc: 0.9931 - val_loss: 0.2236 - val_acc: 0.9912\n",
            "Epoch 42/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.1981 - acc: 0.9931 - val_loss: 0.1868 - val_acc: 0.9912\n",
            "Epoch 43/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.1644 - acc: 0.9931 - val_loss: 0.1577 - val_acc: 0.9912\n",
            "Epoch 44/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.1379 - acc: 0.9931 - val_loss: 0.1349 - val_acc: 0.9912\n",
            "Epoch 45/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 0.1170 - acc: 0.9931 - val_loss: 0.1170 - val_acc: 0.9912\n",
            "Epoch 46/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.1007 - acc: 0.9931 - val_loss: 0.1029 - val_acc: 0.9912\n",
            "Epoch 47/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0879 - acc: 0.9931 - val_loss: 0.0918 - val_acc: 0.9912\n",
            "Epoch 48/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0778 - acc: 0.9931 - val_loss: 0.0832 - val_acc: 0.9912\n",
            "Epoch 49/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0700 - acc: 0.9931 - val_loss: 0.0764 - val_acc: 0.9912\n",
            "Epoch 50/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0638 - acc: 0.9931 - val_loss: 0.0712 - val_acc: 0.9912\n",
            "Epoch 51/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 0.0591 - acc: 0.9931 - val_loss: 0.0672 - val_acc: 0.9912\n",
            "Epoch 52/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0554 - acc: 0.9931 - val_loss: 0.0641 - val_acc: 0.9912\n",
            "Epoch 53/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0526 - acc: 0.9931 - val_loss: 0.0618 - val_acc: 0.9912\n",
            "Epoch 54/100\n",
            "14480/14480 [==============================] - 0s 27us/sample - loss: 0.0504 - acc: 0.9931 - val_loss: 0.0598 - val_acc: 0.9912\n",
            "Epoch 55/100\n",
            "14480/14480 [==============================] - 0s 26us/sample - loss: 0.0486 - acc: 0.9931 - val_loss: 0.0582 - val_acc: 0.9912\n",
            "Epoch 56/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0472 - acc: 0.9931 - val_loss: 0.0571 - val_acc: 0.9912\n",
            "Epoch 57/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0462 - acc: 0.9931 - val_loss: 0.0560 - val_acc: 0.9912\n",
            "Epoch 58/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0453 - acc: 0.9931 - val_loss: 0.0553 - val_acc: 0.9912\n",
            "Epoch 59/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0446 - acc: 0.9931 - val_loss: 0.0547 - val_acc: 0.9912\n",
            "Epoch 60/100\n",
            "14480/14480 [==============================] - 0s 28us/sample - loss: 0.0441 - acc: 0.9931 - val_loss: 0.0540 - val_acc: 0.9912\n",
            "Epoch 61/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0436 - acc: 0.9931 - val_loss: 0.0534 - val_acc: 0.9912\n",
            "Epoch 62/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0432 - acc: 0.9931 - val_loss: 0.0531 - val_acc: 0.9912\n",
            "Epoch 63/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0429 - acc: 0.9931 - val_loss: 0.0526 - val_acc: 0.9912\n",
            "Epoch 64/100\n",
            "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0427 - acc: 0.9931 - val_loss: 0.0524 - val_acc: 0.9912\n",
            "Epoch 65/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0425 - acc: 0.9931 - val_loss: 0.0521 - val_acc: 0.9912\n",
            "Epoch 66/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0423 - acc: 0.9931 - val_loss: 0.0519 - val_acc: 0.9912\n",
            "Epoch 67/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0422 - acc: 0.9931 - val_loss: 0.0517 - val_acc: 0.9912\n",
            "Epoch 68/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0420 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 69/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0419 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 70/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0418 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 71/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0418 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
            "Epoch 72/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0417 - acc: 0.9931 - val_loss: 0.0514 - val_acc: 0.9912\n",
            "Epoch 73/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0417 - acc: 0.9931 - val_loss: 0.0514 - val_acc: 0.9912\n",
            "Epoch 74/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0416 - acc: 0.9931 - val_loss: 0.0513 - val_acc: 0.9912\n",
            "Epoch 75/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0416 - acc: 0.9931 - val_loss: 0.0512 - val_acc: 0.9912\n",
            "Epoch 76/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0415 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
            "Epoch 77/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0415 - acc: 0.9931 - val_loss: 0.0512 - val_acc: 0.9912\n",
            "Epoch 78/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
            "Epoch 79/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
            "Epoch 80/100\n",
            "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
            "Epoch 81/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 82/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 83/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 84/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 85/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 86/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 87/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 88/100\n",
            "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 89/100\n",
            "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 90/100\n",
            "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 91/100\n",
            "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 92/100\n",
            "14480/14480 [==============================] - 0s 24us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
            "Epoch 93/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 94/100\n",
            "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
            "Epoch 95/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0507 - val_acc: 0.9912\n",
            "Epoch 96/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 97/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 98/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
            "Epoch 99/100\n",
            "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
            "Epoch 100/100\n",
            "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       ...,\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
              "        7.7093949e-07, 7.5853711e-07],\n",
              "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804076e-07,\n",
              "        7.7093949e-07, 7.5853706e-07]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6zr63na53LE",
        "colab_type": "text"
      },
      "source": [
        "### Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wUar-316ObEg"
      },
      "source": [
        "#### Convolutional Neural Network (CNN) for Multi-Class Classification :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wu4yq5_BObEg",
        "outputId": "96dcb77c-2ea5-4b79-c1ed-136ddd41153e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "X_train = np.random.random((100, 100, 100, 3))\n",
        "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
        "X_test = np.random.random((20, 100, 100, 3))\n",
        "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "def cnn_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
        "# this applies 32 convolution filters of size 3x3 each.\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(100, 100, 3)))\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (3, 3), activation=tf.nn.relu))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation=tf.nn.relu))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation=tf.nn.relu))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = cnn_model()\n",
        "model.fit(X_train, y_train, batch_size=32, epochs=10)\n",
        "score = model.evaluate(X_test, y_test, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 5s 50ms/sample - loss: 2.2897\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.3151\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.3100\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2882\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2574\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.3003\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2794\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 5s 49ms/sample - loss: 2.2688\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 5s 48ms/sample - loss: 2.2722\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 5s 49ms/sample - loss: 2.2781\n",
            "20/20 [==============================] - 0s 15ms/sample - loss: 2.3009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFahUvtn6JXL",
        "colab_type": "text"
      },
      "source": [
        "### Recurrent Neural Network (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iCTkprTVObEh"
      },
      "source": [
        "#### Recurrent Neural Network (LSTM) for Regression:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HhjGHgX6ObEi",
        "outputId": "6edffa0f-b69b-4791-ed69-8756cd08bf65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
        "\n",
        "print (X_train.shape)\n",
        "print (y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14480, 4)\n",
            "(14480,)\n",
            "(7133, 4)\n",
            "(7133,)\n",
            "(14480, 1, 4)\n",
            "(14480,)\n",
            "(7133, 1, 4)\n",
            "(7133,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1yOS2w5xObEj",
        "outputId": "2183b9ae-2bf3-46cc-8a1a-eb95dc83d04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
        "                                 write_graph=True,\n",
        "                                 histogram_freq=1)\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def lstm_model() :   \n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.LSTM(128,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True))\n",
        "    model.add(layers.Dropout(0.25))\n",
        "    model.add(layers.LSTM(32))\n",
        "    model.add(layers.Dense(1))  \n",
        "    \n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),loss = \"mse\",metrics =[\"accuracy\"])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "model = lstm_model()\n",
        "model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0616 17:49:14.839148 140373151274880 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 14480 samples, validate on 7133 samples\n",
            "Epoch 1/10\n",
            "14480/14480 [==============================] - 7s 481us/sample - loss: 416599474139.7923 - acc: 0.0000e+00 - val_loss: 446471973033.6857 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "14480/14480 [==============================] - 5s 365us/sample - loss: 416586449457.2199 - acc: 0.0000e+00 - val_loss: 446459547576.2209 - val_acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "14480/14480 [==============================] - 5s 354us/sample - loss: 416574177243.7923 - acc: 0.0000e+00 - val_loss: 446447106407.7567 - val_acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "14480/14480 [==============================] - 5s 360us/sample - loss: 416561902025.1227 - acc: 0.0000e+00 - val_loss: 446434691070.5644 - val_acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "14480/14480 [==============================] - 5s 359us/sample - loss: 416549629775.4873 - acc: 0.0000e+00 - val_loss: 446422231067.2761 - val_acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "14480/14480 [==============================] - 5s 352us/sample - loss: 416537372769.3083 - acc: 0.0000e+00 - val_loss: 446409802667.4443 - val_acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "14480/14480 [==============================] - 5s 355us/sample - loss: 416525070177.5911 - acc: 0.0000e+00 - val_loss: 446397377657.8809 - val_acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "14480/14480 [==============================] - 5s 347us/sample - loss: 416512829754.5547 - acc: 0.0000e+00 - val_loss: 446384939176.8243 - val_acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "14480/14480 [==============================] - 5s 351us/sample - loss: 416500522129.9624 - acc: 0.0000e+00 - val_loss: 446372482660.2753 - val_acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "14480/14480 [==============================] - 5s 334us/sample - loss: 416488261901.2950 - acc: 0.0000e+00 - val_loss: 446360081168.9758 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[119.00605],\n",
              "       [119.00605],\n",
              "       [119.00605],\n",
              "       ...,\n",
              "       [119.00605],\n",
              "       [119.00605],\n",
              "       [119.00605]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9ZN19eON9zL",
        "colab_type": "text"
      },
      "source": [
        "## Keras Functional API (Complex Architectures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt_EoNCjRzIn",
        "colab_type": "text"
      },
      "source": [
        "The Keras functional API lets you build much more complex architectures than the simple linear stack of Sequential models we have seen previously. It also supports more advanced models. These models include multi-input and multi-output models, models with shared layers, and models with residual connections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTuZH4KEOBQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "inputs = tf.keras.Input(shape=(4,)) # Returns a 'placeholder' tensor\n",
        "x = tf.keras.layers.Dense(128)(inputs)\n",
        "x = tf.keras.layers.Dense(64, activation='relu',name='d1')(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu',name='d2')(x)\n",
        "x = tf.keras.layers.Dense(16, activation='relu',name='d3')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "predictions = tf.keras.layers.Dense(14,activation=tf.nn.softmax, name='d4')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1TOODo0PpRd",
        "colab_type": "code",
        "outputId": "712eead4-e978-4ca5-9638-baf791ebc126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "optimiser = tf.keras.optimizers.RMSprop(0.01)\n",
        "model.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512, epochs=10)\n",
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "14480/14480 [==============================] - 0s 18us/sample - loss: 79.3885 - acc: 0.2677\n",
            "Epoch 2/10\n",
            "14480/14480 [==============================] - 0s 10us/sample - loss: 2.2260 - acc: 0.4157\n",
            "Epoch 3/10\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 1.9951 - acc: 0.4157\n",
            "Epoch 4/10\n",
            "14480/14480 [==============================] - 0s 10us/sample - loss: 1.8234 - acc: 0.4157\n",
            "Epoch 5/10\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 1.7056 - acc: 0.4157\n",
            "Epoch 6/10\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 1.6299 - acc: 0.4157\n",
            "Epoch 7/10\n",
            "14480/14480 [==============================] - 0s 8us/sample - loss: 1.5845 - acc: 0.4157\n",
            "Epoch 8/10\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 1.5578 - acc: 0.4157\n",
            "Epoch 9/10\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 1.5430 - acc: 0.4157\n",
            "Epoch 10/10\n",
            "14480/14480 [==============================] - 0s 9us/sample - loss: 1.5339 - acc: 0.4157\n",
            "7133/7133 [==============================] - 0s 70us/sample - loss: 1.5369 - acc: 0.4153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5368850278968014, 0.41525304]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}
