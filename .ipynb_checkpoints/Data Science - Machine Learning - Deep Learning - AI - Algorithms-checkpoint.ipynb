{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/myrondza/Data-Science-Machine-Learning-Deep-Learning-AI-Guide-Algorithms/blob/master/Data%20Science%20-%20Machine%20Learning%20-%20Deep%20Learning%20-%20AI%20-%20Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQrxvcnUOa9m"
   },
   "source": [
    "# Data Science Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CQV8OcdrOa9t"
   },
   "source": [
    "## Data Source Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HLEA7Dd4Oa9x"
   },
   "source": [
    "### Microsoft SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6J4aiRCOa94"
   },
   "outputs": [],
   "source": [
    "import pymssql\n",
    "\n",
    "server = getenv(\"xxx.xxx.xx.xx\")\n",
    "user = getenv(\"username\")\n",
    "password = getenv(\"password\")\n",
    "\n",
    "conn = pymssql.connect(server, user, password, \"tempdb\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "                        IF OBJECT_ID('persons', 'U') IS NOT NULL\n",
    "                            DROP TABLE persons\n",
    "                        CREATE TABLE persons (\n",
    "                            id INT NOT NULL,\n",
    "                            name VARCHAR(100),\n",
    "                            salesrep VARCHAR(100),\n",
    "                            PRIMARY KEY(id)\n",
    "                        )\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "cursor.executemany(\n",
    "    \"INSERT INTO persons VALUES (%d, %s, %s)\",\n",
    "    [(1, 'John Smith', 'John Doe'),\n",
    "     (2, 'Jane Doe', 'Joe Dog'),\n",
    "     (3, 'Mike T.', 'Sarah H.')])\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cursor.execute('SELECT * FROM persons')\n",
    "row = cursor.fetchone()\n",
    "while row:\n",
    "    print(\"ID=%d, Name=%s\" % (row[0], row[1]))\n",
    "    row = cursor.fetchone()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFPr1LHIOa-G"
   },
   "source": [
    "### TM1 Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2ADwiUXOa-J"
   },
   "outputs": [],
   "source": [
    "from TM1py import TM1Service\n",
    "ADDRESS = 'xxx.xxx.xx.xx'\n",
    "PORT = 12354\n",
    "USER = 'admin'\n",
    "PASSWORD = 'apple'\n",
    "SSL = False\n",
    "DECODE_B64 = False\n",
    "\n",
    "CUBE = \"\"\n",
    "VIEW = \"\"\n",
    "\n",
    "with TM1Service(address=ADDRESS, port=PORT, user=USER, password=PASSWORD, ssl=SSL, decode_b64=DECODE_B64) as tm1:\n",
    "    df = tm1.cubes.cells.execute_view_dataframe_pivot(\n",
    "        cube_name=CUBE,\n",
    "        view_name=VIEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3ZCRHGVOa-T"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AYOWoH4Oa-W"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "silkVljCOa-e"
   },
   "source": [
    "### Pandas Data Frame "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7lNb6B_WdwZ"
   },
   "source": [
    "Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "NWScnE-nOa-h",
    "outputId": "84547785-1653-4d4a-b856-298644a7233c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  ...     long  sqft_living15  sqft_lot15\n",
       "0  7129300520  20141013T000000  221900.0  ... -122.257           1340        5650\n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'kc_house_data.csv', error_bad_lines=False)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjAb9_C8Oa-r"
   },
   "outputs": [],
   "source": [
    "X = df[[\"bedrooms\",\"sqft_living\",\"floors\",\"bathrooms\"]]\n",
    "y = df[\"price\"]\n",
    "#y = df[\"waterfront\"]\n",
    "#y = df[\"grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjUkiZooOa-v"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NDJM6lK9Oa-z",
    "outputId": "a0cb5f9b-deaa-43ef-f795-407deb375e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14480, 4)\n",
      "(14480,)\n",
      "(7133, 4)\n",
      "(7133,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1u0Pwh-Oa-5"
   },
   "source": [
    "# Supervised Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWM05R5YY25L"
   },
   "source": [
    "Given a set of data points {x(1),...,x(m)} associated to a set of outcomes {y(1),...,y(m)}, we want to build a classifier that learns how to predict y from x."
   ]
  },
  {
   "attachments": {
    "Screen%20Shot%202019-06-24%20at%201.11.14%20PM.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZpfvClVZFCe"
   },
   "source": [
    "![Screen%20Shot%202019-06-24%20at%201.11.14%20PM.png](attachment:Screen%20Shot%202019-06-24%20at%201.11.14%20PM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkgQSSZ-Oa-6"
   },
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8dPl6VBDOa-7"
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39jMs34jX28D"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "LTzhHkocOa-8",
    "outputId": "f2fa23ba-8923-4665-a4a8-7fb960e305af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.5025801802472102\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.5025801802472102\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4190853.1986948266\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 174286.3120128403\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 74492754485.58958\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.15824984512419465\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 126220.20859889686\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.5024906747145044\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "linreg = LinearRegression(\n",
    "    fit_intercept=True,\n",
    "    normalize=False,\n",
    "    copy_X=True,\n",
    "    n_jobs=None,\n",
    ")\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcjrqtXYOa_C"
   },
   "source": [
    "## Linear Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "ywJosghMOa_D",
    "outputId": "17772a55-0fdb-47c0-a211-526c651c6733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.5025798594802962\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.5025798594802962\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4190861.3067016643\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 174286.19780452107\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 74492802611.21846\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.158249164482852\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 126217.24480640539\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.5024903533013774\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "linrid = linear_model.Ridge(\n",
    "    alpha=1.0,\n",
    "    fit_intercept=True,\n",
    "    normalize=False,\n",
    "    copy_X=True,\n",
    "    max_iter=None,\n",
    "    tol=0.001,\n",
    "    solver='auto',\n",
    "    random_state=None,\n",
    ")\n",
    "linrid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linrid.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQ6q-y6LOa_I"
   },
   "source": [
    "## Linear Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "e9fyR7pmOa_M",
    "outputId": "85035da5-d534-4075-b696-c5eac10f2e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.5025802829016262\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.5025802829016262\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4190849.4994220138\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 174286.1065858295\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 74492739745.50328\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.15824910236510256\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 126215.81307340605\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.5024907731580435\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "linlass = linear_model.Lasso(\n",
    "    alpha=1.0,\n",
    "    fit_intercept=True,\n",
    "    normalize=False,\n",
    "    precompute=False,\n",
    "    copy_X=True,\n",
    "    max_iter=1000,\n",
    "    tol=0.0001,\n",
    "    warm_start=False,\n",
    "    positive=False,\n",
    "    random_state=None,\n",
    "    selection='cyclic',\n",
    ")\n",
    "\n",
    "linlass.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linlass.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6YU3V5dOa_R"
   },
   "source": [
    "## Support Vector Machines Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "sNm7VQUFOa_S",
    "outputId": "6d87f80a-ab51-451d-d8d0-1fc07630fc26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 2.9634962457336655e-05\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 2.9634962457336655e-05\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 6612478.372652433\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 227198.9448046691\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 158702470236.78464\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.2852188207333007\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 150510.01114453678\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : -0.05991461094270578\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "svr = svm.SVR(\n",
    "    kernel='rbf',\n",
    "    degree=3,\n",
    "    gamma='auto_deprecated',\n",
    "    coef0=0.0,\n",
    "    tol=0.001,\n",
    "    C=1.0,\n",
    "    epsilon=0.1,\n",
    "    shrinking=True,\n",
    "    cache_size=200,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    ")\n",
    "\n",
    "svr.fit(X_train, y_train)  \n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JH76wHE8Oa_Y"
   },
   "source": [
    "## Transformed Target Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "AkZrZkPTOa_Z",
    "outputId": "e1432c13-1732-45bc-f309-be6f1eeeae1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.11963992266389734\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.11963992266389734\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 6755529.695166179\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 178196.28431840078\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 132857992866.61635\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.1475434631407419\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 113654.11784739455\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.11269101476651688\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "def func(x):\n",
    "    return np.log(x)\n",
    "def inverse_func(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "regr = TransformedTargetRegressor( transformer = QuantileTransformer(output_distribution='normal'),\n",
    "                                   regressor=linreg,\n",
    "                                   #func=func,\n",
    "                                   #inverse_func=inverse_func\n",
    "                                 )\n",
    "# Either use transformer or function & inverese function\n",
    "\n",
    "regr.fit(X_train, y_train) \n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_PYLzFUdOa_e"
   },
   "source": [
    "## Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "0HO7qTUROa_f",
    "outputId": "680d2e09-c7a3-47fd-c83e-a7a3883cb5ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.5025528854309511\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.5025528854309511\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4191516.4445031728\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 174277.88125644284\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 74496848244.177\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.15819791385822218\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 126295.90384339419\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.5024633340276581\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "linbayes = linear_model.BayesianRidge(\n",
    "    n_iter=300,\n",
    "    tol=0.001,\n",
    "    alpha_1=1e-06,\n",
    "    alpha_2=1e-06,\n",
    "    lambda_1=1e-06,\n",
    "    lambda_2=1e-06,\n",
    "    compute_score=False,\n",
    "    fit_intercept=True,\n",
    "    normalize=False,\n",
    "    copy_X=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "linbayes.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linbayes.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1AuptacOa_k"
   },
   "source": [
    " ## Huber Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "sSH7RSVROa_l",
    "outputId": "173ec667-9862-4e1b-e9ce-e220c64e6e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.4740211311371182\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.4740211311371182\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4734852.297902894\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 169708.0772657343\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 80388824246.9135\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.15027959150311426\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 118697.82961323732\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.4631130237060438\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "linhub = linear_model.HuberRegressor(\n",
    "    epsilon=1.35,\n",
    "    max_iter=100,\n",
    "    alpha=0.0001,\n",
    "    warm_start=False,\n",
    "    fit_intercept=True,\n",
    "    tol=1e-05,\n",
    ")\n",
    "\n",
    "linhub.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linhub.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BqpLbETOa_p"
   },
   "source": [
    "## RANdom SAmple Consensus Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "QmG2UElVOa_q",
    "outputId": "6637794b-695f-430d-a035-02df1d4adec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.37520435402368024\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.37520435402368024\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 5235219.298239896\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 193614.88621373053\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 113351261622.01985\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.2053681191889484\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 123273.95127144211\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.2429691977527838\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from numpy import inf\n",
    "\n",
    "linran = linear_model.RANSACRegressor(\n",
    "    base_estimator=None,\n",
    "    min_samples=None,\n",
    "    residual_threshold=None,\n",
    "    is_data_valid=None,\n",
    "    is_model_valid=None,\n",
    "    max_trials=100,\n",
    "    max_skips=inf,\n",
    "    stop_n_inliers=inf,\n",
    "    stop_score=inf,\n",
    "    stop_probability=0.99,\n",
    "    loss='absolute_loss',\n",
    "    random_state=None,\n",
    ")\n",
    "\n",
    "linran.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linran.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrfNIhh5Oa_s"
   },
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "YY7Uge2ROa_t",
    "outputId": "fbd76d66-d76e-4ccc-f809-f89269d5b369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.2392491572348504\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.2392491572348504\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 5420000.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 202820.2999407902\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 113909852129.01071\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.21368509200142008\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 128500.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.239238580081804\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn import metrics\n",
    "\n",
    "dtree = DecisionTreeRegressor(\n",
    "    criterion='mse',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    presort=False,\n",
    ")\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7ZoQNXHOa_x"
   },
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "NugxquXVOa_z",
    "outputId": "d6a27e40-55a2-4a3f-f08b-376959b82d75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.4516637920799279\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.4516637920799279\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4377000.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 181604.04387443163\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 82110170862.77086\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.1710767777571059\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 122402.48543123546\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.45161679163150925\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators='warn',\n",
    "    criterion='mse',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "rfr.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rfr.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fS82NDIgOa_3"
   },
   "source": [
    "## XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "49b0QmYWOa_5",
    "outputId": "83fe7364-b9a3-4e52-9ea1-1d187898201e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.5373906994756107\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.5373906994756107\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4975684.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 165979.19164446936\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 69268602953.5168\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.14214645627777067\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 117154.5625\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.5373808344603559\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    silent=True,\n",
    "    objective='reg:linear',\n",
    "    booster='gbtree',\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,\n",
    "    missing=None,\n",
    "    importance_type='gain',\n",
    ")\n",
    "\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nwo7WVpgOa_-"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 25911
    },
    "colab_type": "code",
    "id": "XaRL7cKcOa_-",
    "outputId": "fda0add0-d4df-48bb-91fb-9ff6fe464a98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.32885442606741144\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.32885442606741144\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4420000.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 189388.72872564138\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 109475929934.12645\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.18338691437342883\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 123260.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.26885109279902364\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    dual=False,\n",
    "    tol=0.0001,\n",
    "    C=1.0,\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    class_weight=None,\n",
    "    random_state=None,\n",
    "    solver='lbfgs',\n",
    "    max_iter=100,\n",
    "    multi_class='warn',\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    n_jobs=None,\n",
    "    l1_ratio=None,\n",
    ")\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2vkVs-49ObAA"
   },
   "source": [
    "## Multi-layer perceptron (MLP) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "Jiq6oJ0fObAB",
    "outputId": "4a0374b7-8eb3-47b4-fc50-aad949dcd453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.4841194901326197\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.4841194901326197\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4440412.303482478\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 176192.58390430172\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 77246107344.6375\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.1611054350114478\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 128327.15221276396\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.48410205782636384\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlpreg = MLPRegressor(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.001,\n",
    "    power_t=0.5,\n",
    "    max_iter=200,\n",
    "    shuffle=True,\n",
    "    random_state=None,\n",
    "    tol=0.0001,\n",
    "    verbose=False,\n",
    "    warm_start=False,\n",
    "    momentum=0.9,\n",
    "    nesterovs_momentum=True,\n",
    "    early_stopping=False,\n",
    "    validation_fraction=0.1,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08,\n",
    "    n_iter_no_change=10,\n",
    ")\n",
    "\n",
    "mlpreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlpreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzKzBzpkObAE"
   },
   "source": [
    "## Star Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "colab_type": "code",
    "id": "tIlTkIw3ObAF",
    "outputId": "3bb9878b-e64c-4472-b055-e01f5710385b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting starboost\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/4d/3f696e4ff21a029b677e0ae3104f3385973679d17e3cef234e775da00617/starboost-0.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from starboost) (0.21.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from starboost) (1.16.4)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from starboost) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.0->starboost) (0.13.2)\n",
      "Installing collected packages: starboost\n",
      "Successfully installed starboost-0.0.2\n",
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score : 0.5225639625191154\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Explained Variance Score Uniform Average : 0.5225639625191154\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Maximum Error (ME) : 4422148.5\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Absolute Error (MAE) : 169562.46440400253\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Error (MSE) : 71492156643.59364\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Mean Squared Log Error (MSLE) : 0.15011786565761953\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Median Absolute Error (MedAE) : 125470.375\n",
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score (R2) : 0.522530548634233\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install starboost\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import starboost as sb\n",
    "\n",
    "\n",
    "strboost = sb.BoostingRegressor(\n",
    "    loss=None,\n",
    "    base_estimator=tree.DecisionTreeRegressor(max_depth=3),\n",
    "    tree_flavor=False,\n",
    "    n_estimators=30,\n",
    "    init_estimator=None,\n",
    "    line_searcher=None,\n",
    "    learning_rate=0.1,\n",
    "    row_sampling=1.0,\n",
    "    col_sampling=1.0,\n",
    "    eval_metric=None,\n",
    "    early_stopping_rounds=None,\n",
    "    random_state=None,\n",
    ")\n",
    "\n",
    "strboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = strboost.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score :\",explained_variance_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Explained Variance Score Uniform Average :\",explained_variance_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Maximum Error (ME) :\",max_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Absolute Error (MAE) :\",mean_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Error (MSE) :\",mean_squared_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Mean Squared Log Error (MSLE) :\",mean_squared_log_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Median Absolute Error (MedAE) :\",median_absolute_error(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score (R2) :\",r2_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJWsd4hsObAJ"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YlyWMEMeObAK"
   },
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "cus2mDy9ObAL",
    "outputId": "34b87204-e793-4cbd-d993-d01a3bf4698b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.985279685966634\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.011387798495256788\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.5206270627062706\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.014720314033366046\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7070\n",
      "           1       0.06      0.05      0.05        63\n",
      "\n",
      "    accuracy                           0.99      7133\n",
      "   macro avg       0.53      0.52      0.52      7133\n",
      "weighted avg       0.98      0.99      0.98      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.04677268475210472\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[7025   45]\n",
      " [  60    3]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.05405405405405405\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.014720314033366046\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.0058881256133465\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.027777777777777776\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.5084266792864135\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.047212480683821056\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[   3   60]\n",
      "  [  45 7025]]\n",
      "\n",
      " [[7025   45]\n",
      "  [  60    3]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 0.0625    , 1.        ]), array([1.        , 0.04761905, 0.        ]), array([0, 1]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.9915314, 0.0625   ]), array([0.99363508, 0.04761905]), array([0.99258213, 0.05405405]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.0625\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.047619047619047616\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.5206270627062706\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0.        , 0.00636492, 1.        ]), array([0.        , 0.04761905, 1.        ]), array([2, 1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.014720314033366044\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import hinge_loss\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dtree = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    presort=False,\n",
    ")\n",
    "\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtree.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YGCZBvOEObAO"
   },
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1108
    },
    "colab_type": "code",
    "id": "YXmg0PfjObAP",
    "outputId": "b38d055e-0df4-48f0-f637-0bc72f739744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.9892051030421982\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.009684058445098682\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.5068756875687569\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.010794896957801767\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7070\n",
      "           1       0.06      0.02      0.03        63\n",
      "\n",
      "    accuracy                           0.99      7133\n",
      "   macro avg       0.53      0.51      0.51      7133\n",
      "weighted avg       0.98      0.99      0.99      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.02181691247054718\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[7055   15]\n",
      " [  62    1]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.02531645569620253\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.010794896957801767\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.0019627085377822\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.01282051282051282\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.3728442137066567\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.02719678932967194\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[   1   62]\n",
      "  [  15 7055]]\n",
      "\n",
      " [[7055   15]\n",
      "  [  62    1]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 0.0625    , 1.        ]), array([1.        , 0.01587302, 0.        ]), array([0, 1]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.99128846, 0.0625    ]), array([0.99787836, 0.01587302]), array([0.9945725 , 0.02531646]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.0625\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.015873015873015872\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.5068756875687568\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0.        , 0.00212164, 1.        ]), array([0.        , 0.01587302, 1.        ]), array([2, 1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.01079489695780178\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators='warn',\n",
    "    criterion='gini',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight=None,\n",
    ")\n",
    "\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ul50DqyQObAS"
   },
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1244
    },
    "colab_type": "code",
    "id": "JRX8Tl6dObAT",
    "outputId": "09b52c0d-cfd2-419b-93b1-56f791474ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.9911678115799804\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.5\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7070\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.99      7133\n",
      "   macro avg       0.50      0.50      0.50      7133\n",
      "weighted avg       0.98      0.99      0.99      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[7070    0]\n",
      " [  63    0]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.30505298091677835\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[   0   63]\n",
      "  [   0 7070]]\n",
      "\n",
      " [[7070    0]\n",
      "  [  63    0]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 1.        ]), array([1., 0.]), array([0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.99116781, 0.        ]), array([1., 0.]), array([0.99556432, 0.        ]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.5\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0., 1.]), array([0., 1.]), array([1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.008832188420019649\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgc = XGBClassifier(\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    silent=True,\n",
    "    objective='binary:logistic',\n",
    "    booster='gbtree',\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=1,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,\n",
    "    missing=None\n",
    ")\n",
    "\n",
    "xgc.fit(X_train,y_train)\n",
    "\n",
    "y_pred = xgc.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhUoTJnIObAV"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "3_yNI6IZObAV",
    "outputId": "594789b3-79f3-4bea-9038-9414fa9e573f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.9798121407542408\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.025937001260228867\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.5807952223793807\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.020187859245759148\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7070\n",
      "           1       0.11      0.17      0.13        63\n",
      "\n",
      "    accuracy                           0.98      7133\n",
      "   macro avg       0.55      0.58      0.56      7133\n",
      "weighted avg       0.98      0.98      0.98      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.12291691572026298\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[6978   92]\n",
      " [  52   11]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.1325301204819277\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.020187859245759148\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.0113556708257396\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.07096774193548387\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.697274269428112\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.12673582114682663\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[  11   52]\n",
      "  [  92 6978]]\n",
      "\n",
      " [[6978   92]\n",
      "  [  52   11]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 0.10679612, 1.        ]), array([1.        , 0.17460317, 0.        ]), array([0, 1]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.99260313, 0.10679612]), array([0.98698727, 0.17460317]), array([0.98978723, 0.13253012]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.10679611650485436\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.1746031746031746\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.5807952223793809\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0.        , 0.01301273, 1.        ]), array([0.        , 0.17460317, 1.        ]), array([2, 1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.020187859245759165\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "naive = GaussianNB(\n",
    "    priors=None,\n",
    "    var_smoothing=1e-09)\n",
    "\n",
    "naive.fit(X_train, y_train)\n",
    "\n",
    "y_pred = naive.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_DcQMRLObAZ"
   },
   "source": [
    "## Stocastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1244
    },
    "colab_type": "code",
    "id": "0r8kbvT2ObAZ",
    "outputId": "9a934af5-ad63-4e86-9ea6-1a4be702e1bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.9911678115799804\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.5\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7070\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.99      7133\n",
      "   macro avg       0.50      0.50      0.50      7133\n",
      "weighted avg       0.98      0.99      0.99      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[7070    0]\n",
      " [  63    0]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.30505298091677835\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[   0   63]\n",
      "  [   0 7070]]\n",
      "\n",
      " [[7070    0]\n",
      "  [  63    0]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 1.        ]), array([1., 0.]), array([0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.99116781, 0.        ]), array([1., 0.]), array([0.99556432, 0.        ]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.5\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0., 1.]), array([0., 1.]), array([1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.008832188420019649\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "sgd = SGDClassifier(\n",
    "    loss='hinge',\n",
    "    penalty='l2',\n",
    "    alpha=0.0001,\n",
    "    l1_ratio=0.15,\n",
    "    fit_intercept=True,\n",
    "    max_iter=1000,\n",
    "    tol=0.001,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    epsilon=0.1,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    learning_rate='optimal',\n",
    "    eta0=0.0,\n",
    "    power_t=0.5,\n",
    "    early_stopping=False,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=5,\n",
    "    class_weight=None,\n",
    "    warm_start=False,\n",
    "    average=False,\n",
    ")\n",
    "\n",
    "sgd.fit(X_train, y_train)  \n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "710uP6UyObAb"
   },
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "t6wWXd33ObAc",
    "outputId": "18df36ee-16d0-421e-98ce-9118e8fafd32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.9894854899761671\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.009825781801107752\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.507017130284457\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.01051451002383289\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      7070\n",
      "           1       0.07      0.02      0.03        63\n",
      "\n",
      "    accuracy                           0.99      7133\n",
      "   macro avg       0.53      0.51      0.51      7133\n",
      "weighted avg       0.98      0.99      0.99      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.02283566250271707\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[7057   13]\n",
      " [  62    1]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.025974025974025972\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.01051451002383289\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.0016823216038133\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.013157894736842105\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.3631597678935792\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.029668528244599635\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[   1   62]\n",
      "  [  13 7057]]\n",
      "\n",
      " [[7057   13]\n",
      "  [  62    1]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 0.07142857, 1.        ]), array([1.        , 0.01587302, 0.        ]), array([0, 1]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.99129091, 0.07142857]), array([0.99816124, 0.01587302]), array([0.99471422, 0.02597403]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.07142857142857142\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.015873015873015872\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.507017130284457\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0.        , 0.00183876, 1.        ]), array([0.        , 0.01587302, 1.        ]), array([2, 1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.010514510023832857\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "bgclass = BaggingClassifier(\n",
    "    base_estimator=None,\n",
    "    n_estimators=10,\n",
    "    max_samples=1.0,\n",
    "    max_features=1.0,\n",
    "    bootstrap=True,\n",
    "    bootstrap_features=False,\n",
    "    oob_score=False,\n",
    "    warm_start=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "bgclass.fit(X_train,y_train)\n",
    "\n",
    "y_pred = bgclass.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hdxw0fDObAf"
   },
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1074
    },
    "colab_type": "code",
    "id": "fQD0-ZG3ObAf",
    "outputId": "eba07089-7ffa-4bb0-d4c5-0852d32c0e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.9908874246460115\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.012660248921289158\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.5077243438629577\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.009112575353988505\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7070\n",
      "           1       0.25      0.02      0.03        63\n",
      "\n",
      "    accuracy                           0.99      7133\n",
      "   macro avg       0.62      0.51      0.51      7133\n",
      "weighted avg       0.98      0.99      0.99      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.028826556795354952\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[7067    3]\n",
      " [  62    1]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.029850746268656716\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.009112575353988505\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.000280386933969\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.015151515151515152\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.3147375388281917\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.061055848801045344\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[   1   62]\n",
      "  [   3 7067]]\n",
      "\n",
      " [[7067    3]\n",
      "  [  62    1]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 0.25      , 1.        ]), array([1.        , 0.01587302, 0.        ]), array([0, 1]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.99130313, 0.25      ]), array([0.99957567, 0.01587302]), array([0.99542221, 0.02985075]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.25\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.015873015873015872\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.5077243438629576\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0.00000000e+00, 4.24328147e-04, 1.00000000e+00]), array([0.        , 0.01587302, 1.        ]), array([2, 1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.009112575353988461\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "abclass = AdaBoostClassifier(\n",
    "    base_estimator=None,\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    algorithm='SAMME.R',\n",
    "    random_state=None,\n",
    ")\n",
    "\n",
    "abclass.fit(X_train,y_train)\n",
    "\n",
    "y_pred = abclass.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QzVgwwd0ObAi"
   },
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dHOUv-2xTiSL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "vclass = VotingClassifier(\n",
    "    estimators=[('rfr', rfr), ('dtree', dtree)],\n",
    "    voting='hard',\n",
    "    weights=None,\n",
    "    n_jobs=None,\n",
    "    flatten_transform=True,\n",
    ")\n",
    "\n",
    "vclass.fit(X_train,y_train)\n",
    "\n",
    "y_pred = vclass.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGfn9nMOObAl"
   },
   "source": [
    "# Multi-layer perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1244
    },
    "colab_type": "code",
    "id": "EYcBx5twObAl",
    "outputId": "f2af5d67-500f-45ba-e4ad-994258455500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Accuracy Score : 0.9911678115799804\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AUC Metric : nan\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Average Precision Score : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Balanced Accuracy Score : 0.5\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Brier Score Loss : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7070\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.99      7133\n",
      "   macro avg       0.50      0.50      0.50      7133\n",
      "weighted avg       0.98      0.99      0.99      7133\n",
      "\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Cohen Kappa Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Confusion Matrix : [[7070    0]\n",
      " [  63    0]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "F1 Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hamming Loss : 0.008832188420019628\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Hinge Loss : 1.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Jaccard Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Log Loss : 0.30505298091677835\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Matthews Corr Coef : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Multilabel Confusion Matrix : [[[   0   63]\n",
      "  [   0 7070]]\n",
      "\n",
      " [[7070    0]\n",
      "  [  63    0]]]\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall Curve : (array([0.00883219, 1.        ]), array([1., 0.]), array([0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Recall FScore Support : (array([0.99116781, 0.        ]), array([1., 0.]), array([0.99556432, 0.        ]), array([7070,   63]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Precision Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Recall Score : 0.0\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC AUC Score : 0.5\n",
      "--------------------------------------------------------------------------------------------------\n",
      "ROC Curve : (array([0., 1.]), array([0., 1.]), array([1, 0]))\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Zero One Loss : 0.008832188420019649\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py:659: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.001,\n",
    "    power_t=0.5,\n",
    "    max_iter=200,\n",
    "    shuffle=True,\n",
    "    random_state=None,\n",
    "    tol=0.0001,\n",
    "    verbose=False,\n",
    "    warm_start=False,\n",
    "    momentum=0.9,\n",
    "    nesterovs_momentum=True,\n",
    "    early_stopping=False,\n",
    "    validation_fraction=0.1,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-08,\n",
    "    n_iter_no_change=10,\n",
    ")\n",
    "\n",
    "mlp.fit(X_train, y_train)                         \n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Accuracy Score :\",accuracy_score(y_test, y_pred)) \n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"AUC Metric :\",metrics.auc(fpr, tpr))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Average Precision Score :\",average_precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Balanced Accuracy Score :\",balanced_accuracy_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Brier Score Loss :\",brier_score_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Classification Report :\",classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Cohen Kappa Score :\",cohen_kappa_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Confusion Matrix :\",confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"F1 Score :\",f1_score(y_test, y_pred))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"FBeta Score :\",fbeta_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hamming Loss :\",hamming_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Hinge Loss :\",hinge_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Jaccard Score :\",jaccard_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Log Loss :\",log_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Matthews Corr Coef :\",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Multilabel Confusion Matrix :\",multilabel_confusion_matrix(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall Curve :\",precision_recall_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Recall FScore Support :\",precision_recall_fscore_support(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Precision Score :\",precision_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Recall Score :\",recall_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC AUC Score :\",roc_auc_score(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"ROC Curve :\",roc_curve(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Zero One Loss :\",zero_one_loss(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rl5P706XObAo"
   },
   "source": [
    "## MultiOutput Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "rNWucHnsObAp",
    "outputId": "79d576e6-f944-412e-ce2d-ab7ee5bbfdbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 0],\n",
       "       [1, 2, 1],\n",
       "       [2, 1, 0],\n",
       "       [0, 0, 2],\n",
       "       [0, 2, 1],\n",
       "       [0, 0, 2],\n",
       "       [1, 1, 0],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 2],\n",
       "       [2, 0, 0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "X, y = make_classification(n_samples=10, n_features=100, n_informative=30, n_classes=3, random_state=1)\n",
    "y2 = shuffle(y, random_state=1)\n",
    "y3 = shuffle(y, random_state=2)\n",
    "Y = np.vstack((y, y2, y3)).T\n",
    "n_samples, n_features = X.shape\n",
    "n_outputs = Y.shape[1] \n",
    "n_classes = 3\n",
    "forest = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "multi_target_forest = MultiOutputClassifier(forest, n_jobs=-1)\n",
    "multi_target_forest.fit(X, Y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohUiz2wHObAr"
   },
   "source": [
    "## MultiOutput Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Qb7iP6jNObAs",
    "outputId": "c3c73097-7a3c-4757-ff4f-dc7350fc44bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-154.75474165, -147.03498585,  -50.03812219],\n",
       "       [   7.12165031,    5.12914884,  -81.46081961],\n",
       "       [-187.8948621 , -100.44373091,   13.88978285],\n",
       "       [-141.62745778,   95.02891072, -191.48204257],\n",
       "       [  97.03260883,  165.34867495,  139.52003279],\n",
       "       [ 123.92529176,   21.25719016,   -7.84253   ],\n",
       "       [-122.25193977,  -85.16443186, -107.12274212],\n",
       "       [ -30.170388  ,  -94.80956739,   12.16979946],\n",
       "       [ 140.72667194,  176.50941682,  -17.50447799],\n",
       "       [ 149.37967282,  -81.15699552,   -5.72850319]])"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "X, y = make_regression(n_samples=10, n_targets=3, random_state=1)\n",
    "MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2uKo7qNObAt"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vti7H4QAUK7I"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(\n",
    "    estimator,\n",
    "    threshold=None,\n",
    "    prefit=False,\n",
    "    norm_order=1,\n",
    "    max_features=None,\n",
    ")\n",
    "X_new = model.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BIKroXDObAv"
   },
   "source": [
    "# Semi - Supervised Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WenMA__KObAv"
   },
   "source": [
    "## Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "d4Bk4CNeObAw",
    "outputId": "7c88ca34-c988-4772-cf54-9bd5acf064bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:288: ConvergenceWarning: max_iter=1 was reached without convergence.\n",
      "  category=ConvergenceWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score : -0.23311331133113344\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "label_prop_model = LabelPropagation(\n",
    "    kernel='rbf',\n",
    "    gamma=20,\n",
    "    n_neighbors=7,\n",
    "    max_iter=1,\n",
    "    tol=0.001,\n",
    "    n_jobs=None,\n",
    ")\n",
    "\n",
    "label_prop_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = label_prop_model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score :\",metrics.r2_score(y_test,y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RstKqnOZObAy"
   },
   "source": [
    "## Label Spreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Xal0JxVqObAy",
    "outputId": "809e3970-a23d-48bf-9544-8c60b636b44b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:288: ConvergenceWarning: max_iter=1 was reached without convergence.\n",
      "  category=ConvergenceWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------\n",
      "R2 Score : -0.23311331133113344\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    "label_prop_model = LabelSpreading(\n",
    "    kernel='rbf',\n",
    "    gamma=20,\n",
    "    n_neighbors=7,\n",
    "    max_iter=1,\n",
    "    tol=0.001,\n",
    "    n_jobs=None,\n",
    ")\n",
    "\n",
    "label_prop_model.fit(X_train,y_train)\n",
    "\n",
    "y_pred = label_prop_model.predict(X_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"R2 Score :\",metrics.r2_score(y_test,y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5igebqhObA0"
   },
   "source": [
    "# Unsupervised Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErdgQA1lObA0"
   },
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "8IHvxCuqObA1",
    "outputId": "c213a55d-2ffd-4274-af86-2ee7808a80e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 3 ... 3 0 1]\n",
      "[[2.74295223e+00 1.23820889e+03 1.31959671e+00 1.50650940e+00]\n",
      " [3.97142857e+00 2.95975111e+03 1.72730159e+00 2.64920635e+00]\n",
      " [4.33989501e+00 4.46663780e+03 1.90879265e+00 3.49606299e+00]\n",
      " [3.46813187e+00 2.01567070e+03 1.47802198e+00 2.17861722e+00]]\n",
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Calinski Harabasz Score : 32526.736957525507\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Davies Bouldin Score : 0.5566293464169927\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Score : 0.5422620112860752\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Samples : [0.35219067 0.71658154 0.38709775 ... 0.73079125 0.47518937 0.70869416]\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import calinski_harabasz_score\n",
    "from sklearn.metrics.cluster import davies_bouldin_score\n",
    "from sklearn.metrics.cluster import completeness_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics.cluster import fowlkes_mallows_score\n",
    "from sklearn.metrics.cluster import homogeneity_completeness_v_measure\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from sklearn.metrics.cluster import mutual_info_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "from sklearn.metrics.cluster import silhouette_samples\n",
    "from sklearn.metrics.cluster import v_measure_score\n",
    "\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=4,\n",
    "    init='k-means++',\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=0.0001,\n",
    "    precompute_distances='auto',\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "    copy_x=True,\n",
    "    n_jobs=None,\n",
    "    algorithm='auto',\n",
    ").fit(X_train)\n",
    "\n",
    "print(kmeans.labels_)\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "kmeans.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,kmeans.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,kmeans.labels_))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Completeness Score :\",completeness_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Score :\",silhouette_score(X_train,kmeans.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Samples :\",silhouette_samples(X_train,kmeans.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ePQav-eObA4"
   },
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZi2JwaNVSq3"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "spec = SpectralClustering(\n",
    "    n_clusters=4,\n",
    "    eigen_solver=None,\n",
    "    random_state=None,\n",
    "    n_init=10,\n",
    "    gamma=1.0,\n",
    "    affinity='rbf',\n",
    "    n_neighbors=10,\n",
    "    eigen_tol=0.0,\n",
    "    assign_labels='kmeans',\n",
    "    degree=3,\n",
    "    coef0=1,\n",
    "    kernel_params=None,\n",
    "    n_jobs=None,\n",
    ").fit(X_train)\n",
    "\n",
    "print(spec.labels_)\n",
    "print(spec.cluster_centers_)\n",
    "\n",
    "spec.predict(X_test)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,spec.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,spec.labels_))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Completeness Score :\",completeness_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Score :\",silhouette_score(X_train,spec.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Samples :\",silhouette_samples(X_train,spec.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFkxIsVRObA6"
   },
   "source": [
    "## DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "cQuG0bvFObA6",
    "outputId": "e6fa99b6-16c1-4c40-c1e0-e103dbd2620f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2 ... 369  -1 516]\n",
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Calinski Harabasz Score : 20.34504046130372\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Davies Bouldin Score : 4.8839357456327575\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Score : 0.1700204070337957\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Samples : [ 0.4850618   0.81076289  0.63390284 ...  0.87110883 -0.89222697\n",
      "  0.963909  ]\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(\n",
    "    eps=0.5,\n",
    "    min_samples=5,\n",
    "    metric='euclidean',\n",
    "    metric_params=None,\n",
    "    algorithm='auto',\n",
    "    leaf_size=30,\n",
    "    p=None,\n",
    "    n_jobs=None,\n",
    ").fit(X_train)\n",
    "\n",
    "print(dbscan.labels_)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,dbscan.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,dbscan.labels_))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Completeness Score :\",completeness_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Score :\",silhouette_score(X_train,dbscan.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Samples :\",silhouette_samples(X_train,dbscan.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RGExIsgObA9"
   },
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "kN0BfeOzObA9",
    "outputId": "76563fd8-c8c8-4937-8e0a-3c418394926f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 0]\n",
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Calinski Harabasz Score : 23781.015897196357\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Davies Bouldin Score : 0.5953727648396083\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Score : 0.5918015713057287\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Samples : [0.43616478 0.38290124 0.72894623 ... 0.41220805 0.56112077 0.63895725]\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "aggclus = AgglomerativeClustering(\n",
    "    n_clusters=2,\n",
    "    affinity='euclidean',\n",
    "    memory=None,\n",
    "    connectivity=None,\n",
    "    compute_full_tree='auto',\n",
    "    linkage='ward',\n",
    "    pooling_func='deprecated',\n",
    "    distance_threshold=None,\n",
    ").fit(X_train)\n",
    "\n",
    "print(aggclus.labels_)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,aggclus.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,aggclus.labels_))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Completeness Score :\",completeness_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Score :\",silhouette_score(X_train,aggclus.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Samples :\",silhouette_samples(X_train,aggclus.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fs8vledkObBA"
   },
   "source": [
    "## Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_Qmh130ObBA"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "affclus = AffinityPropagation(\n",
    "    damping=0.5,\n",
    "    max_iter=5,\n",
    "    convergence_iter=15,\n",
    "    copy=True,\n",
    "    preference=None,\n",
    "    affinity='euclidean',\n",
    "    verbose=False,\n",
    ").fit(X_train)\n",
    "\n",
    "print(affclus.labels_)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,affclus.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,affclus.labels_))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Completeness Score :\",completeness_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Score :\",silhouette_score(X_train,affclus.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Samples :\",silhouette_samples(X_train,affclus.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19B06bMOObBC"
   },
   "source": [
    "## OPTICS Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "JvcnHZL7ObBD",
    "outputId": "5a0abec4-88fa-41d2-be74-972c12bfafd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/optics_.py:795: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ratio = reachability_plot[:-1] / reachability_plot[1:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   3   8 ... 126  -1 943]\n",
      "*************************************| Error / Accuracy Metrics |************************************\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Calinski Harabasz Score : 14.270531803286424\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Davies Bouldin Score : 5.1442510762486675\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Score : 0.21567074450206808\n",
      "--------------------------------------------------------------------------------------------------\n",
      "Silhouette Samples : [-0.01008472  0.81553195  0.53972157 ...  1.         -0.87959254\n",
      "  0.93652039]\n",
      "--------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "optics = OPTICS(\n",
    "    min_samples=5,\n",
    "    max_eps=1,\n",
    "    metric='minkowski',\n",
    "    p=2,\n",
    "    metric_params=None,\n",
    "    cluster_method='xi',\n",
    "    eps=None,\n",
    "    xi=0.05,\n",
    "    predecessor_correction=True,\n",
    "    min_cluster_size=None,\n",
    "    algorithm='auto',\n",
    "    leaf_size=30,\n",
    "    n_jobs=None,\n",
    ").fit(X_train)\n",
    "\n",
    "print(optics.labels_)\n",
    "\n",
    "print(\"*************************************| Error / Accuracy Metrics |************************************\")\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Mutual Info Score :\",adjusted_mutual_info_score(X_test)) \n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Adjusted Rand Score :\",adjusted_rand_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Calinski Harabasz Score :\",calinski_harabasz_score(X_train,optics.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Davies Bouldin Score :\",davies_bouldin_score(X_train,optics.labels_))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Completeness Score :\",completeness_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Contingency Matrix :\",contingency_matrix(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Fowlkes Mallows Score :\",fowlkes_mallows_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Completeness V Measure :\",homogeneity_completeness_v_measure(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Homogeneity Score :\",homogeneity_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Mutual Info Score :\",mutual_info_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"Normalized Mutual Info Score :\",normalized_mutual_info_score(X_test))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Score :\",silhouette_score(X_train,optics.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "print(\"Silhouette Samples :\",silhouette_samples(X_train,optics.labels_))\n",
    "print(\"--------------------------------------------------------------------------------------------------\")\n",
    "#print(\"V Measure Score :\",v_measure_score(X_test))\n",
    "#print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "eMOXa3BNObBF",
    "outputId": "206acb3c-a6a7-4acd-b13c-ca2f131b4414"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/lof.py:236: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    algorithm='auto',\n",
    "    leaf_size=30,\n",
    "    metric='minkowski',\n",
    "    p=2,\n",
    "    metric_params=None,\n",
    "    contamination='legacy',\n",
    "    novelty=False,\n",
    "    n_jobs=None,\n",
    ").fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8VydnOWXBWQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(linreg,X,y, cv=5) \n",
    "print(scores)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHpw-P3IObBI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2)\n",
    "for X_ktrain, X_ktest in kf.split(X):\n",
    "    print(\"%s %s\" % (X_ktrain,X_ktest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvCeHsYIObBJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=None)\n",
    "for X_rtrain, X_rtest in rkf.split(X):\n",
    "    print(\"%s %s\" % (X_rtrain, X_rtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H36W7jwEObBK"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_stored = pickle.dumps(linreg)\n",
    "model_loaded = pickle.loads(model_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4dukVfsaObBM"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "estimators = [(\n",
    "    \n",
    "                'reduce_dim', \n",
    "                PCA(\n",
    "                n_components=None,\n",
    "                copy=True,\n",
    "                whiten=False,\n",
    "                svd_solver='auto',\n",
    "                tol=0.0,\n",
    "                iterated_power='auto',\n",
    "                random_state=None,\n",
    "    )\n",
    "\n",
    "),(\n",
    "    \n",
    "                'linreg', \n",
    "                LinearRegression(\n",
    "                fit_intercept=True,\n",
    "                normalize=False,\n",
    "                copy_X=True,\n",
    "                n_jobs=None,\n",
    "                )\n",
    "\n",
    ")]\n",
    "\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "pipe \n",
    "\n",
    "Pipeline(memory=None,\n",
    "         steps=[('reduce_dim', PCA(copy=True)),\n",
    "                ('linreg', LinearRegression(fit_intercept=True,normalize=False,copy_X=True,n_jobs=None,))], \n",
    "                 verbose=False)\n",
    "\n",
    "print(pipe.steps[0])\n",
    "print(pipe[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_cGCgDrObBN"
   },
   "source": [
    "# Neuro-linguistic programming (NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "864O-bK8ObBO"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    input='content',\n",
    "    encoding='utf-8',\n",
    "    decode_error='strict',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words=None,\n",
    "    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=1.0,\n",
    "    min_df=1,\n",
    "    max_features=None,\n",
    "    vocabulary=None,\n",
    "    binary=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ym76sSuBObBQ",
    "outputId": "e71746bf-e9be-4b0d-b1d6-4a9dae2b29fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x12 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['This is an example of NLP',\n",
    "          'This is the first document.',\n",
    "          'And the second one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mXCp3TN6ObBU",
    "outputId": "86810646-5489-415d-b0c6-cfc5e0a6780d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "analyze(\"This is a text document to analyze.\") == (['this', 'is', 'text', 'document', 'analyze'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "OftttK-PObBW",
    "outputId": "5358770f-3cbf-473d-9104-c4ee9f8aacfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()\n",
    "X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x1Dh_cpwObBY",
    "outputId": "e2565d8b-9395-4bc5-ac3d-4039d2402435"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6MewG2mHObBb",
    "outputId": "471a76db-fcbd-40f8-f028-b06baef20d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2),\n",
    "                                     token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "analyze = bigram_vectorizer.build_analyzer()\n",
    "analyze('Bi-grams are cool!') == (['bi', 'grams', 'are', 'cool', 'bi grams', 'grams are', 'are cool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "rqg0t56yObBe",
    "outputId": "6fb6a8bc-f3e1-41e4-f8b5-548be9dd1a88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = bigram_vectorizer.fit_transform(corpus).toarray()\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "61OekX4MObBj",
    "outputId": "72ef1934-21d8-4a97-f7a7-7e229c66acdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46714844, 0.        , 0.        , 0.46714844, 0.        ,\n",
       "        0.25208067, 0.46714844, 0.46714844, 0.        , 0.        ,\n",
       "        0.        , 0.25208067],\n",
       "       [0.        , 0.        , 0.51741994, 0.        , 0.51741994,\n",
       "        0.3935112 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3935112 , 0.3935112 ],\n",
       "       [0.        , 0.55121857, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.55121857, 0.55121857,\n",
       "        0.29744623, 0.        ],\n",
       "       [0.        , 0.        , 0.51741994, 0.        , 0.51741994,\n",
       "        0.3935112 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3935112 , 0.3935112 ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "\n",
    "TfidfTransformer(norm='l2', smooth_idf=False, sublinear_tf=False,\n",
    "                 use_idf=True)\n",
    "\n",
    "tfidf = transformer.fit_transform(X.toarray())\n",
    "tfidf.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tCf6J99mObBn",
    "outputId": "654f1a4f-e363-4b9c-a0f7-04118af73966"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 1, 0, 1, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
    "counts = ngram_vectorizer.fit_transform(['words', 'wprds'])\n",
    "ngram_vectorizer.get_feature_names() == ([' w', 'ds', 'or', 'pr', 'rd', 's ', 'wo', 'wp'])\n",
    "\n",
    "counts.toarray().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "CGuNGLTCObBp",
    "outputId": "1e2ebd2f-bb4d-47b1-ad28-3d819b0564b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(5, 5))\n",
    "ngram_vectorizer.fit_transform(['jumpy fox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GcXic02dObBr"
   },
   "source": [
    "## Vader Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "colab_type": "code",
    "id": "xhg1U3L-ObBs",
    "outputId": "2f111793-c03a-4516-ceeb-9d1a83df8e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.2.1\n",
      "The food was good.-------------------------------- {'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n",
      "The service was not very good!-------------------- {'neg': 0.368, 'neu': 0.632, 'pos': 0.0, 'compound': -0.4432}\n",
      "Not bad at all------------------------------------ {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.431}\n",
      "The service was horrible-------------------------- {'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentences = [\"The food was good.\",\n",
    "             \"The service was not very good!\", \n",
    "             \"Not bad at all\",\n",
    "             \"The service was horrible\"]\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<50} {}\".format(sentence, str(vs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "96g1Opq2ObBu"
   },
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "colab_type": "code",
    "id": "SXGi9aZSObBv",
    "outputId": "c1cef993-06a6-4e4f-c9df-b359ed16cf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.6.0)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.2->spacy) (4.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\n",
      "Verbs: ['start', 'work', 'drive', 'take', 'can', 'tell', 'would', 'shake', 'turn', 'be', 'talk', 'say']\n",
      "Sebastian Thrun PERSON\n",
      "Google ORG\n",
      "2007 DATE\n",
      "American NORP\n",
      "Thrun PERSON\n",
      "Recode ORG\n",
      "earlier this week DATE\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "import spacy\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ax8C7TJEObBy",
    "outputId": "a92a702a-64ba-48fe-8d69-ba216dfc92b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple 0 5 ORG\n",
      "U.K. 27 31 GPE\n",
      "$1 billion 44 54 MONEY\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "vqKXW_CdObBz",
    "outputId": "0c087014-06f6-4688-957b-c92299ffba3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(u\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YH4TLd5XObB1",
    "outputId": "95d26ff9-f155-490e-83c0-0f404fb3bbef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', '-', 'world.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "prefix_re = re.compile(r'''^[[(\"']''')\n",
    "suffix_re = re.compile(r'''[])\"']$''')\n",
    "infix_re = re.compile(r'''[-~]''')\n",
    "simple_url_re = re.compile(r'''^https?://''')\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab, prefix_search=prefix_re.search,\n",
    "                                suffix_search=suffix_re.search,\n",
    "                                infix_finditer=infix_re.finditer,\n",
    "                                token_match=simple_url_re.match)\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "doc = nlp(u\"hello-world.\")\n",
    "\n",
    "print([t.text for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7XkQhjFsObB3",
    "outputId": "15285b24-cc7e-4745-edd4-92787218406b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['I', 'live', 'in', 'New', 'York']\n",
      "After: ['I', 'live', 'in', 'New York']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(\"I live in New York\")\n",
    "\n",
    "print(\"Before:\", [token.text for token in doc])\n",
    "\n",
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[3:5], attrs={\"LEMMA\": \"new york\"})\n",
    "    \n",
    "print(\"After:\", [token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "O-8ZcdbCObB6",
    "outputId": "12d2f7d5-1274-45f8-b851-7d8f17a5a180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(u\"This is a sentence. This is another sentence.\")\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vVqamYu8ObB8",
    "outputId": "6bab806c-e59c-4ba3-b25d-8ed25d7037fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAPPY 😀\n",
      "HASHTAG #MondayMotivation\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = English()  # We only want the tokenizer, so no need to load a model\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pos_emoji = [u\"😀\", u\"😃\", u\"😂\", u\"🤣\", u\"😊\", u\"😍\"]  # Positive emoji\n",
    "neg_emoji = [u\"😞\", u\"😠\", u\"😩\", u\"😢\", u\"😭\", u\"😒\"]  # Negative emoji\n",
    "\n",
    "# Add patterns to match one or more emoji tokens\n",
    "pos_patterns = [[{\"ORTH\": emoji}] for emoji in pos_emoji]\n",
    "neg_patterns = [[{\"ORTH\": emoji}] for emoji in neg_emoji]\n",
    "\n",
    "# Function to label the sentiment\n",
    "def label_sentiment(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    if doc.vocab.strings[match_id] == \"HAPPY\":  # Don't forget to get string!\n",
    "        doc.sentiment += 0.1  # Add 0.1 for positive sentiment\n",
    "    elif doc.vocab.strings[match_id] == \"SAD\":\n",
    "        doc.sentiment -= 0.1  # Subtract 0.1 for negative sentiment\n",
    "\n",
    "matcher.add(\"HAPPY\", label_sentiment, *pos_patterns)  # Add positive pattern\n",
    "matcher.add(\"SAD\", label_sentiment, *neg_patterns)  # Add negative pattern\n",
    "\n",
    "# Add pattern for valid hashtag, i.e. '#' plus any ASCII token\n",
    "matcher.add(\"HASHTAG\", None, [{\"ORTH\": \"#\"}, {\"IS_ASCII\": True}])\n",
    "\n",
    "doc = nlp(u\"Hello world 😀 #MondayMotivation\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = doc.vocab.strings[match_id]  # Look up string ID\n",
    "    span = doc[start:end]\n",
    "    print(string_id, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "omAbFScpObB-",
    "outputId": "5f6263e1-6f77-4b94-db1c-494531accdbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Alex Smith', 'PERSON'), ('first', 'ORDINAL'), ('Acme Corp Inc.', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(\"Dr Alex Smith chaired first board meeting of Acme Corp Inc.\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "l-U3ecwVObCA",
    "outputId": "12a35b94-c64e-4772-bbeb-9e2c89e7861d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'person': Alex Smith, 'orgs': [Acme Corp Inc.], 'past': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"61ef71ef3d4248f4996491a946b1ace0-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Alex Smith</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NNP</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">worked</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VBD</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">at</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">IN</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Acme Corp Inc.</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NNP</tspan>\\n</text>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-61ef71ef3d4248f4996491a946b1ace0-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-61ef71ef3d4248f4996491a946b1ace0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-61ef71ef3d4248f4996491a946b1ace0-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-61ef71ef3d4248f4996491a946b1ace0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-61ef71ef3d4248f4996491a946b1ace0-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-61ef71ef3d4248f4996491a946b1ace0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\\n</g>\\n</svg>'"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import merge_entities\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "def extract_person_orgs(doc):\n",
    "    person_entities = [ent for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    for ent in person_entities:\n",
    "        head = ent.root.head\n",
    "        if head.lemma_ == \"work\":\n",
    "            preps = [token for token in head.children if token.dep_ == \"prep\"]\n",
    "            for prep in preps:\n",
    "                orgs = [token for token in prep.children if token.ent_type_ == \"ORG\"]\n",
    "                print({'person': ent, 'orgs': orgs, 'past': head.tag_ == \"VBD\"})\n",
    "    return doc\n",
    "\n",
    "# To make the entities easier to work with, we'll merge them into single tokens\n",
    "nlp.add_pipe(merge_entities)\n",
    "nlp.add_pipe(extract_person_orgs)\n",
    "\n",
    "doc = nlp(\"Alex Smith worked at Acme Corp Inc.\")\n",
    "# If you're not in a Jupyter / IPython environment, use displacy.serve\n",
    "displacy.render(doc, options={'fine_grained': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "bublqtX5ObCB",
    "outputId": "71b86262-9b5e-492b-b530-7392a054c20c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'ent' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n",
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"\"\"But Google is starting from behind. The company made a late push\n",
    "into hardware, and Apple’s Siri, available on iPhones, and Amazon’s Alexa\n",
    "software, which runs on its Echo and Dot devices, have clear leads in\n",
    "consumer adoption.\"\"\"\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(text)\n",
    "displacy.serve(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MHy51afObCD"
   },
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Oc0_AxXZObCD",
    "outputId": "2545e0eb-4895-467f-9066-6397b4dfc6a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program  :  program\n",
      "programs  :  program\n",
      "programer  :  program\n",
      "programing  :  program\n",
      "programers  :  program\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "  \n",
    "# choose some words to be stemmed \n",
    "words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"] \n",
    "  \n",
    "for w in words: \n",
    "    print(w, \" : \", ps.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "py6XbQ36ObCF",
    "outputId": "371a0ec6-575e-4c16-9706-80132169eb4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "Programers  :  program\n",
      "program  :  program\n",
      "with  :  with\n",
      "programing  :  program\n",
      "languages  :  languag\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "   \n",
    "sentence = \"Programers program with programing languages\"\n",
    "words = word_tokenize(sentence) \n",
    "   \n",
    "for w in words: \n",
    "    print(w, \" : \", ps.stem(w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "JTOYTn3QObCK",
    "outputId": "0bd30b59-8ff3-4643-d073-72de52ad4578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/names.zip.\n",
      "male\n",
      "0.7634336378291241\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "from nltk.corpus import names \n",
    "import nltk \n",
    "nltk.download('names')\n",
    "  \n",
    "def gender_features(word): \n",
    "    return {'last_letter':word[-1]} \n",
    "  \n",
    "# preparing a list of examples and corresponding class labels. \n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')]+\n",
    "             [(name, 'female') for name in names.words('female.txt')]) \n",
    "  \n",
    "random.shuffle(labeled_names) \n",
    "  \n",
    "# we use the feature extractor to process the names data. \n",
    "featuresets = [(gender_features(n), gender)  \n",
    "               for (n, gender)in labeled_names] \n",
    "  \n",
    "# Divide the resulting list of feature \n",
    "# sets into a training set and a test set. \n",
    "train_set, test_set = featuresets[500:], featuresets[:500] \n",
    "  \n",
    "# The training set is used to  \n",
    "# train a new \"naive Bayes\" classifier. \n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "  \n",
    "print(classifier.classify(gender_features('Myron'))) \n",
    "  \n",
    "# output should be 'male' \n",
    "print(nltk.classify.accuracy(classifier, train_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "YDCHJb5iObCM",
    "outputId": "429e5ad1-7e6b-408c-858b-591d2a65448d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     36.5 : 1.0\n",
      "             last_letter = 'k'              male : female =     32.4 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.1 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.3 : 1.0\n",
      "             last_letter = 'v'              male : female =     10.6 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.1 : 1.0\n",
      "             last_letter = 'm'              male : female =      9.6 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.6 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.6 : 1.0\n",
      "             last_letter = 'w'              male : female =      5.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "bTAo2IYbObDv",
    "outputId": "fb20226c-d8a0-4c85-851a-0e53e8ec209d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "nltk.download('wordnet')  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YDATTLs8ObDw"
   },
   "source": [
    "## TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "zs-4OueQObDx",
    "outputId": "9eabe4ce-a22e-4a5f-e9c3-4338fd2a311f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('brown')\n",
    " \n",
    "text = \"The service was good\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "blob.tags          \n",
    "\n",
    "blob.noun_phrases   \n",
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g3eXb6KdObDz",
    "outputId": "6dd3d554-a948-4d56-f628-91d734ac6c35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallibility', 1.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word('falibility')\n",
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "43WlBL-tObD0",
    "outputId": "bdc7e445-7aa0-4d7b-e5db-c84e63d2f4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buenos días\n",
      "Bonjour\n",
      "早上好\n",
      "صباح الخير\n"
     ]
    }
   ],
   "source": [
    "en_blob = TextBlob(u'Good Morning')\n",
    "print(en_blob.translate(to='es'))\n",
    "print(en_blob.translate(to='fr'))\n",
    "print(en_blob.translate(to='zh-CN'))\n",
    "print(en_blob.translate(to='ar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NPB4VPnyObD2",
    "outputId": "d6a47109-a964-4be7-ec4d-22ea480ee208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar'"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(u\"بسيط هو أفضل من مجمع\")\n",
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "0UjbZuKJObD4",
    "outputId": "13b2ca05-d818-4871-f973-e4636b875520"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob(\"Now is better than never.\")\n",
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "77avOTNWObD6",
    "outputId": "3f181dbe-a60e-4940-c666-7c1cd327a172"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chop.v.05'),\n",
       " Synset('hack.v.02'),\n",
       " Synset('hack.v.03'),\n",
       " Synset('hack.v.04'),\n",
       " Synset('hack.v.05'),\n",
       " Synset('hack.v.06'),\n",
       " Synset('hack.v.07'),\n",
       " Synset('hack.v.08')]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "from textblob.wordnet import VERB\n",
    "word = Word(\"octopus\")\n",
    "word.synsets\n",
    "Word(\"hack\").get_synsets(pos=VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "n6h9Ma-3ObD8",
    "outputId": "1f14b50c-f2a4-4587-d970-57c0755ef702"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['water falling in drops from vapor condensed in the atmosphere',\n",
       " 'drops of fresh water that fall as precipitation from clouds',\n",
       " 'anything happening rapidly or in quick successive',\n",
       " 'precipitate as rain']"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Word(\"rain\").definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3495hNF2ObD-"
   },
   "source": [
    "# TensorFlow + Keras (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "J4Zcq987ObD_",
    "outputId": "136a0815-b012-4a85-92d5-9842ea0f1ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14480, 4)\n",
      "(14480,)\n",
      "(7133, 4)\n",
      "(7133,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpciJN59ObEA"
   },
   "source": [
    "## Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79C1LACWYhab"
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.Dense(\n",
    "    units,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IX5AsGRSObEB"
   },
   "source": [
    "## Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6lWGZoYObEB"
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.Conv1D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=1,\n",
    "    padding='valid',\n",
    "    data_format='channels_last',\n",
    "    dilation_rate=1,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None\n",
    ")\n",
    "\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    padding='valid',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdvvRfKsObEC"
   },
   "source": [
    "## Pooling Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPQQrcwYObED"
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.MaxPooling1D(\n",
    "    pool_size=2,\n",
    "    strides=None,\n",
    "    padding='valid',\n",
    "    data_format='channels_last'\n",
    ")\n",
    "\n",
    "tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=None,\n",
    "    padding='valid',\n",
    "    data_format=None\n",
    ")\n",
    "\n",
    "tf.keras.layers.MaxPooling3D(\n",
    "    pool_size=(2, 2, 2),\n",
    "    strides=None,\n",
    "    padding='valid',\n",
    "    data_format=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nbmZ-sT1ObEF"
   },
   "source": [
    "## Locally Connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff2NJAp4ObEF"
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.LocallyConnected1D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=1,\n",
    "    padding='valid',\n",
    "    data_format=None,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    implementation=1\n",
    ")\n",
    "\n",
    "tf.keras.layers.LocallyConnected2D(\n",
    "    filters,\n",
    "    kernel_size,\n",
    "    strides=(1, 1),\n",
    "    padding='valid',\n",
    "    data_format=None,\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    implementation=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXz-SbzBObEH"
   },
   "source": [
    "## Flatten Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfhniZPkObEH"
   },
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3),input_shape=(3, 32, 32), padding='same',))\n",
    "# now: model.output_shape == (None, 64, 32, 32)\n",
    "model.add(Flatten())\n",
    "# now: model.output_shape == (None, 65536)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OmFKvJz5ObEJ"
   },
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFsKH8_QObEJ"
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.RNN(\n",
    "    cell,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False,\n",
    "    time_major=False\n",
    ")\n",
    "\n",
    "tf.keras.layers.SimpleRNN(\n",
    "    units,\n",
    "    activation='tanh',\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    recurrent_initializer='orthogonal',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False\n",
    ")\n",
    "\n",
    "tf.keras.layers.GRU(\n",
    "    units,\n",
    "    activation='tanh',\n",
    "    recurrent_activation='sigmoid',\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    recurrent_initializer='orthogonal',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    implementation=2,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    unroll=False,\n",
    "    time_major=False,\n",
    "    reset_after=True\n",
    ")\n",
    "\n",
    "tf.keras.layers.LSTM(\n",
    "    units,\n",
    "    activation='tanh',\n",
    "    recurrent_activation='sigmoid',\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    recurrent_initializer='orthogonal',\n",
    "    bias_initializer='zeros',\n",
    "    unit_forget_bias=True,\n",
    "    kernel_regularizer=None,\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    dropout=0.0,\n",
    "    recurrent_dropout=0.0,\n",
    "    implementation=2,\n",
    "    return_sequences=False,\n",
    "    return_state=False,\n",
    "    go_backwards=False,\n",
    "    stateful=False,\n",
    "    time_major=False,\n",
    "    unroll=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgWny6BXObEL"
   },
   "source": [
    "## Advanced Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFDPNbAlObEM",
    "outputId": "09c5f108-c8c4-4413-c398-0a60956a3915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.advanced_activations.ThresholdedReLU at 0x14db90c50>"
      ]
     },
     "execution_count": 156,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.ReLU(max_value=None, negative_slope=0.0, threshold=0.0)\n",
    "tf.keras.layers.ELU(alpha=1.0) # Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n",
    "tf.keras.layers.Softmax(axis=-1)\n",
    "tf.keras.layers.LeakyReLU(alpha=0.3) #Rectifier Nonlinearities Improve Neural Network Acoustic Models\n",
    "tf.keras.layers.PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None) #Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n",
    "tf.keras.layers.ThresholdedReLU(theta=1.0) #Zero-Bias Autoencoders and the Benefits of Co-Adapting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XK3N72_ObEO"
   },
   "source": [
    "### Embedding Layer - A Theoretically Grounded Application of Dropout in Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0ip5KODObEO"
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okUYaaQrObEP"
   },
   "source": [
    "### Accelerating Deep Network Training (Reducing Internal Covariate Shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNEffp3eObEQ",
    "outputId": "66a60d26-45fa-4f32-909e-2ec5f0285580"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x14db90f28>"
      ]
     },
     "execution_count": 154,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.99,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mNrnRKXObES"
   },
   "source": [
    "### Prevent Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MttI9j8UObES"
   },
   "outputs": [],
   "source": [
    "tf.keras.layers.Dropout(rate, noise_shape=None, seed=None, **kwargs)\n",
    "tf.keras.layers.GaussianNoise(stddev)\n",
    "tf.keras.layers.GaussianDropout(rate)\n",
    "tf.keras.layers.AlphaDropout(rate, noise_shape=None, seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aa4fIuAoObET"
   },
   "source": [
    "### Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEjSJjvXObET"
   },
   "outputs": [],
   "source": [
    "tf.keras.activations.elu(x, alpha=1.0)\n",
    "tf.keras.activations.exponential(x)\n",
    "tf.keras.activations.hard_sigmoid(x)\n",
    "tf.keras.activations.linear(x)\n",
    "tf.keras.activations.relu(x, alpha=0.0, max_value=None, threshold=0)\n",
    "tf.keras.activations.selu(x)\n",
    "tf.keras.activations.sigmoid(x)\n",
    "tf.keras.activations.tanh(x)\n",
    "tf.keras.activations.softmax(x, axis=-1)\n",
    "tf.keras.activations.softplus(x)\n",
    "tf.keras.activations.softsign(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irVTV48QObEU"
   },
   "source": [
    "### Regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohlEPZPdObEU"
   },
   "outputs": [],
   "source": [
    "# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# A linear layer with L1 & L2 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qd2PHdWlObEV"
   },
   "source": [
    "### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QhyYQxWPObEV",
    "outputId": "6551a91f-66b9-4bf0-e78f-93580f4c9873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.CategoricalCrossentropy at 0x14d8d7240>"
      ]
     },
     "execution_count": 153,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.CategoricalAccuracy()\n",
    "tf.keras.metrics.Accuracy()\n",
    "tf.keras.metrics.AUC()\n",
    "tf.keras.metrics.BinaryAccuracy()\n",
    "tf.keras.metrics.BinaryCrossentropy()\n",
    "tf.keras.metrics.CategoricalAccuracy()\n",
    "tf.keras.metrics.CategoricalCrossentropy()\n",
    "tf.keras.metrics.CategoricalHinge()\n",
    "tf.keras.metrics.CosineSimilarity()\n",
    "tf.keras.metrics.Hinge()\n",
    "\n",
    "tf.keras.metrics.KLD(y_true, y_pred)\n",
    "tf.keras.metrics.MAE(y_true, y_pred)\n",
    "tf.keras.metrics.MAPE(y_true, y_pred)\n",
    "tf.keras.metrics.Mean()\n",
    "tf.keras.metrics.MSE(y_true, y_pred)\n",
    "tf.keras.metrics.MSLE(y_true, y_pred)\n",
    "\n",
    "tf.keras.metrics.Poisson()\n",
    "tf.keras.metrics.RootMeanSquaredError()\n",
    "tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vb7QEs_aObEX"
   },
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P4g-lZGcObEX"
   },
   "outputs": [],
   "source": [
    "tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0,\n",
    "    reduction='auto',\n",
    "    name='categorical_crossentropy',\n",
    ")\n",
    "\n",
    "tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=False,\n",
    "    label_smoothing=0,\n",
    "    reduction='auto',\n",
    "    name='binary_crossentropy',\n",
    ")\n",
    "\n",
    "tf.keras.losses.CategoricalHinge(\n",
    "    reduction='auto',\n",
    "    name='categorical_hinge',\n",
    ")\n",
    "\n",
    "tf.keras.losses.CosineSimilarity(\n",
    "    axis=-1,\n",
    "    reduction='auto',\n",
    "    name='cosine_similarity',\n",
    ")\n",
    "\n",
    "tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=False,\n",
    "    reduction='auto',\n",
    "    name=None,\n",
    ")\n",
    "\n",
    "tf.keras.losses.KLD(y_true, y_pred)\n",
    "tf.keras.losses.LogCosh(reduction='auto', name='logcosh')\n",
    "tf.keras.losses.Poisson(reduction='auto', name='poisson')\n",
    "tf.keras.losses.SquaredHinge(reduction='auto', name='squared_hinge')\n",
    "\n",
    "tf.keras.losses.MAE(y_true, y_pred)\n",
    "tf.keras.losses.MAPE(y_true, y_pred)\n",
    "tf.keras.losses.MSE(y_true, y_pred)\n",
    "tf.keras.losses.MSLE(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAE1NtZoObEY"
   },
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8CnsWBiObEZ",
    "outputId": "64633ad8-b956-43c3-9e3f-dbb140665381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.optimizer_v2.ftrl.Ftrl at 0x14cdec160>"
      ]
     },
     "execution_count": 149,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.optimizers.Adadelta(\n",
    "    learning_rate=0.001,\n",
    "    rho=0.95,\n",
    "    epsilon=1e-07,\n",
    "    name='Adadelta'\n",
    ")\n",
    "\n",
    "tf.keras.optimizers.Adagrad(\n",
    "    learning_rate=0.001,\n",
    "    initial_accumulator_value=0.1,\n",
    "    epsilon=1e-07,\n",
    "    name='Adagrad'\n",
    ")\n",
    "\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam'\n",
    ")\n",
    "\n",
    "tf.keras.optimizers.Adamax(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    name='Adamax'\n",
    ")\n",
    "\n",
    "tf.keras.optimizers.Nadam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    name='Nadam'\n",
    ")\n",
    "\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01,\n",
    "    momentum=0.0,\n",
    "    nesterov=False,\n",
    "    name='SGD'\n",
    ")\n",
    "\n",
    "tf.keras.optimizers.Ftrl(\n",
    "    learning_rate=0.001,\n",
    "    learning_rate_power=-0.5,\n",
    "    initial_accumulator_value=0.1,\n",
    "    l1_regularization_strength=0.0,\n",
    "    l2_regularization_strength=0.0,\n",
    "    name='Ftrl',\n",
    "    l2_shrinkage_regularization_strength=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0LoY_I2gObEb"
   },
   "source": [
    "## Deep Neural Network (DNN) for Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3553
    },
    "colab_type": "code",
    "id": "ST2RjxqsObEb",
    "outputId": "fb136113-2134-4067-e970-fe5d655e4211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14480 samples, validate on 7133 samples\n",
      "Epoch 1/100\n",
      "14480/14480 [==============================] - 0s 15us/sample - loss: 24077.8424 - acc: 0.0854 - val_loss: 0.0215 - val_acc: 0.9867\n",
      "Epoch 2/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0125 - acc: 0.9927 - val_loss: 0.0129 - val_acc: 0.9909\n",
      "Epoch 3/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0130 - acc: 0.9927 - val_loss: 0.0827 - val_acc: 0.9256\n",
      "Epoch 4/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 885.8289 - acc: 0.5742 - val_loss: 1.7083 - val_acc: 0.9912\n",
      "Epoch 5/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 529.4218 - acc: 0.5157 - val_loss: 524.7122 - val_acc: 0.0088\n",
      "Epoch 6/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 445.0928 - acc: 0.4961 - val_loss: 778.1347 - val_acc: 0.9912\n",
      "Epoch 7/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 489.3062 - acc: 0.5047 - val_loss: 656.0197 - val_acc: 0.0088\n",
      "Epoch 8/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 443.5343 - acc: 0.4941 - val_loss: 274.9792 - val_acc: 0.9912\n",
      "Epoch 9/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 493.4202 - acc: 0.5052 - val_loss: 367.5925 - val_acc: 0.0088\n",
      "Epoch 10/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 444.4734 - acc: 0.4959 - val_loss: 1475.0523 - val_acc: 0.9912\n",
      "Epoch 11/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 205.4427 - acc: 0.5036 - val_loss: 1232.3436 - val_acc: 0.0088\n",
      "Epoch 12/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 400.1292 - acc: 0.4953 - val_loss: 1233.9900 - val_acc: 0.9912\n",
      "Epoch 13/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 376.9817 - acc: 0.5044 - val_loss: 1360.1720 - val_acc: 0.0088\n",
      "Epoch 14/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 314.5192 - acc: 0.4953 - val_loss: 468.7754 - val_acc: 0.9912\n",
      "Epoch 15/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 334.1401 - acc: 0.5059 - val_loss: 639.5700 - val_acc: 0.0088\n",
      "Epoch 16/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 295.6788 - acc: 0.4961 - val_loss: 569.7871 - val_acc: 0.9912\n",
      "Epoch 17/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 298.8173 - acc: 0.5055 - val_loss: 352.0087 - val_acc: 0.0088\n",
      "Epoch 18/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 281.8611 - acc: 0.4946 - val_loss: 401.5198 - val_acc: 0.9912\n",
      "Epoch 19/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 266.5429 - acc: 0.5054 - val_loss: 176.2505 - val_acc: 0.0088\n",
      "Epoch 20/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 242.1960 - acc: 0.4959 - val_loss: 147.6920 - val_acc: 0.9912\n",
      "Epoch 21/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 220.3410 - acc: 0.5047 - val_loss: 206.6050 - val_acc: 0.0088\n",
      "Epoch 22/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 189.7994 - acc: 0.4950 - val_loss: 301.5651 - val_acc: 0.9912\n",
      "Epoch 23/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 180.6182 - acc: 0.5050 - val_loss: 293.9100 - val_acc: 0.0088\n",
      "Epoch 24/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 178.5386 - acc: 0.4950 - val_loss: 150.0191 - val_acc: 0.9912\n",
      "Epoch 25/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 170.8329 - acc: 0.5046 - val_loss: 107.5187 - val_acc: 0.0088\n",
      "Epoch 26/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 142.4293 - acc: 0.4953 - val_loss: 190.5522 - val_acc: 0.9912\n",
      "Epoch 27/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 139.9497 - acc: 0.5052 - val_loss: 92.6311 - val_acc: 0.0088\n",
      "Epoch 28/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 126.8358 - acc: 0.4957 - val_loss: 56.4212 - val_acc: 0.9912\n",
      "Epoch 29/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 123.6298 - acc: 0.5061 - val_loss: 82.6105 - val_acc: 0.0088\n",
      "Epoch 30/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 114.9083 - acc: 0.4953 - val_loss: 70.5810 - val_acc: 0.9912\n",
      "Epoch 31/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 44.9153 - acc: 0.5484 - val_loss: 10.1310 - val_acc: 0.0088\n",
      "Epoch 32/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 59.9246 - acc: 0.4950 - val_loss: 35.9701 - val_acc: 0.9912\n",
      "Epoch 33/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 59.2736 - acc: 0.5041 - val_loss: 30.5245 - val_acc: 0.0088\n",
      "Epoch 34/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 52.3890 - acc: 0.4956 - val_loss: 50.2321 - val_acc: 0.9912\n",
      "Epoch 35/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 51.0632 - acc: 0.5046 - val_loss: 50.1428 - val_acc: 0.0088\n",
      "Epoch 36/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 69.2107 - acc: 0.4988 - val_loss: 0.1704 - val_acc: 0.9912\n",
      "Epoch 37/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 40.8213 - acc: 0.6321 - val_loss: 1.6098 - val_acc: 0.0457\n",
      "Epoch 38/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 20.4210 - acc: 0.5533 - val_loss: 45.4473 - val_acc: 0.9912\n",
      "Epoch 39/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 30.4005 - acc: 0.5048 - val_loss: 54.2613 - val_acc: 0.0088\n",
      "Epoch 40/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 28.6482 - acc: 0.4961 - val_loss: 81.3055 - val_acc: 0.9912\n",
      "Epoch 41/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 26.3997 - acc: 0.5052 - val_loss: 40.5506 - val_acc: 0.0088\n",
      "Epoch 42/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 25.3494 - acc: 0.4942 - val_loss: 29.0293 - val_acc: 0.9912\n",
      "Epoch 43/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 22.2986 - acc: 0.5054 - val_loss: 20.9288 - val_acc: 0.0088\n",
      "Epoch 44/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 18.6805 - acc: 0.4945 - val_loss: 26.0849 - val_acc: 0.9912\n",
      "Epoch 45/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 15.6222 - acc: 0.5052 - val_loss: 8.0814 - val_acc: 0.0093\n",
      "Epoch 46/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 15.1460 - acc: 0.4958 - val_loss: 9.2317 - val_acc: 0.9912\n",
      "Epoch 47/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 13.9966 - acc: 0.5044 - val_loss: 12.1245 - val_acc: 0.0088\n",
      "Epoch 48/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 12.7135 - acc: 0.4970 - val_loss: 7.1570 - val_acc: 0.9912\n",
      "Epoch 49/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 54.1629 - acc: 0.5758 - val_loss: 0.0090 - val_acc: 0.9912\n",
      "Epoch 50/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 51/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 1.1837 - acc: 0.8816 - val_loss: 56.9383 - val_acc: 0.0088\n",
      "Epoch 52/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 85.7221 - acc: 0.8539 - val_loss: 0.0087 - val_acc: 0.9912\n",
      "Epoch 53/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0093 - val_acc: 0.9912\n",
      "Epoch 54/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.5465 - acc: 0.9118 - val_loss: 50.9197 - val_acc: 0.0088\n",
      "Epoch 55/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8.5894 - acc: 0.5582 - val_loss: 25.2660 - val_acc: 0.9912\n",
      "Epoch 56/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 9.4278 - acc: 0.5153 - val_loss: 11.9390 - val_acc: 0.0088\n",
      "Epoch 57/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 13.9960 - acc: 0.4952 - val_loss: 83.8669 - val_acc: 0.9912\n",
      "Epoch 58/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 16.4968 - acc: 0.9229 - val_loss: 0.0087 - val_acc: 0.9912\n",
      "Epoch 59/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0070 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
      "Epoch 60/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 7.7343 - acc: 0.8420 - val_loss: 0.0239 - val_acc: 0.9912\n",
      "Epoch 61/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 10.5067 - acc: 0.9228 - val_loss: 0.0091 - val_acc: 0.9912\n",
      "Epoch 62/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0079 - acc: 0.9931 - val_loss: 0.0656 - val_acc: 0.9790\n",
      "Epoch 63/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 5.5607 - acc: 0.6419 - val_loss: 0.4022 - val_acc: 0.9912\n",
      "Epoch 64/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 5.1891 - acc: 0.5273 - val_loss: 0.6166 - val_acc: 0.2679\n",
      "Epoch 65/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 4.2680 - acc: 0.5261 - val_loss: 1.6739 - val_acc: 0.9912\n",
      "Epoch 66/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 9.6510 - acc: 0.6428 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 67/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0092 - val_acc: 0.9912\n",
      "Epoch 68/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 11.8590 - acc: 0.7831 - val_loss: 0.0250 - val_acc: 0.9912\n",
      "Epoch 69/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0082 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
      "Epoch 70/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0093 - val_acc: 0.9912\n",
      "Epoch 71/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 4.0881 - acc: 0.7123 - val_loss: 0.2091 - val_acc: 0.9912\n",
      "Epoch 72/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 3.1308 - acc: 0.5959 - val_loss: 1.0191 - val_acc: 0.1196\n",
      "Epoch 73/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 2.6344 - acc: 0.5194 - val_loss: 0.6827 - val_acc: 0.9912\n",
      "Epoch 74/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 2.1284 - acc: 0.5317 - val_loss: 0.8738 - val_acc: 0.1584\n",
      "Epoch 75/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 7.1973 - acc: 0.7328 - val_loss: 0.0087 - val_acc: 0.9912\n",
      "Epoch 76/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 0.9912\n",
      "Epoch 77/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0127 - val_acc: 0.9912\n",
      "Epoch 78/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 1.4043 - acc: 0.7458 - val_loss: 0.0846 - val_acc: 0.9525\n",
      "Epoch 79/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 1.1813 - acc: 0.7028 - val_loss: 0.1987 - val_acc: 0.9912\n",
      "Epoch 80/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 10.5459 - acc: 0.6604 - val_loss: 0.9719 - val_acc: 0.9912\n",
      "Epoch 81/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.1346 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
      "Epoch 82/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0087 - val_acc: 0.9912\n",
      "Epoch 83/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0082 - acc: 0.9931 - val_loss: 0.1458 - val_acc: 0.9912\n",
      "Epoch 84/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 4.6700 - acc: 0.7562 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 85/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 86/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0078 - acc: 0.9931 - val_loss: 0.0651 - val_acc: 0.9781\n",
      "Epoch 87/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.2396 - acc: 0.8775 - val_loss: 0.2659 - val_acc: 0.9912\n",
      "Epoch 88/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.3328 - acc: 0.7990 - val_loss: 0.3569 - val_acc: 0.4966\n",
      "Epoch 89/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 15.8533 - acc: 0.8258 - val_loss: 1.0061 - val_acc: 0.9912\n",
      "Epoch 90/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.3246 - acc: 0.9931 - val_loss: 0.0319 - val_acc: 0.9912\n",
      "Epoch 91/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0119 - acc: 0.9931 - val_loss: 0.0090 - val_acc: 0.9912\n",
      "Epoch 92/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0089 - val_acc: 0.9912\n",
      "Epoch 93/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 94/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 95/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 96/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 97/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 98/100\n",
      "14480/14480 [==============================] - 0s 6us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 99/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n",
      "Epoch 100/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 0.0069 - acc: 0.9931 - val_loss: 0.0088 - val_acc: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00735136],\n",
       "       [0.00735136],\n",
       "       [0.00735136],\n",
       "       ...,\n",
       "       [0.00735136],\n",
       "       [0.00735136],\n",
       "       [0.00735136]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
    "\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
    "                                 write_graph=True,\n",
    "                                 histogram_freq=1)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def regression_model() :   \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(64,input_dim=4))\n",
    "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
    "    model.add(layers.Dense(16,activation=tf.nn.relu))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),loss = \"mse\",metrics =[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = regression_model()\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZ-XxPgbObEd"
   },
   "source": [
    "## Deep Neural Network (DNN) for Binary Classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCLzs7HnObEd",
    "outputId": "891615f5-7106-4fa8-fb67-58bec7a8330c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14480 samples, validate on 7133 samples\n",
      "Epoch 1/100\n",
      "14480/14480 [==============================] - 1s 39us/sample - loss: 8295368.5436 - accuracy: 0.0000e+00 - val_loss: 8402822.8707 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2729 - accuracy: 0.0000e+00 - val_loss: 8402822.3857 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4691 - accuracy: 0.0000e+00 - val_loss: 8402822.7523 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4298 - accuracy: 0.0000e+00 - val_loss: 8402822.7397 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2298 - accuracy: 0.0000e+00 - val_loss: 8402822.7931 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6033 - accuracy: 0.0000e+00 - val_loss: 8402822.5061 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.8906 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3238 - accuracy: 0.0000e+00 - val_loss: 8402822.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4254 - accuracy: 0.0000e+00 - val_loss: 8402822.5364 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3796 - accuracy: 0.0000e+00 - val_loss: 8402822.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5370 - accuracy: 0.0000e+00 - val_loss: 8402822.7419 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4442 - accuracy: 0.0000e+00 - val_loss: 8402822.9446 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6094 - accuracy: 0.0000e+00 - val_loss: 8402822.4560 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4685 - accuracy: 0.0000e+00 - val_loss: 8402822.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.1481 - accuracy: 0.0000e+00 - val_loss: 8402822.8129 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.3481 - accuracy: 0.0000e+00 - val_loss: 8402822.6361 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.4729 - accuracy: 0.0000e+00 - val_loss: 8402822.4647 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6961 - accuracy: 0.0000e+00 - val_loss: 8402822.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2696 - accuracy: 0.0000e+00 - val_loss: 8402822.4947 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3624 - accuracy: 0.0000e+00 - val_loss: 8402822.5883 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3442 - accuracy: 0.0000e+00 - val_loss: 8402822.5619 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4680 - accuracy: 0.0000e+00 - val_loss: 8402822.5850 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3812 - accuracy: 0.0000e+00 - val_loss: 8402822.5723 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4149 - accuracy: 0.0000e+00 - val_loss: 8402822.6846 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3961 - accuracy: 0.0000e+00 - val_loss: 8402822.8864 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3906 - accuracy: 0.0000e+00 - val_loss: 8402822.7906 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3956 - accuracy: 0.0000e+00 - val_loss: 8402823.0008 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.1845 - accuracy: 0.0000e+00 - val_loss: 8402822.5109 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2751 - accuracy: 0.0000e+00 - val_loss: 8402822.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4354 - accuracy: 0.0000e+00 - val_loss: 8402822.7374 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6829 - accuracy: 0.0000e+00 - val_loss: 8402822.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4674 - accuracy: 0.0000e+00 - val_loss: 8402822.8786 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5105 - accuracy: 0.0000e+00 - val_loss: 8402822.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4856 - accuracy: 0.0000e+00 - val_loss: 8402822.5204 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.5409 - accuracy: 0.0000e+00 - val_loss: 8402822.6317 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2227 - accuracy: 0.0000e+00 - val_loss: 8402822.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4144 - accuracy: 0.0000e+00 - val_loss: 8402822.6752 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4188 - accuracy: 0.0000e+00 - val_loss: 8402822.5311 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3591 - accuracy: 0.0000e+00 - val_loss: 8402822.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4878 - accuracy: 0.0000e+00 - val_loss: 8402822.7582 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4840 - accuracy: 0.0000e+00 - val_loss: 8402822.2678 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2033 - accuracy: 0.0000e+00 - val_loss: 8402822.3530 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5044 - accuracy: 0.0000e+00 - val_loss: 8402822.6345 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.3642 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4337 - accuracy: 0.0000e+00 - val_loss: 8402822.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1923 - accuracy: 0.0000e+00 - val_loss: 8402823.0918 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4083 - accuracy: 0.0000e+00 - val_loss: 8402822.9626 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1785 - accuracy: 0.0000e+00 - val_loss: 8402822.6171 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4177 - accuracy: 0.0000e+00 - val_loss: 8402822.4830 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5586 - accuracy: 0.0000e+00 - val_loss: 8402822.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4431 - accuracy: 0.0000e+00 - val_loss: 8402822.5925 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3072 - accuracy: 0.0000e+00 - val_loss: 8402822.5470 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3116 - accuracy: 0.0000e+00 - val_loss: 8402822.5311 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3536 - accuracy: 0.0000e+00 - val_loss: 8402822.7465 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4884 - accuracy: 0.0000e+00 - val_loss: 8402822.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4707 - accuracy: 0.0000e+00 - val_loss: 8402822.7341 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.6420 - accuracy: 0.0000e+00 - val_loss: 8402822.7165 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2199 - accuracy: 0.0000e+00 - val_loss: 8402822.7922 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3646 - accuracy: 0.0000e+00 - val_loss: 8402822.8089 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4862 - accuracy: 0.0000e+00 - val_loss: 8402822.7189 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5287 - accuracy: 0.0000e+00 - val_loss: 8402822.6590 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3536 - accuracy: 0.0000e+00 - val_loss: 8402822.7969 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3961 - accuracy: 0.0000e+00 - val_loss: 8402822.5271 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3138 - accuracy: 0.0000e+00 - val_loss: 8402822.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4061 - accuracy: 0.0000e+00 - val_loss: 8402822.7015 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "14480/14480 [==============================] - 0s 10us/sample - loss: 8295368.5044 - accuracy: 0.0000e+00 - val_loss: 8402822.6449 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2022 - accuracy: 0.0000e+00 - val_loss: 8402823.1485 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3315 - accuracy: 0.0000e+00 - val_loss: 8402822.8184 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5204 - accuracy: 0.0000e+00 - val_loss: 8402822.6126 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5238 - accuracy: 0.0000e+00 - val_loss: 8402822.8909 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3431 - accuracy: 0.0000e+00 - val_loss: 8402822.9244 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4177 - accuracy: 0.0000e+00 - val_loss: 8402822.6037 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4000 - accuracy: 0.0000e+00 - val_loss: 8402822.4586 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4265 - accuracy: 0.0000e+00 - val_loss: 8402822.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5033 - accuracy: 0.0000e+00 - val_loss: 8402822.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4669 - accuracy: 0.0000e+00 - val_loss: 8402822.7307 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5215 - accuracy: 0.0000e+00 - val_loss: 8402822.4659 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.4160 - accuracy: 0.0000e+00 - val_loss: 8402822.4670 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4320 - accuracy: 0.0000e+00 - val_loss: 8402822.8773 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2989 - accuracy: 0.0000e+00 - val_loss: 8402822.7346 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.2608 - accuracy: 0.0000e+00 - val_loss: 8402822.5990 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5381 - accuracy: 0.0000e+00 - val_loss: 8402822.7458 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.3983 - accuracy: 0.0000e+00 - val_loss: 8402822.9714 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5204 - accuracy: 0.0000e+00 - val_loss: 8402823.1312 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4155 - accuracy: 0.0000e+00 - val_loss: 8402822.9336 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.2580 - accuracy: 0.0000e+00 - val_loss: 8402822.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.5050 - accuracy: 0.0000e+00 - val_loss: 8402823.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4552 - accuracy: 0.0000e+00 - val_loss: 8402822.4691 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3823 - accuracy: 0.0000e+00 - val_loss: 8402822.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4166 - accuracy: 0.0000e+00 - val_loss: 8402822.7264 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3818 - accuracy: 0.0000e+00 - val_loss: 8402822.6480 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4530 - accuracy: 0.0000e+00 - val_loss: 8402822.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.3602 - accuracy: 0.0000e+00 - val_loss: 8402822.5260 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4265 - accuracy: 0.0000e+00 - val_loss: 8402822.3326 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1669 - accuracy: 0.0000e+00 - val_loss: 8402822.9249 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.4851 - accuracy: 0.0000e+00 - val_loss: 8402822.7352 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "14480/14480 [==============================] - 0s 7us/sample - loss: 8295368.5182 - accuracy: 0.0000e+00 - val_loss: 8402822.5558 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "14480/14480 [==============================] - 0s 9us/sample - loss: 8295368.4110 - accuracy: 0.0000e+00 - val_loss: 8402822.6736 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.1492 - accuracy: 0.0000e+00 - val_loss: 8402822.4661 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "14480/14480 [==============================] - 0s 8us/sample - loss: 8295368.3878 - accuracy: 0.0000e+00 - val_loss: 8402822.6316 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
    "\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
    "                                 write_graph=True,\n",
    "                                 histogram_freq=1)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def binaryclass_model() :   \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128,input_dim=4))\n",
    "    model.add(layers.Dense(64,activation=tf.nn.relu))\n",
    "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
    "    model.add(layers.Dense(1,activation=tf.nn.sigmoid))  \n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),loss = 'binary_crossentropy',metrics =[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = binaryclass_model()\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9aVIWn1ObEf"
   },
   "source": [
    "## Deep Neural Network (DNN) for Multi-Class Classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3655
    },
    "colab_type": "code",
    "id": "O3998DVwObEf",
    "outputId": "60ed0a5e-f8ac-4675-d64d-6759563af2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14480 samples, validate on 7133 samples\n",
      "Epoch 1/100\n",
      "14480/14480 [==============================] - 1s 37us/sample - loss: 85.2323 - acc: 0.7825 - val_loss: 18.4541 - val_acc: 0.9912\n",
      "Epoch 2/100\n",
      "14480/14480 [==============================] - 0s 27us/sample - loss: 10.4217 - acc: 0.9931 - val_loss: 11.4321 - val_acc: 0.9912\n",
      "Epoch 3/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 5.5147 - acc: 0.9231 - val_loss: 17.2698 - val_acc: 0.9912\n",
      "Epoch 4/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 7.8217 - acc: 0.9931 - val_loss: 5.1975 - val_acc: 0.9912\n",
      "Epoch 5/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 36.9202 - acc: 0.8541 - val_loss: 19.9685 - val_acc: 0.9912\n",
      "Epoch 6/100\n",
      "14480/14480 [==============================] - 0s 28us/sample - loss: 10.7934 - acc: 0.9931 - val_loss: 10.4356 - val_acc: 0.9912\n",
      "Epoch 7/100\n",
      "14480/14480 [==============================] - 0s 28us/sample - loss: 8.3069 - acc: 0.9231 - val_loss: 10.3582 - val_acc: 0.9912\n",
      "Epoch 8/100\n",
      "14480/14480 [==============================] - 0s 33us/sample - loss: 34.4879 - acc: 0.8539 - val_loss: 24.6847 - val_acc: 0.9912\n",
      "Epoch 9/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 12.3716 - acc: 0.9931 - val_loss: 6.1752 - val_acc: 0.9912\n",
      "Epoch 10/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 9.8100 - acc: 0.9228 - val_loss: 9.6859 - val_acc: 0.9912\n",
      "Epoch 11/100\n",
      "14480/14480 [==============================] - 0s 28us/sample - loss: 12.7904 - acc: 0.9226 - val_loss: 254.5598 - val_acc: 0.0088\n",
      "Epoch 12/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 30.7963 - acc: 0.9233 - val_loss: 10.6206 - val_acc: 0.9912\n",
      "Epoch 13/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 2.6273 - acc: 0.9931 - val_loss: 1.1685 - val_acc: 0.9912\n",
      "Epoch 14/100\n",
      "14480/14480 [==============================] - 0s 27us/sample - loss: 8.9070 - acc: 0.9235 - val_loss: 5.9908 - val_acc: 0.9912\n",
      "Epoch 15/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 15.2661 - acc: 0.9227 - val_loss: 4.8545 - val_acc: 0.9912\n",
      "Epoch 16/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 22.8889 - acc: 0.8532 - val_loss: 3.3279 - val_acc: 0.9912\n",
      "Epoch 17/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 1.8561 - acc: 0.9931 - val_loss: 2.0649 - val_acc: 0.9912\n",
      "Epoch 18/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.9337 - acc: 0.9931 - val_loss: 0.5554 - val_acc: 0.9912\n",
      "Epoch 19/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.2126 - acc: 0.9931 - val_loss: 0.0977 - val_acc: 0.9912\n",
      "Epoch 20/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0718 - acc: 0.9931 - val_loss: 0.0996 - val_acc: 0.9912\n",
      "Epoch 21/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0739 - acc: 0.9931 - val_loss: 0.2651 - val_acc: 0.9912\n",
      "Epoch 22/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.1111 - acc: 0.9931 - val_loss: 0.8191 - val_acc: 0.9912\n",
      "Epoch 23/100\n",
      "14480/14480 [==============================] - 0s 32us/sample - loss: 0.1733 - acc: 0.9931 - val_loss: 0.4577 - val_acc: 0.9912\n",
      "Epoch 24/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 2.7704 - acc: 0.8539 - val_loss: 0.3340 - val_acc: 0.9912\n",
      "Epoch 25/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0947 - acc: 0.9931 - val_loss: 0.1504 - val_acc: 0.9912\n",
      "Epoch 26/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0817 - acc: 0.9931 - val_loss: 0.2651 - val_acc: 0.9912\n",
      "Epoch 27/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.1948 - acc: 0.9931 - val_loss: 1.3744 - val_acc: 0.9912\n",
      "Epoch 28/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.3107 - acc: 0.9931 - val_loss: 0.0869 - val_acc: 0.9912\n",
      "Epoch 29/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0765 - acc: 0.9931 - val_loss: 0.1248 - val_acc: 0.9912\n",
      "Epoch 30/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0830 - acc: 0.9931 - val_loss: 0.1181 - val_acc: 0.9912\n",
      "Epoch 31/100\n",
      "14480/14480 [==============================] - 0s 26us/sample - loss: 1.2972 - acc: 0.9931 - val_loss: 1.4498 - val_acc: 0.9912\n",
      "Epoch 32/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 1.3433 - acc: 0.9931 - val_loss: 1.2246 - val_acc: 0.9912\n",
      "Epoch 33/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 1.1346 - acc: 0.9931 - val_loss: 1.0337 - val_acc: 0.9912\n",
      "Epoch 34/100\n",
      "14480/14480 [==============================] - 0s 27us/sample - loss: 0.9535 - acc: 0.9931 - val_loss: 0.8656 - val_acc: 0.9912\n",
      "Epoch 35/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.7945 - acc: 0.9931 - val_loss: 0.7193 - val_acc: 0.9912\n",
      "Epoch 36/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.6568 - acc: 0.9931 - val_loss: 0.5938 - val_acc: 0.9912\n",
      "Epoch 37/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.5395 - acc: 0.9931 - val_loss: 0.4879 - val_acc: 0.9912\n",
      "Epoch 38/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.4412 - acc: 0.9931 - val_loss: 0.4001 - val_acc: 0.9912\n",
      "Epoch 39/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.3601 - acc: 0.9931 - val_loss: 0.3282 - val_acc: 0.9912\n",
      "Epoch 40/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.2939 - acc: 0.9931 - val_loss: 0.2701 - val_acc: 0.9912\n",
      "Epoch 41/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.2406 - acc: 0.9931 - val_loss: 0.2236 - val_acc: 0.9912\n",
      "Epoch 42/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.1981 - acc: 0.9931 - val_loss: 0.1868 - val_acc: 0.9912\n",
      "Epoch 43/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.1644 - acc: 0.9931 - val_loss: 0.1577 - val_acc: 0.9912\n",
      "Epoch 44/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 0.1379 - acc: 0.9931 - val_loss: 0.1349 - val_acc: 0.9912\n",
      "Epoch 45/100\n",
      "14480/14480 [==============================] - 0s 28us/sample - loss: 0.1170 - acc: 0.9931 - val_loss: 0.1170 - val_acc: 0.9912\n",
      "Epoch 46/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.1007 - acc: 0.9931 - val_loss: 0.1029 - val_acc: 0.9912\n",
      "Epoch 47/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0879 - acc: 0.9931 - val_loss: 0.0918 - val_acc: 0.9912\n",
      "Epoch 48/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0778 - acc: 0.9931 - val_loss: 0.0832 - val_acc: 0.9912\n",
      "Epoch 49/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0700 - acc: 0.9931 - val_loss: 0.0764 - val_acc: 0.9912\n",
      "Epoch 50/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0638 - acc: 0.9931 - val_loss: 0.0712 - val_acc: 0.9912\n",
      "Epoch 51/100\n",
      "14480/14480 [==============================] - 0s 28us/sample - loss: 0.0591 - acc: 0.9931 - val_loss: 0.0672 - val_acc: 0.9912\n",
      "Epoch 52/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0554 - acc: 0.9931 - val_loss: 0.0641 - val_acc: 0.9912\n",
      "Epoch 53/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0526 - acc: 0.9931 - val_loss: 0.0618 - val_acc: 0.9912\n",
      "Epoch 54/100\n",
      "14480/14480 [==============================] - 0s 27us/sample - loss: 0.0504 - acc: 0.9931 - val_loss: 0.0598 - val_acc: 0.9912\n",
      "Epoch 55/100\n",
      "14480/14480 [==============================] - 0s 26us/sample - loss: 0.0486 - acc: 0.9931 - val_loss: 0.0582 - val_acc: 0.9912\n",
      "Epoch 56/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0472 - acc: 0.9931 - val_loss: 0.0571 - val_acc: 0.9912\n",
      "Epoch 57/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0462 - acc: 0.9931 - val_loss: 0.0560 - val_acc: 0.9912\n",
      "Epoch 58/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0453 - acc: 0.9931 - val_loss: 0.0553 - val_acc: 0.9912\n",
      "Epoch 59/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0446 - acc: 0.9931 - val_loss: 0.0547 - val_acc: 0.9912\n",
      "Epoch 60/100\n",
      "14480/14480 [==============================] - 0s 28us/sample - loss: 0.0441 - acc: 0.9931 - val_loss: 0.0540 - val_acc: 0.9912\n",
      "Epoch 61/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0436 - acc: 0.9931 - val_loss: 0.0534 - val_acc: 0.9912\n",
      "Epoch 62/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0432 - acc: 0.9931 - val_loss: 0.0531 - val_acc: 0.9912\n",
      "Epoch 63/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0429 - acc: 0.9931 - val_loss: 0.0526 - val_acc: 0.9912\n",
      "Epoch 64/100\n",
      "14480/14480 [==============================] - 0s 25us/sample - loss: 0.0427 - acc: 0.9931 - val_loss: 0.0524 - val_acc: 0.9912\n",
      "Epoch 65/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0425 - acc: 0.9931 - val_loss: 0.0521 - val_acc: 0.9912\n",
      "Epoch 66/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0423 - acc: 0.9931 - val_loss: 0.0519 - val_acc: 0.9912\n",
      "Epoch 67/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0422 - acc: 0.9931 - val_loss: 0.0517 - val_acc: 0.9912\n",
      "Epoch 68/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0420 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
      "Epoch 69/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0419 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
      "Epoch 70/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0418 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
      "Epoch 71/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0418 - acc: 0.9931 - val_loss: 0.0516 - val_acc: 0.9912\n",
      "Epoch 72/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0417 - acc: 0.9931 - val_loss: 0.0514 - val_acc: 0.9912\n",
      "Epoch 73/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0417 - acc: 0.9931 - val_loss: 0.0514 - val_acc: 0.9912\n",
      "Epoch 74/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0416 - acc: 0.9931 - val_loss: 0.0513 - val_acc: 0.9912\n",
      "Epoch 75/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0416 - acc: 0.9931 - val_loss: 0.0512 - val_acc: 0.9912\n",
      "Epoch 76/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0415 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
      "Epoch 77/100\n",
      "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0415 - acc: 0.9931 - val_loss: 0.0512 - val_acc: 0.9912\n",
      "Epoch 78/100\n",
      "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
      "Epoch 79/100\n",
      "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0511 - val_acc: 0.9912\n",
      "Epoch 80/100\n",
      "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
      "Epoch 81/100\n",
      "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 82/100\n",
      "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
      "Epoch 83/100\n",
      "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 84/100\n",
      "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0414 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
      "Epoch 85/100\n",
      "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
      "Epoch 86/100\n",
      "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 87/100\n",
      "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
      "Epoch 88/100\n",
      "14480/14480 [==============================] - 0s 20us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 89/100\n",
      "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 90/100\n",
      "14480/14480 [==============================] - 0s 19us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
      "Epoch 91/100\n",
      "14480/14480 [==============================] - 0s 22us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 92/100\n",
      "14480/14480 [==============================] - 0s 24us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
      "Epoch 93/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 94/100\n",
      "14480/14480 [==============================] - 0s 29us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0508 - val_acc: 0.9912\n",
      "Epoch 95/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0507 - val_acc: 0.9912\n",
      "Epoch 96/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 97/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 98/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0510 - val_acc: 0.9912\n",
      "Epoch 99/100\n",
      "14480/14480 [==============================] - 0s 31us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n",
      "Epoch 100/100\n",
      "14480/14480 [==============================] - 0s 30us/sample - loss: 0.0413 - acc: 0.9931 - val_loss: 0.0509 - val_acc: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
       "        7.7093949e-07, 7.5853711e-07],\n",
       "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
       "        7.7093949e-07, 7.5853711e-07],\n",
       "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
       "        7.7093949e-07, 7.5853711e-07],\n",
       "       ...,\n",
       "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
       "        7.7093949e-07, 7.5853711e-07],\n",
       "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804082e-07,\n",
       "        7.7093949e-07, 7.5853711e-07],\n",
       "       [9.9342322e-01, 6.5678796e-03, 7.1360387e-07, ..., 7.6804076e-07,\n",
       "        7.7093949e-07, 7.5853706e-07]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
    "\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
    "                                 write_graph=True,\n",
    "                                 histogram_freq=1)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def multiclass_model() :   \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(128,input_dim=4))\n",
    "    model.add(layers.Dense(64,activation=tf.nn.relu))\n",
    "    model.add(layers.Dense(32,activation=tf.nn.relu))\n",
    "    model.add(layers.Dense(14,activation=tf.nn.softmax))  \n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),loss = 'sparse_categorical_crossentropy',metrics =[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = multiclass_model()\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=1024,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUar-316ObEg"
   },
   "source": [
    "## Deep Neural Network (CNN) for Multi-Class Classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "Wu4yq5_BObEg",
    "outputId": "96dcb77c-2ea5-4b79-c1ed-136ddd41153e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 5s 50ms/sample - loss: 2.2897\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 5s 48ms/sample - loss: 2.3151\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 5s 48ms/sample - loss: 2.3100\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 5s 48ms/sample - loss: 2.2882\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 5s 48ms/sample - loss: 2.2574\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 5s 48ms/sample - loss: 2.3003\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 5s 48ms/sample - loss: 2.2794\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 5s 49ms/sample - loss: 2.2688\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 5s 48ms/sample - loss: 2.2722\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 5s 49ms/sample - loss: 2.2781\n",
      "20/20 [==============================] - 0s 15ms/sample - loss: 2.3009\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "X_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "X_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "def cnn_model() :   \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(100, 100, 3)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=tf.nn.relu))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=tf.nn.relu))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=tf.nn.relu))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation=tf.nn.relu))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(X_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCTkprTVObEh"
   },
   "source": [
    "## Recurrent Neural Network (LSTM) for Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "HhjGHgX6ObEi",
    "outputId": "6edffa0f-b69b-4791-ed69-8756cd08bf65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14480, 4)\n",
      "(14480,)\n",
      "(7133, 4)\n",
      "(7133,)\n",
      "(14480, 1, 4)\n",
      "(14480,)\n",
      "(7133, 1, 4)\n",
      "(7133,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],1,X_train.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],1,X_test.shape[1])\n",
    "\n",
    "print (X_train.shape)\n",
    "print (y_train.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "id": "1yOS2w5xObEj",
    "outputId": "2183b9ae-2bf3-46cc-8a1a-eb95dc83d04e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0616 17:49:14.839148 140373151274880 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14480 samples, validate on 7133 samples\n",
      "Epoch 1/10\n",
      "14480/14480 [==============================] - 7s 481us/sample - loss: 416599474139.7923 - acc: 0.0000e+00 - val_loss: 446471973033.6857 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "14480/14480 [==============================] - 5s 365us/sample - loss: 416586449457.2199 - acc: 0.0000e+00 - val_loss: 446459547576.2209 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "14480/14480 [==============================] - 5s 354us/sample - loss: 416574177243.7923 - acc: 0.0000e+00 - val_loss: 446447106407.7567 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "14480/14480 [==============================] - 5s 360us/sample - loss: 416561902025.1227 - acc: 0.0000e+00 - val_loss: 446434691070.5644 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "14480/14480 [==============================] - 5s 359us/sample - loss: 416549629775.4873 - acc: 0.0000e+00 - val_loss: 446422231067.2761 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "14480/14480 [==============================] - 5s 352us/sample - loss: 416537372769.3083 - acc: 0.0000e+00 - val_loss: 446409802667.4443 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "14480/14480 [==============================] - 5s 355us/sample - loss: 416525070177.5911 - acc: 0.0000e+00 - val_loss: 446397377657.8809 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "14480/14480 [==============================] - 5s 347us/sample - loss: 416512829754.5547 - acc: 0.0000e+00 - val_loss: 446384939176.8243 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "14480/14480 [==============================] - 5s 351us/sample - loss: 416500522129.9624 - acc: 0.0000e+00 - val_loss: 446372482660.2753 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "14480/14480 [==============================] - 5s 334us/sample - loss: 416488261901.2950 - acc: 0.0000e+00 - val_loss: 446360081168.9758 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[119.00605],\n",
       "       [119.00605],\n",
       "       [119.00605],\n",
       "       ...,\n",
       "       [119.00605],\n",
       "       [119.00605],\n",
       "       [119.00605]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
    "\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='./Graph',\n",
    "                                 write_graph=True,\n",
    "                                 histogram_freq=1)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
    "\n",
    "def lstm_model() :   \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(128,input_shape=(X_train.shape[1], X_train.shape[2]),return_sequences=True))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.LSTM(32))\n",
    "    model.add(layers.Dense(1))  \n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),loss = \"mse\",metrics =[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = lstm_model()\n",
    "model.fit(X_train,y_train,epochs=10,validation_data=(X_test,y_test),callbacks=[tensorboard_callback])\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFr0XvElObEl"
   },
   "source": [
    "# Microsofts Model Interpretation (Detecting Bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n9vChjzMObEm",
    "outputId": "322626ec-0d49-4ba8-dec0-e67516a7c39b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<interpret.glassbox.linear.LinearRegression at 0x7faa8b2e9240>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install interpret\n",
    "from interpret.glassbox import LinearRegression\n",
    "\n",
    "ebm = LinearRegression()\n",
    "ebm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "colab_type": "code",
    "id": "bMETx3n6ObEn",
    "outputId": "c145ab23-c62c-4145-bcd9-e6e9181c1fe1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7554/140370454905744/ -->\n",
       "<iframe src=\"http://127.0.0.1:7554/140370454905744/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "colab_type": "code",
    "id": "IXyrP-fvObEp",
    "outputId": "f7b215b0-ff7c-4c86-de07-74237a9f9e3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7554/140370458563976/ -->\n",
       "<iframe src=\"http://127.0.0.1:7554/140370458563976/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_local = ebm.explain_local(X_test, y_test)\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "ixxaSvvNObEr",
    "outputId": "ae019085-e083-458d-afae-4464b3744d34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  ...     long  sqft_living15  sqft_lot15\n",
       "0  7129300520  20141013T000000  221900.0  ... -122.257           1340        5650\n",
       "1  6414100192  20141209T000000  538000.0  ... -122.319           1690        7639\n",
       "2  5631500400  20150225T000000  180000.0  ... -122.233           2720        8062\n",
       "3  2487200875  20141209T000000  604000.0  ... -122.393           1360        5000\n",
       "4  1954400510  20150218T000000  510000.0  ... -122.045           1800        7503\n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install xai\n",
    "import xai.data\n",
    "df = xai.data.pd.read_csv(\"kc_house_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "y6oMh45AObEt",
    "outputId": "20a8c1f9-bbba-442e-b286-02da964ccc29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0616 17:55:52.548324 140373151274880 __init__.py:991] No categorical_cols passed so inferred using np.object, np.int8 and np.bool: Index(['date'], dtype='object'). If you see an error these are not correct, please provide them as a string array as: categorical_cols=['col1', 'col2', ...]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAE6CAYAAAD9Sp7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcFdWd///XW0DAJYKAhjQkYFDC\njtAIjllARxQXMMbd/ETjiEaTGE1GzeYy0a8ak2icoA6jKBpGNG4QIhrjgisIAkEBFQSVJiirW2Tn\n8/vjVjcXqptu+jZd3fT7+Xj0w7qnTtX93PLSnz6nTp2jiMDMzCzfblkHYGZmdY+Tg5mZpTg5mJlZ\nipODmZmlODmYmVmKk4OZmaU4OZiZWYqTg5mZpTg5mJlZSuOsA6iu1q1bR4cOHbIOw8ysXnnttddW\nRESbyurV2+TQoUMHpk+fnnUYZmb1iqT3qlLP3UpmZpbi5GBmZilODmZmllJv7zmY1aQNGzZQUlLC\n2rVrsw7FrEY0a9aMdu3a0aRJk2od7+RgBpSUlLD33nvToUMHJGUdjllBIoKVK1dSUlJCx44dq3UO\ndyuZAWvXrqVVq1ZODLZLkESrVq0Kagk7OZglnBhsV1Lo99nJwczMUpwczPLMnbcsk5+XX3mTr32t\nO1/7Wndat96PoqIievfuTYsWLejatWuNf87nnnuO4447boeOGThwYLkPnt5zzz384Ac/qPT4yy67\njG7dutGlSxd+9KMfUbp+/cCBA+ncuTO9e/emd+/eLFu2bKvjHn74YSSVvferr75aVrdXr148+uij\n5b7f2WefTceOHcvqzpo1C8j1x//oRz+iU6dO9OzZkxkzZpR7/Jo1a/jWt77Fpk2bAGjUqFHZuYYO\nHVpWb9GiRfTv359OnTpx6qmnsn79+nLPd/3119OpUyc6d+7Mk08+WVb+xBNP0LlzZzp16sQNN9xQ\nVn7mmWfSs2dPfv7zn5eVXXvttTz22GNlrydOnMiVV15Z7vsVysnBrA5o0WJfHnn0GR559BlOPXU4\nl1xyCbNmzWLWrFnstlvl/0w3btxYC1FW38svv8xLL73E7NmzeeONN5g2bRqTJ08u2z927Niyz7vf\nfvuVlX/66af84Q9/oH///mVl3bt3Z/r06cyaNYsnnniC888/v8LPf9NNN5Wdt3fv3gBMmjSJ+fPn\nM3/+fEaNGsX3v//9co8dPXo0J554Io0aNQKgefPmZeeaMGFCWb3LL7+cSy65hAULFtCyZUvuuuuu\n1Lnmzp3LuHHjmDNnDk888QQXXnghmzZtYtOmTVx00UVMmjSJuXPncv/99zN37lxmz55N8+bNmT17\nNtOmTePjjz9m6dKlTJ06lRNOOKHsvMceeyx/+ctf+Pzzz6vyv2GHeLSS2Tb2v/6XNHtzTo2ec+3X\nuvHhz66t1rGbNm3ivPPO4+WXX6aoqIjx48fTvHlzBg4cSO/evXnxxRc5/fTTOeuss7jgggt4//33\nAbjllls47LDDmDx5MhdffDGQ64d+/vnnAfjss8846aSTeOONN+jbty9/+tOfkMTTTz/NT3/6UzZu\n3Ei/fv24/fbbadq06VYx3X333Vx//fW0aNGCXr16pfZvSxJr165l/fr1RAQbNmxg//33r/Sz/+pX\nv+Lyyy/npptuKivbY489yrbXrl27w33r48eP56yzzkISAwYM4KOPPmLp0qW0bdt2q3pjx47l//7v\n/7Z7rojgmWeeKas3fPhwrr766lTCGT9+PKeddhpNmzalY8eOdOrUiVdffRWATp06ccABBwBw2mmn\nMX78eE444QTWrFnD5s2b2bBhA40aNeLKK6/kmmuu2eq8khg4cCATJ07klFNO2aHrUBm3HMzquPnz\n53PRRRcxZ84cWrRowcMPP1y2b/369UyfPp2f/OQnXHzxxVxyySVMmzaNhx9+mP/4j/8A4Le//S0j\nR45k1qxZvPDCCzRv3hyAmTNncssttzB37lwWLlzISy+9xNq1azn77LN54IEHeP3119m4cSO33377\nVvEsXbqUq666ipdeeokXX3yRuXPnlu2bMGFCud0chx56KIMGDaJt27a0bduWo446ii5dupTtP+ec\nc+jduze//vWvy7qbZsyYweLFizn22GNT55s6dSrdunWjR48e3HHHHTRuXP7fub/4xS/o2bMnl1xy\nCevWrQNgyZIltG/fvqxOu3btWLJkyVbHrV+/noULF5I/uefatWspLi5mwIABZV07K1eupEWLFmXv\nX965tveeFZV36dKFNm3a0KdPH44//ngWLFjA5s2b6dOnT+rcxcXFvPDCC+V+/kK45WC2jer+hb+z\nlPabA/Tt25d33323bN+pp55atv33v/99q1/Un3zyCZ999hmHHXYYl156KWeeeSYnnngi7dq1A+CQ\nQw4p2+7duzfvvvsue++9Nx07duSggw4Ccn8Jjxw5kh//+Mdl5506dSoDBw6kTZs2ZTG8/fbbAAwd\nOnSr/vhSCxYsYN68eZSUlABw5JFH8sILL/CNb3yDsWPHUlRUxKeffsp3vvMd7rvvPr773e9y6aWX\ncs8995R7Tfr378+cOXOYN28ew4cPZ8iQITRr1myrOtdffz1f/OIXWb9+PSNGjODGG2+scv/8ihUr\naNGixVZl7733HkVFRSxcuJDDDz+cHj16sM8++1TpfNVxyy23lG0ff/zx/M///A/XXXcd//jHPzjy\nyCM577zzANhvv/345z//WePv75aDWR2X32XTqFGjrfrX99xzz7LtzZs3M2XKlLJ+8SVLlrDXXntx\nxRVXcOedd7JmzRoOO+ww3nzzzUrPW9MeffRRBgwYwF577cVee+3FkCFDeOWVVwAoKioCYO+99+aM\nM87g1Vdf5dNPP+WNN95g4MCBdOjQgSlTpjB06NDUDfEuXbqw11578cYbb6Tes23btkiiadOmnHPO\nOWXdOEVFRSxevLisXklJSVkMpZo3b556RqC0zgEHHMDAgQOZOXMmrVq14qOPPiq7duWda3vvWZVY\nxo8fT9++ffnss8945513ePDBB3nooYfK7jOsXbu2rDVYk5wczHYRgwcP5r//+7/LXpeOznnnnXfo\n0aMHl19+Of369StLDuXp3Lkz7777LgsWLADgvvvu41vf+tZWdfr378/kyZNZuXIlGzZs4M9//nOl\nsX35y19m8uTJbNy4kQ0bNjB58mS6dOnCxo0bWbFiBZCbwmTixIl0796dffbZhxUrVvDuu+/y7rvv\nMmDAACZMmEBxcTGLFi0q+2X83nvv8eabb1Le2i5Lly4FcvcFHnvsMbp37w7kWjf33nsvEcGUKVPY\nZ599UvcbWrZsyaZNm8oSxOrVq8u6pVasWMFLL71E165dkcSgQYN46KGHABgzZgzDhg1LxTJ06FDG\njRvHunXrWLRoEfPnz+eQQw6hX79+zJ8/n0WLFrF+/XrGjRu3Vctrw4YN3HLLLVx22WWsWbOm7P7K\npk2bykZFvf3222WfrSY5OZjtIm699VamT59Oz5496dq1K3fccQeQ657o3r07PXv2pEmTJgwZMqTC\nczRr1oy7776bk08+mR49erDbbrtxwQUXbFWnbdu2XH311Rx66KEcdthhW907qOiew0knncRXv/pV\nevToQa9evejVqxfHH38869at46ijjqJnz5707t2boqKisu6Sirz44ov06tWL3r178+1vf5vbbruN\n1q1bA3DMMceUdbGceeaZ9OjRgx49erBixQp++ctfltU54IAD6NSpE+eddx633XZbue8zePBgXnzx\nRQDmzZtHcXExvXr1YtCgQVxxxRVlQ4xvvPFGfv/739OpUydWrlzJueeem7oW3bp145RTTqFr164c\nffTRjBw5kkaNGtG4cWP++Mc/lt2DOeWUU+jWrVtZDCNHjmT48OHsscce9OzZk88//5wePXrQt2/f\nsm6vZ599ttz7MoVS6c2f+qa4uDi82I/VlHnz5tGlSxfmzltWeeVa0LXLfpVXsp1qxowZ3Hzzzdx3\n331Zh1KhDz/8kDPOOIOnn3663P2l3+t8kl6LiOLKzu2Wg5lZOfr06cOgQYPKHoKri95//31+97vf\n7ZRzV5ocJI2WtEzSG9uU/1DSm5LmSPpNXvnPJC2Q9Jako/LKj07KFki6Iq+8o6SpSfkDknavqQ9n\nZlaI733ve2UPwdVF/fr1KxvJVtOq0nK4Bzg6v0DSIGAY0CsiugG/Tcq7AqcB3ZJjbpPUSFIjYCQw\nBOgKnJ7UBbgRuDkiOgGrgXML/VBmZlaYSpNDRDwPrNqm+PvADRGxLqlT2lE7DBgXEesiYhGwADgk\n+VkQEQsjYj0wDhim3K33w4GHkuPHACdgZmaZqu49h4OAbyTdQZMl9UvKi4DFefVKkrKKylsBH0XE\nxm3KzcwsQ9V9QroxsC8wAOgHPCjpgBqLqgKSRgAjIDdu2szMdo7qJocS4JHIjYN9VdJmoDWwBGif\nV69dUkYF5SuBFpIaJ62H/PopETEKGAW5oazVjN2sUrO6fqNGz9d7bs3PfbM9HTp0YPr06WXj/812\nVHW7lR4DBgFIOgjYHVgBTABOk9RUUkfgQOBVYBpwYDIyaXdyN60nJMnlWeCk5LzDgfHV/TBmu7K6\nPi237VoqbTlIuh8YCLSWVAJcBYwGRifDW9cDw5Nf9HMkPQjMBTYCF0XEpuQ8PwCeBBoBoyOidE7k\ny4Fxkq4FZgLpydDNGoDbb/89E//yEC33bUXngw6gb9++TJw4catpuQ866CCuvfZa1q9fT6tWrRg7\ndiz7778/K1eu5PTTT2fJkiUceuih5D/c+qc//Ylbb72V9evX079/f2677bY6PTzT6oZKk0NEnF7B\nru9WUP864Lpyyh8HHi+nfCG50UxmDdbrr8/kqb9N5JFHn2Hjxo2ccfpR9O3bF9gyLTfk5viZMmUK\nkrjzzjv5zW9+w+9+9zuuueYavv71r3PllVfy17/+tWzBmXnz5vHAAw/w0ksv0aRJEy688ELGjh3L\nWWedldlntfrBU3ab1QEzZ77K4YcfTdOmzWjaNDdFc6n8ablLSko49dRTWbp0KevXr6djx44APP/8\n8zzyyCNAbnWwli1bAvD000/z2muv0a9fbkDhmjVrtlppzawiTg5mdVz+tNw//OEPufTSSxk6dCjP\nPfccV1999XaPjQiGDx/O9ddfv5OjtF2N51YyqwMOPvgQnnvub6xbt5Z//etfTJw4sdx6H3/8cdl8\n/2PGjCkr/+Y3v1m2VOWkSZNYvXo1AEcccQQPPfQQy5blnlNdtWoV77333s78KLaLcMvBrBy1PfS0\nR4+DGTToKL59wiBatWpT4SpjV199NSeffDItW7bk8MMPZ9GiRQBcddVVnH766XTr1o1/+7d/K3sO\nqGvXrlx77bUMHjyYzZs306RJE0aOHMlXvvKVWv18Vv94ym4z6saU3f/617/Yc889WbPmc84fcRKj\nRo0qd81gs6oqZMputxzM6oirr/4J7yx4m/Xr13Heed9zYrBMOTmY1RE33XRH2bYX+7Gs+Ya0WaK+\ndrGalafQ77OTgxm5tZNXrlzpBGG7hIhg5cqVNGvWrNrncLeSGdCuXTtKSkr4YOkycsuMZEuszDoE\nq+eaNWtGu3btqn28k4MZ0KRJEzp27Mh3TpuUdSgAzJh6YdYhWAPnbiUzM0txcjAzsxQnBzMzS3Fy\nMDOzlEqTg6TRkpYlC/tsu+8nkkJS6+S1JN0qaYGk2ZL65NUdLml+8jM8r7yvpNeTY25VXRgqYmbW\nwFWl5XAPcPS2hZLaA4OB9/OKh5BbGvRAYARwe1J3X3IryPUnt7DPVZJaJsfcDpyXd1zqvczMrHZV\nmhwi4nlgVTm7bgYuA/KfGhoG3Bs5U4AWktoCRwFPRcSqiFgNPAUcnez7QkRMSZYZvRc4obCPZGZm\nharWPQdJw4AlEfGPbXYVAYvzXpckZdsrLymn3MzMMrTDD8FJ2gP4ObkupVolaQS57qqy+erNzKzm\nVafl8FWgI/APSe8C7YAZkr4ILAHa59Vtl5Rtr7xdOeXliohREVEcEcVt2rSpRuhmZlYVO5wcIuL1\niNgvIjpERAdyXUF9IuIDYAJwVjJqaQDwcUQsBZ4EBktqmdyIHgw8mez7RNKAZJTSWcD4GvpsZmZW\nTVUZyno/8ArQWVKJpHO3U/1xYCGwAPhf4EKAiFgF/BqYlvz8V1JGUufO5Jh3gLoxuY2ZWQNW6T2H\niDi9kv0d8rYDuKiCeqOB0eWUTwe6VxaHmZnVHj8hbWZmKU4OZmaW4uRgZmYpTg5mZpbi5GBmZilO\nDmZmluLkYGZmKU4OZmaW4uRgZmYpTg5mZpbi5GBmZilODmZmluLkYGZmKU4OZmaW4uRgZmYpTg5m\nZpZSlZXgRktaJumNvLKbJL0pabakRyW1yNv3M0kLJL0l6ai88qOTsgWSrsgr7yhpalL+gKTda/ID\nmpnZjqtKy+Ee4Ohtyp4CukdET+Bt4GcAkroCpwHdkmNuk9RIUiNgJDAE6AqcntQFuBG4OSI6AauB\n7S1DamZmtaDS5BARzwOrtin7W0RsTF5OAdol28OAcRGxLiIWkVsX+pDkZ0FELIyI9cA4YJgkAYcD\nDyXHjwFOKPAzmZlZgWrinsP3gEnJdhGwOG9fSVJWUXkr4KO8RFNaXi5JIyRNlzR9+fLlNRC6mZmV\np6DkIOkXwEZgbM2Es30RMSoiiiOiuE2bNrXxlmZmDVLj6h4o6WzgOOCIiIikeAnQPq9au6SMCspX\nAi0kNU5aD/n1zcwsI9VqOUg6GrgMGBoRn+ftmgCcJqmppI7AgcCrwDTgwGRk0u7kblpPSJLKs8BJ\nyfHDgfHV+yhmZlZTqjKU9X7gFaCzpBJJ5wJ/BPYGnpI0S9IdABExB3gQmAs8AVwUEZuSVsEPgCeB\necCDSV2Ay4FLJS0gdw/irhr9hGZmtsMq7VaKiNPLKa7wF3hEXAdcV07548Dj5ZQvJDeayczM6gg/\nIW1mZilODmZmluLkYGZmKU4OZmaW4uRgZmYpTg5mZpbi5GBmZilODmZmluLkYGZmKU4OZmaW4uRg\nZmYpTg5mZpbi5GBmZilODmZmluLkYGZmKVVZ7Ge0pGWS3sgr21fSU5LmJ/9tmZRL0q2SFkiaLalP\n3jHDk/rzJQ3PK+8r6fXkmFslqaY/pJmZ7ZiqtBzuAY7epuwK4OmIOBB4OnkNMITc0qAHAiOA2yGX\nTICrgP7kFva5qjShJHXOyztu2/cyM7NaVmlyiIjngVXbFA8DxiTbY4AT8srvjZwpQAtJbYGjgKci\nYlVErAaeAo5O9n0hIqYk60nfm3cuMzPLSHXvOewfEUuT7Q+A/ZPtImBxXr2SpGx75SXllJdL0ghJ\n0yVNX758eTVDNzOzyhR8Qzr5iz9qIJaqvNeoiCiOiOI2bdrUxluamTVI1U0OHyZdQiT/XZaULwHa\n59Vrl5Rtr7xdOeVmZpah6iaHCUDpiKPhwPi88rOSUUsDgI+T7qcngcGSWiY3ogcDTyb7PpE0IBml\ndFbeuczMLCONK6sg6X5gINBaUgm5UUc3AA9KOhd4Dzglqf44cAywAPgcOAcgIlZJ+jUwLan3XxFR\nepP7QnIjopoDk5IfMzPLUKXJISJOr2DXEeXUDeCiCs4zGhhdTvl0oHtlcZiZWe3xE9JmZpbi5GBm\nZilODmZmluLkYGZmKU4OZmaW4uRgZmYpTg5mZpbi5GBmZilODmZmluLkYGZmKU4OZmaWUuncSnXW\nW2/BwIFZR2G7mFHz/pl1CDkDH8w6Amvg3HIwM7OU+tty6NwZnnsu6yhsFzOi/21ZhwDAjOcuzDoE\n21VJVarmloOZmaUUlBwkXSJpjqQ3JN0vqZmkjpKmSlog6QFJuyd1myavFyT7O+Sd52dJ+VuSjirs\nI5mZWaGqnRwkFQE/AoojojvQCDgNuBG4OSI6AauBc5NDzgVWJ+U3J/WQ1DU5rhtwNHCbpEbVjcvM\nzApXaLdSY6C5pMbAHsBS4HDgoWT/GOCEZHtY8ppk/xHJutHDgHERsS4iFpFbYvSQAuMyM7MCVDs5\nRMQS4LfA++SSwsfAa8BHEbExqVYCFCXbRcDi5NiNSf1W+eXlHLMVSSMkTZc0ffny5dUN3czMKlFI\nt1JLcn/1dwS+BOxJrltop4mIURFRHBHFbdq02ZlvZWbWoBXSrfTvwKKIWB4RG4BHgMOAFkk3E0A7\nYEmyvQRoD5Ds3wdYmV9ezjFmZpaBQpLD+8AASXsk9w6OAOYCzwInJXWGA+OT7QnJa5L9z0REJOWn\nJaOZOgIHAq8WEJeZmRWo2g/BRcRUSQ8BM4CNwExgFPBXYJyka5Oyu5JD7gLuk7QAWEVuhBIRMUfS\ng+QSy0bgoojYVN24zMyscAU9IR0RVwFXbVO8kHJGG0XEWuDkCs5zHXBdIbGYmVnN8RPSZmaW4uRg\nZmYpTg5mZpbi5GBmZilODmZmluLkYGZmKU4OZmaW4uRgZmYpTg5mZpbi5GBmZilODmZmluLkYGZm\nKU4OZmaW4uRgZmYpTg5mZpZSUHKQ1ELSQ5LelDRP0qGS9pX0lKT5yX9bJnUl6VZJCyTNltQn7zzD\nk/rzJQ2v+B3NzKw2FNpy+APwRER8DegFzAOuAJ6OiAOBp5PXAEPILQF6IDACuB1A0r7kFgzqT26R\noKtKE4qZmWWj2slB0j7AN0mWAY2I9RHxETAMGJNUGwOckGwPA+6NnClAC0ltgaOApyJiVUSsBp4C\njq5uXGZmVrhCWg4dgeXA3ZJmSrpT0p7A/hGxNKnzAbB/sl0ELM47viQpq6jczMwyUkhyaAz0AW6P\niIOBf7GlCwmAiAggCniPrUgaIWm6pOnLly+vqdOamdk2CkkOJUBJRExNXj9ELll8mHQXkfx3WbJ/\nCdA+7/h2SVlF5SkRMSoiiiOiuE2bNgWEbmZm21Pt5BARHwCLJXVOio4A5gITgNIRR8OB8cn2BOCs\nZNTSAODjpPvpSWCwpJbJjejBSZmZmWWkcYHH/xAYK2l3YCFwDrmE86Ckc4H3gFOSuo8DxwALgM+T\nukTEKkm/BqYl9f4rIlYVGJeZmRWgoOQQEbOA4nJ2HVFO3QAuquA8o4HRhcRiZmY1x09Im5lZipOD\nmZmlODmYmVmKk4OZmaU4OZiZWYqTg5mZpTg5mJlZipODmZmlODmYmVmKk4OZmaU4OZiZWYqTg5mZ\npTg5mJlZipODmZmlODmYmVmKk4OZmaUUnBwkNZI0U9LE5HVHSVMlLZD0QLJKHJKaJq8XJPs75J3j\nZ0n5W5KOKjQmMzMrTE20HC4G5uW9vhG4OSI6AauBc5Pyc4HVSfnNST0kdQVOA7oBRwO3SWpUA3GZ\nmVk1FZQcJLUDjgXuTF4LOBx4KKkyBjgh2R6WvCbZf0RSfxgwLiLWRcQicmtMH1JIXGZmVphCWw63\nAJcBm5PXrYCPImJj8roEKEq2i4DFAMn+j5P6ZeXlHLMVSSMkTZc0ffny5QWGbmZmFal2cpB0HLAs\nIl6rwXi2KyJGRURxRBS3adOmtt7WzKzBaVzAsYcBQyUdAzQDvgD8AWghqXHSOmgHLEnqLwHaAyWS\nGgP7ACvzykvlH2NmZhmodnKIiJ8BPwOQNBD4aUScKenPwEnAOGA4MD45ZELy+pVk/zMREZImAP8n\n6ffAl4ADgVerG5eZ1Yw1vzgm6xAAaH7d41mH0CAV0nKoyOXAOEnXAjOBu5Lyu4D7JC0AVpEboURE\nzJH0IDAX2AhcFBGbdkJcZmZWRTWSHCLiOeC5ZHsh5Yw2ioi1wMkVHH8dcF1NxGJmZoXzE9JmZpbi\n5GBmZilODmZmluLkYGZmKU4OZmaW4uRgZmYpTg5mZpbi5GBmZilODmZmluLkYGZmKU4OZmaW4uRg\nZmYpTg5mZpbi5GBmZilODmZmllLIGtLtJT0raa6kOZIuTsr3lfSUpPnJf1sm5ZJ0q6QFkmZL6pN3\nruFJ/fmShhf+sczMrBCFtBw2Aj+JiK7AAOAiSV2BK4CnI+JA4OnkNcAQckuAHgiMAG6HXDIBrgL6\nk1sk6KrShGJmZtmodnKIiKURMSPZ/hSYBxQBw4AxSbUxwAnJ9jDg3siZArSQ1BY4CngqIlZFxGrg\nKeDo6sZlZmaFq5F7DpI6AAcDU4H9I2JpsusDYP9kuwhYnHdYSVJWUXl57zNC0nRJ05cvX14ToZuZ\nWTkKTg6S9gIeBn4cEZ/k74uIAKLQ98g736iIKI6I4jZt2tTUac3MbBsFJQdJTcglhrER8UhS/GHS\nXUTy32VJ+RKgfd7h7ZKyisrNzCwjhYxWEnAXMC8ifp+3awJQOuJoODA+r/ysZNTSAODjpPvpSWCw\npJbJjejBSZmZmWWkcQHHHgb8f8DrkmYlZT8HbgAelHQu8B5wSrLvceAYYAHwOXAOQESskvRrYFpS\n778iYlUBcZmZWYGqnRwi4kVAFew+opz6AVxUwblGA6OrG4uZmdUsPyFtZmYpTg5mZpbi5GBmZilO\nDmZmluLkYGZmKU4OZmaW4uRgZmYpTg5mZpbi5GBmZilODmZmluLkYGZmKU4OZmaWUsisrGZmDcLE\nL3TOOgQAjvvkrVp7L7cczMwsxcnBzMxS6ky3kqSjgT8AjYA7I+KGjENqMB5pXjeazCeuqb0ms5lt\nX51oOUhqBIwEhgBdgdMldc02KjOzhqtOJAfgEGBBRCyMiPXAOGBYxjGZmTVYdaVbqQhYnPe6BOi/\nbSVJI4ARycvPJGXdD9EaWJFxDHVF4ddCFa06W+8UfC2kclfUrY8K/178P38vytTMv5GvVKVSXUkO\nVRIRo4BRWcdRStL0iCjOOo66wNdiC1+LLXwttqhv16KudCstAdrnvW6XlJmZWQbqSnKYBhwoqaOk\n3YHTgAkZx2Rm1mDViW6liNgo6QfAk+SGso6OiDkZh1UVdaaLqw7wtdjC12ILX4st6tW1UERkHYOZ\nmdUxdaVbyczM6hAnBzMzS3FyMDOzlDpxQ9rM6j9JJ1ah2tqIeHynB2MF8w3pKpI0uwrVlkfEETs9\nmIz5Wmwh6ZPKqgBLI+Kg2ognS5JWAuPJfeaKfDMivlpLIWVG0q1VqPZJRPxypwdTTW45VF0j4Jjt\n7BcN59kMX4st3omIg7dXQdLAIWHvAAANKklEQVTM2gomY5Mi4nvbqyDpT7UVTMaGAVdWUucKwMlh\nF3B+RLy3vQqSLqytYDLma7HFd2qoTr0XEd+tiTq7iJsjYsz2KkhqWVvBVIe7lQogqU9EzMg6jrpA\nUuuI8CSEDZikLwPLImKtJAFnA32AucD/RsTGLOOzHePRSlUkqc82P32BCZIOltQn6/hqk6QhkhZJ\nejH5/HOAqZJKJO3y9xnySWovaZykFyT9XFKTvH2PZRlbBh5ny++UG4BjgalAP+rZ08GFktRY0vmS\nnpA0O/mZJOmC/O9IXeaWQxVJ2gxMAdblFQ9IyiIiDs8ksAxImgWcDrQAJgLHRsQUSV2AsRHRYJKl\npKeAh8l9D84F+gLHR8RKSTMrux+xK5E0NyK6JtuvAf0iYnPy+h8R0SvTAGuRpPuBj4Ax5JYggNyE\nosOBfSPi1Kxiqyrfc6i6k4EfAb+JiEkAkhZFxKBsw8rE5oiYByDp84iYAhAR8yQ1tNZom4i4I9n+\noaTvAs9LGgo0tL+8Fks6PCKeAd4lN9Pye5JaZRtWJvqWM0KtBJgi6e0sAtpRDe0fcrVFxMPkmsmD\nJf056V9taP/4S32UNJn/E1gt6RJJRZKGA59lHVwtayKpWemLiPgTcDG5SSTbZhZVNv4D+JWk54Hd\ngVmSngX+DlyaaWS1b5Wkk/P/WJK0m6RTgdUZxlVl7laqBkkHA78HukXEflnHU9sktSc3BG8zcA25\nLqZzgfeAn5a2KhoCSZcAMyJi8jblB5NrZR6ZTWTZSboXDyLXM1ECTCvtXmooJHUAbgQOZ0syaAE8\nC1wREYuyiazqnByqKRmNsXdEVPYQlJk1YKXdahGxMutYdoS7laopcj4BkHRc1vHUFb4WW/habCGp\nQY1WyhcRK/MTg6QvZhlPVTk51Ix+WQdQh/habOFrscX/ZB1AHXJX1gFUhbuVzMwsxS2HHSDpEEn9\nku2uki6VtL05hhqEZO3vEyV9LetYapuk3SWdJenfk9dnSPqjpIvqy8NONUXSPpJukPSmpFWSVkqa\nl5S1yDq+2paMTtot2d49eXh236zjqionhyqSdBVwK3C7pOuBPwJ7AldI+kWmwdWy/Cd/JQ0DngGO\nB8ZLOjuruDJyN7khzhdLuo/c8zClTwXfmWVgGXiQ3MicgRGxb0S0AgYlZQ9mGlktk3QCsBRYkvwb\neQG4CZgt6fhMg6sidytVkaTXgd5AU+ADoF1EfCKpOTA1InpmGmAtyn/yV9LLwJkRsUhSa+DpBvYk\n7OyI6CmpMbAE+FJEbEpGs/2jgX0v3oqIzju6b1ek3Ey8Q4DmwD/IPS3+lqSvAA9HRHGmAVaBWw5V\ntzEiNkXE5+Smaf4EICLWkBvv35Dk/0XRuHTMdjLxXkO7FrtJ2h3YG9gD2Ccpbwo0qG4lck9DXyZp\n/9ICSftLuhxYnGFcmYiID5J/G+9HxFtJ2XvUk9+7nj6j6tZL2iNJDn1LCyXtQ8P7hdhLuUVuBDSV\n1DYilia/JBtlHFttuwt4k9zn/gXwZ0kLyc27NS7LwDJwKrk1CiZLKn049ENya3uckllUGZG0W/Lw\n3/fyyhqRe3q8znO3UhVJahoR68opbw20jYjXMwirTkluOnaJiFeyjqU2SfoSQET8M7kG/07ur8VX\ns43MspIMXHk9ItZuU94B+HoyzUqd5uRgZjudpHMi4u6s47Cqqxd9X2ZW712TdQB1haRJWcdQFb7n\nYGY1QtLsinYB+1ewb5ekihcAE7lRj3Wek4OZ1ZT9gaNIT0kt4OXaDydT04DJ5D77turFA4FODgWS\n9HdgAzAyIiZmHU+WJI0BPid3Ld7IOp4sNdDvxURgr4iYte0OSc/VfjiZmgecHxHzt90hqV4M6/UN\n6QIlI1XaAgMiYmTW8WQpGaHxZeCQiLg863iy5O9FwybpJHKjld4qZ98JEVHn1xd3cqiG0vlRImJV\n1rHUFZL2i4hlWcdRF0hqnTwQaFZvebRSFUn6sqRxkpaTmzvnVUnLkrIO2UZXuyTtu81PK3LXo2V9\nmlisJkgaImmRpBclHSxpDjBVUomkI7KOz6y63HKoIkmvALcAD0XEpqSsEbmJ1n4cEQOyjK82SdpM\nbknQfO3ILQkZEXFA7UeVDUmzyC2T2oJcn/uxETElWSpzbERUNGrFrE5zcqgiSfMj4sAd3bcrkvQT\n4EjgP0ufDJe0KCI6ZhtZ7ZM0ozQBSFocEe3z9s2KiHoxbNFsWx6tVHWvSboNGMOWScTaA8OBmZlF\nlYGI+J2kB4Cbk5EXV7H1ZHwNyUeSzge+AKyWdAm56an/Hfgs08jqiAY6cqtckoqBf0bEP7OOpTJu\nOVRRMqncucAwoCgpLgH+AtxV3rxLDYGkocDPgQ4RUS/Wxq1JktoDvyQ3+eI15LqYziXX7fbTiJiX\nYXh1gkdubZEM9+4JvB0Rp2Ydz/Y4OVjBkjUtvtrQn20wqypJe0fEp1nHsT0erVQDJB2XdQxZiog1\npYlhO9MGNDgN7Xsh6QuSrpd0n6Qzttl3W1ZxZSFZFlR5rwdJ+omkIQB1PTGAk0NN6Zd1AHXI97MO\noA5paN+Lu8lNF/EwcJqkhyU1TfY1mNF8iWkk02RI+k/gOnKrwl0q6YYsA6sqdyuZWY3YdnRWsrb6\nMcBQ4KmGNKxX0hsR0T3Zng58IyLWJMvJzqgPy8e65VADJB2ZdQy1TdIXJX0x2W4j6URJ3bKOK2uS\nOibX4mtZx5KBppLKfqdExHXA/wLPA60yiyobn0jqnmyvAJol242pJ79360WQ9cBdWQdQm5Khm68A\nUyR9n+ThL+ARSedmGlwtk/RY3vYw4BngeGC8pLOziisjfwEOzy+IiHuAnwDrswgoQxcAYyXdCywD\npku6G3gR+H+ZRlZF7laqIkkTKtoFHB4Re9ZmPFmS9DrQn1wf6ntAp4j4QFJL4NmG9OCXpJkRcXCy\n/TJwZkQsSpaPfToiemUboWUlmUFhMHAQuRZDCfBkRHyUaWBV5Ifgqu4bwHdJP9gk4JDaDydTGyLi\nc+BzSe9ExAcAEbFaUkP7ayP/8zaOiEUAEbEimWbEyI1ii4gZWcdRm5JpdiYlP/WOk0PVTQE+j4jJ\n2+6QlJqWdxcXkppExAZy3UkASGpGw+uq7CXpE3J/JDSV1DYiliYPTTbKOLa65PvAeVkHURdIujoi\nrs46jsq4W8l2mKQvk5sCYOM25UVAl4j4ezaR1R2SWpC7Fq9kHYvVLZKOj4i/ZB1HZZwcqkiSopKL\nVZU6uwJfiy18LbYm6ZvAhxHxlqTDgEOBeRHx14xDsx3U0LoACvGspB8mfzWXSZ6EPDyZM2V4RrHV\nNl+LLXwtEpJuAW4A7pP0a+AmcoMWLpF0U6bB1TJJjSWdL+kJSbOTn0mSLpDUJOv4qsIthypK+tO/\nB5wJdAQ+Ijd2uRHwN+C2iGgQs7P6Wmzha7GFcgsddSeXEJYARRHxefLLcGbpQ2ENgaT7yX0XxpAb\npQS5NU+GA/vW9Un3wMmhWpIve2tgTX0Zlraz+Fps0dCvRelTwUnCXAp8KXkquBG59ZS7ZhxirZH0\ndkQctKP76hKPVqqGZJTO0qzjqAt8LbbwteCvkl4g13K6E3hQ0hTgW+Sekm5IVkk6GXg4IjYDJE+P\nnwyszjSyKnLLwcxqjKRDyS0VO0XSV4FvA++TW163wTz3ody68jeSe2K8NBm0AJ4Frih9HqYuc3Iw\nsxrhkVvlk9QKICJWZh3LjvBoJTOrKR65VY6IWJmfGOrLRJ1uOZhZjahg5FZzcn+ENqiRW9sj6f2I\n+HLlNbPl5GBmNc4jt+r/RJ1ODmZmNUzSaiqeqPOBiNi/9qPaMR7KamZW8+r9RJ1uOZiZWYpHK5mZ\n1TBJqok6WXJyMDOrefV+WK+7lczMatiuMCGjk4OZ2U5UX4f1OjmYmVmK7zmYmVmKk4OZmaU4OZjV\nEknvSmqddRxmVeHkYFYASZ5lwHZJ/mKbbYekX5GbI2c5sBh4DTgOmAV8Hbhf0tvAL4HdgZXAmRHx\nYTKP//1AEfAKuXl1Ss/7XeBHyTFTgQsjYlNtfS6zyrjlYFYBSf2A7wC9gCFAcd7u3SOiOCJ+B7wI\nDIiIg4FxwGVJnauAFyOiG/Ao8OXkvF2AU4HDIqI3sInceHizOsMtB7OKHQaMj4i1wFpJf8nb90De\ndjvgAUltybUESpeA/CZwIkBE/DWZqRPgCKAvMC2ZQaE5sGynfQqzanByMKuef+Vt/zfw+4iYIGkg\ncHUlxwoYExE/20mxmRXM3UpmFXsJOF5SM0l7kbvXUJ59gCXJdv58Oc8DZwBIGgK0TMqfBk6StF+y\nb19JX6np4M0K4eRgVoGImAZMAGYDk4DXgY/LqXo18GdJrwEr8sqvAb4paQ657qX3k/POJXcD+2+S\nZgNPAW130scwqxZPn2G2HZL2iojPJO1BriUwIiJmZB2X2c7mew5m2zdKUldyM2qOcWKwhsItBzMz\nS/E9BzMzS3FyMDOzFCcHMzNLcXIwM7MUJwczM0v5/wHS94633AiGVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ims = xai.imbalance_plot(df, \"grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "id": "2rNgvGWfObEu",
    "outputId": "d652b17b-9cbd-463c-df21-c7cc98e125dd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAE6CAYAAAD9Sp7VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucVXW9//HXWy6iKYJASKBBgcod\nBQTzclBSQE3wFnDsgKZSidc6v8RfnrDUk6adTBONvEF5AEMT8icqiuYluQqJgAoqyhAqAmqGguDn\n98dezOxhzTDj7GHWwLyfj8c82Puzvmvtz/4C89nr+/3utRQRmJmZ5dsj6wTMzKz2cXEwM7MUFwcz\nM0txcTAzsxQXBzMzS3FxMDOzFBcHMzNLcXEwM7MUFwczM0upn3UCVdW8efNo27Zt1mmYme1SFixY\n8H5EtKio3S5bHNq2bcv8+fOzTsPMbJci6a3KtKtwWEnS3ZLek/TydvGLJb0iaYmkX+bFr5S0QtKr\nkgbkxQcmsRWSxuTF20mak8SnSGpYubdoZmY7S2XmHO4FBuYHJB0HDAa6R0Rn4KYk3gkYBnRO9hkn\nqZ6kesBtwCCgEzA8aQtwA/DriGgPbADOK/RNmZlZYSosDhHxDLB+u/APgOsjYlPS5r0kPhiYHBGb\nIuJNYAVwRPKzIiLeiIjNwGRgsCQBxwNTk/0nAEMKfE9mZlagqs45HAwcI+k64FPgPyNiHtAamJ3X\nriiJAazaLt4HaAZ8EBFbymifImkUMArgoIMOqmLqZmmfffYZRUVFfPrpp1mnYlYtGjVqRJs2bWjQ\noEGV9q9qcagP7A/0BXoD90v6WhWPVWkRMR4YD9CrVy/fiMKqTVFREfvuuy9t27Yld0JrtuuKCNat\nW0dRURHt2rWr0jGq+j2HIuDByJkLfA40B1YDB+a1a5PEyouvA5pIqr9d3KxGffrppzRr1syFwXYL\nkmjWrFlBZ8JVLQ4PAcclSRwMNATeB6YDwyTtKakd0AGYC8wDOiQrkxqSm7SeHrnb0D0FnJkcdyQw\nrapvxqwQLgy2Oyn033OFw0qSJgH9gOaSioCxwN3A3cny1s3AyOQX/RJJ9wNLgS3A6IjYmhznIuAx\noB5wd0QsSV7iCmCypGuBhcBdBb0jMzMrWGVWKw2PiFYR0SAi2kTEXRGxOSK+ExFdIuLwiJiV1/66\niPh6RBwSETPy4o9ExMHJtuvy4m9ExBER0T4iztq2AsosC0uXvZfJz99eeIVDD+3CoYd2oXnzL9O6\ndWt69OhBkyZN6NSpU8WJf0FPP/00p5xyyhfap1+/fmV+8fTee+/loosu2uG+Tz31FD169Cj+adSo\nEQ899BAAxxxzTHH8K1/5CkOG5BYsbtiwgdNOO41u3bpxxBFH8PLLua9arVq1iuOOO45OnTrRuXNn\nfvOb35T7Hvfbb7/iY//85z8v3vboo49yyCGH0L59e66//vpy877ssst45plnADjnnHNo165d8fEW\nLVoE5Mb3L7nkEtq3b0+3bt148cUXyzzWggUL6Nq1K+3bt+eSSy4h93ka1q9fzwknnECHDh044YQT\n2LBhAwAPPPAAnTt35phjjmHdunUAvP766wwdOrT4mJs3b+bYY49ly5Yt6RcskK+tZFYLNGmyPw/+\neRYP/nkWQ4eO5PLLL2fRokUsWrSIPfao+L/pzvjlUJ2OO+644vcza9Ys9t57b0488UQAnn322eJt\nRx55JKeffjoA//3f/02PHj146aWXmDhxIpdeeikA9evX51e/+hVLly5l9uzZ3HbbbSxdurTM1z3m\nmGOKj/3Tn/4UgK1btzJ69GhmzJjB0qVLmTRpUpn7r1u3jtmzZ3PssccWx2688cbi4/Xo0QOAGTNm\nsHz5cpYvX8748eP5wQ9+UGYuP/jBD/j9739f3PbRRx8F4Prrr6d///4sX76c/v37FxerW2+9lXnz\n5vG9732P//3f/wXgqquu4tprry0+ZsOGDenfvz9Tpkyp5N9E5e2yl88w21la/uIqGr2ypOKGX8Cn\nh3bm3SuvrbhhGbZu3coFF1zA3/72N1q3bs20adPYa6+96NevHz169OC5555j+PDhjBgxgu9///u8\n/fbbANx8880cddRR/PWvfy3+xSqp+JPwxx9/zJlnnsnLL79Mz549+eMf/4gknnzySf7zP/+TLVu2\n0Lt3b26//Xb23HPPUjndc889/OIXv6BJkyZ07949tX1Hpk6dyqBBg9h7771LxT/66CNmzZrFPffc\nA8DSpUsZMyZ3MYVDDz2UlStX8u6779KqVStatWoFwL777kvHjh1ZvXp1pc+w5s6dS/v27fna13IL\nLIcNG8a0adNS+z/wwAMMHDiwrEOUMm3aNEaMGIEk+vbtywcffMCaNWuKcwRYs2YNH330EX379gVg\nxIgRPPTQQwwaNIhp06bx9NNPAzBy5Ej69evHDTfcwB577MGmTZvYuHEjDRo04Nlnn+WAAw6gQ4cO\npV5/yJAhXHnllZx99tmVev+V5TMHs1pu+fLljB49miVLltCkSRMeeOCB4m2bN29m/vz5/OhHP+LS\nSy/l8ssvZ968eTzwwAOcf/75ANx0003cdtttLFq0iGeffZa99toLgIULF3LzzTezdOlS3njjDZ5/\n/nk+/fRTzjnnHKZMmcLixYvZsmULt99+e6l81qxZw9ixY3n++ed57rnnSn3qnj59evEn9PJMnjyZ\n4cOHp+IPPfQQ/fv3p3HjxgB0796dBx98EMj9Qn/rrbcoKioqtc/KlStZuHAhffr0KfO1XnjhBbp3\n786gQYNYsiRX8FevXs2BB5YsnmzTpg2rV6cXST7//PP07NmzVOwnP/kJ3bp14/LLL2fTpk2VPt7q\n1atp06ZNmW22FTyAAw44gHfffReAK6+8km9+85v85S9/Yfjw4VxzzTX813/9VyrPLl26MG/evDLf\nfyF85mC2nap+wt9Zto1zA/Ts2ZOVK1cWb8sff37iiSdK/aL+6KOP+PjjjznqqKP44Q9/yNlnn83p\np59e/EvqiCOOKH7co0cPVq5cyb777ku7du04+OCDgdwn2dtuu43LLrus+Lhz5syhX79+tGjRojiH\n1157DYBTTz2VU089tdz3smbNGhYvXsyAAQNS2yZNmlRc0ADGjBnDpZdeSo8ePejatSuHHXYY9erV\nK97+8ccfc8YZZ3DzzTcXF5R8hx9+OG+99Rb77LMPjzzyCEOGDGH58uXl5lZWrtveI8AvfvELDjjg\nADZv3syoUaO44YYbKiyEX5Sk4lVGJ5xwAieccAIAEydO5KSTTuK1117jpptuomnTpvzmN79h7733\npl69ejRs2JB//vOf7LvvvtWWi88czGq5/CGbevXqlZpf+NKXvlT8+PPPP2f27NnFY+KrV69mn332\nYcyYMdx555188sknHHXUUbzyyisVHndnuf/++znttNNS39p9//33mTt3LieffHJxrHHjxtxzzz0s\nWrSIiRMnsnbt2uKhoM8++4wzzjijuOCVpXHjxuyzzz4AnHTSSXz22We8//77tG7dmlWrSi7YUFRU\nROvW6Qsz7LXXXqW+J9CqVSskseeee3Luuecyd+5cgEodr3Xr1qXOevLbtGzZkjVr1gC5gvTlL3+5\n1L4bN27k3nvvZfTo0YwdO5YJEyZw9NFHc9999xW32bRpE40aNSqzH6rKxcFsN3HiiSdy6623Fj/f\ntprm9ddfp2vXrlxxxRX07t27uDiU5ZBDDmHlypWsWLECgD/84Q/827/9W6k2ffr04a9//Svr1q3j\ns88+409/+lOlc5w0aVKZQ0pTp07llFNOKfUL7oMPPmDz5s0A3HnnnRx77LE0btyYiOC8886jY8eO\n/PCHPyz3td55553iFUFz587l888/p1mzZvTu3Zvly5fz5ptvsnnzZiZPnlzm2U7Hjh2L+wEo/gUe\nETz00EN06dIFyJ0tTZw4kYhg9uzZ7LfffqXmGyBXWBo3bszs2bOJCCZOnMjgwYOL958wYQIAEyZM\nKI5vc+ONN3LJJZfQoEEDPvnkEySxxx57sHHjRiA3cd68efMqXyajPC4OZruJW265hfnz59OtWzc6\nderEHXfcAeQmprt06UK3bt1o0KABgwYNKvcYjRo14p577uGss86ia9eu7LHHHnz/+98v1aZVq1Zc\nffXVHHnkkRx11FF07NixeNuO5hxWrlzJqlWrUsUGyp6HWLZsGV26dOGQQw5hxowZxUtWn3/+ef7w\nhz8wa9as4mWljzzyCAB33HFH8fueOnUqXbp0oXv37lxyySVMnjwZSdSvX5/f/va3DBgwgI4dO/Lt\nb3+bzp07p3I6+eSTiyeKAc4++2y6du1K165def/997nqqquA3FnJ1772Ndq3b88FF1zAuHHjivfZ\nNhwIMG7cOM4//3zat2/P17/+9eK/hzFjxjBz5kw6dOjAE088UTwJD/CPf/yDuXPnFi/vvfjii+nd\nuzd33HEH//7v/w7klgnnn3FVF22rrLuaXr16hW/2Y9Vl2bJldOzYkaXL3qu4cQ3o1PHLFTeyne7o\no4/m4YcfpkmTJlmnUq7TTz+d66+/vnieKN+2f9f5JC2IiF4VHdcT0mZWJhdK+NWvfsXbb79da4vD\n5s2bGTJkSJmFoVAuDmZm5ShviWxt0bBhQ0aMGLFTju05BzMzS3FxMDOzFBcHMzNLcXEwM7MUT0ib\nleE750yt1uP98d4zK25Ujdq2bcv8+fNp3rx5jb6u7T585mC2i6jtl+W23YvPHMxqidtv/x8e/stU\nmu7fjEMO/ho9e/bk4YcfLnVZ7oMPPphrr72WzZs306xZM+677z5atmzJunXrGD58OKtXr+bII48k\n/8utf/zjH7nlllvYvHkzffr0Ydy4caUuYGdWlgrPHCTdLem95Jag22/7kaSQ1Dx5Lkm3SFoh6SVJ\nh+e1HSlpefIzMi/eU9LiZJ9b5Bv5Wh20ePFCZj7+MA/+eRa/+92kUndcy78s99FHH83s2bNZuHAh\nw4YN45e//CUAP/vZzzj66KNZsmQJp512WvE9HZYtW8aUKVN4/vnnWbRoEfXq1St1wTaz8lTmzOFe\n4LfAxPygpAOBE4G388KDgA7JTx/gdqCPpP3J3Xu6FxDAAknTI2JD0uYCYA7wCDAQmIFZHbJw4VyO\nP34ge+7ZiD33hG9961vF2/Ivy11UVMTQoUNZs2YNmzdvpl27dgA888wzxfc+OPnkk2natCkATz75\nJAsWLKB3794AfPLJJ6mrfpqVpTL3kH4GWF/Gpl8DPyb3y36bwcDEyJkNNJHUChgAzIyI9UlBmAkM\nTLY1jojZkTsPnggMKewtme1e8i/LffHFF3PRRRexePFifve735W6pHRZIoKRI0cWX8b71Vdf5eqr\nr97JGdvuoEoT0pIGA6sj4u/bbWoNrMp7XpTEdhQvKiNe3uuOkjRf0vy1a9dWJXWzWumww47g6acf\nZ9OmT/nXv/7Fww8/XGa7Dz/8sPg+ANsu8wxw7LHHFt9neMaMGcU3qe/fvz9Tp07lvfdy10lav349\nb7311s58K7ab+MIT0pL2Bv4vuSGlGhUR44HxkLsqa02/vtUdNb30tGvXwzjuuAGcNuQ4mjVrQdeu\nXdlvv/1S7a6++mrOOussmjZtyvHHH8+bb74JwNixYxk+fDidO3fmG9/4BgcddBAAnTp14tprr+XE\nE0/k888/p0GDBtx222189atfrdH3Z7ueqqxW+jrQDvh7MnfcBnhR0hHAauDAvLZtkthqoN928aeT\neJsy2pvVOeeceyGjL/o/fPLJRr436kx69uzJBRdcUKrN4MGDUzeDAWjWrBmPP/54mccdOnRoqXkL\ns8r4wsUhIhYDxTNaklYCvSLifUnTgYskTSY3If1hRKyR9Bjw35KaJrudCFwZEeslfSSpL7kJ6RHA\nrZjVQVdf/SNeX/Eamzdv4oILvsvhhx9e8U5mO0mFxUHSJHKf+ptLKgLGRsRd5TR/BDgJWAFsBM4F\nSIrANcC8pN3PI2LbJPeF5FZE7UVulZJXKlmddOONdxQ/9s1+LGsVFoeISN/wtfT2tnmPAxhdTru7\ngbvLiM8HulSUR3U7vM+4ihvVgBfnXJh1CpbYVe+KaFaWQv89+/IZZuTunbxu3ToXCNstRATr1q2j\nUaNGVT6GL59hBrRp04aioiLeWfMeteFL+mJd1inwzpp/Zp0CUDv6YlfUqFEj2rRpU3HDcrg4mAEN\nGjSgXbt2nDGsdkx51YbhxrPP8dBrXeZhJTMzS3FxMDOzFBcHMzNLcXEwM7MUFwczM0txcTAzsxQX\nBzMzS3FxMDOzFBcHMzNLcXEwM7MUFwczM0txcTAzsxQXBzMzS3FxMDOzFBcHMzNLqbA4SLpb0nuS\nXs6L3SjpFUkvSfqzpCZ5266UtELSq5IG5MUHJrEVksbkxdtJmpPEp0hqWJ1v0MzMvrjKnDncCwzc\nLjYT6BIR3YDXgCsBJHUChgGdk33GSaonqR5wGzAI6AQMT9oC3AD8OiLaAxuA8wp6R2ZmVrAKi0NE\nPAOs3y72eERsSZ7OBrbdi24wMDkiNkXEm8AK4IjkZ0VEvBERm4HJwGDl7sd4PDA12X8CMKTA92Rm\nZgWqjjmH7wLb7q3YGliVt60oiZUXbwZ8kFdotsXLJGmUpPmS5q9du7YaUjczs7IUVBwk/QTYAtxX\nPensWESMj4heEdGrRYsWNfGSZmZ1Uv2q7ijpHOAUoH9ERBJeDRyY16xNEqOc+DqgiaT6ydlDfnsz\nM8tIlc4cJA0EfgycGhEb8zZNB4ZJ2lNSO6ADMBeYB3RIViY1JDdpPT0pKk8BZyb7jwSmVe2tmJlZ\ndanMUtZJwAvAIZKKJJ0H/BbYF5gpaZGkOwAiYglwP7AUeBQYHRFbk7OCi4DHgGXA/UlbgCuAH0pa\nQW4O4q5qfYdmZvaFVTisFBHDywiX+ws8Iq4Drisj/gjwSBnxN8itZjIzs1rC35A2M7MUFwczM0tx\ncTAzsxQXBzMzS3FxMDOzFBcHMzNLcXEwM7OUKl8+w3Yfh/cZl3UKALw458KsUzCzhM8czMwsxcXB\nzMxSXBzMzCzFxcHMzFJcHMzMLMXFwczMUlwczMwsxcXBzMxSXBzMzCylMrcJvVvSe5JezovtL2mm\npOXJn02TuCTdImmFpJckHZ63z8ik/XJJI/PiPSUtTva5RZKq+02amdkXU5kzh3uBgdvFxgBPRkQH\n4MnkOcAgoEPyMwq4HXLFBBgL9CF3S9Cx2wpK0uaCvP22fy0zM6thFRaHiHgGWL9deDAwIXk8ARiS\nF58YObOBJpJaAQOAmRGxPiI2ADOBgcm2xhExOyICmJh3LDMzy0hV5xxaRsSa5PE7QMvkcWtgVV67\noiS2o3hRGXEzM8tQwRPSySf+qIZcKiRplKT5kuavXbu2Jl7SzKxOqmpxeDcZEiL5870kvho4MK9d\nmyS2o3ibMuJliojxEdErInq1aNGiiqmbmVlFqlocpgPbVhyNBKblxUckq5b6Ah8mw0+PASdKappM\nRJ8IPJZs+0hS32SV0oi8Y5mZWUYqvNmPpElAP6C5pCJyq46uB+6XdB7wFvDtpPkjwEnACmAjcC5A\nRKyXdA0wL2n384jYNsl9IbkVUXsBM5IfMzPLUIXFISKGl7OpfxltAxhdznHuBu4uIz4f6FJRHmZm\nVnP8DWkzM0txcTAzsxQXBzMzS3FxMDOzFBcHMzNLcXEwM7MUFwczM0txcTAzsxQXBzMzS3FxMDOz\nFBcHMzNLcXEwM7MUFwczM0txcTAzsxQXBzMzS3FxMDOzFBcHMzNLcXEwM7OUgoqDpMslLZH0sqRJ\nkhpJaidpjqQVkqZIapi03TN5viLZ3jbvOFcm8VclDSjsLZmZWaGqXBwktQYuAXpFRBegHjAMuAH4\ndUS0BzYA5yW7nAdsSOK/TtohqVOyX2dgIDBOUr2q5mVmZoUrdFipPrCXpPrA3sAa4HhgarJ9AjAk\neTw4eU6yvb8kJfHJEbEpIt4EVgBHFJiXmZkVoMrFISJWAzcBb5MrCh8CC4APImJL0qwIaJ08bg2s\nSvbdkrRvlh8vY59SJI2SNF/S/LVr11Y1dTMzq0Ahw0pNyX3qbwd8BfgSuWGhnSYixkdEr4jo1aJF\ni535UmZmdVr9Avb9JvBmRKwFkPQgcBTQRFL95OygDbA6ab8aOBAoSoah9gPW5cW3yd+nfK++Cv36\nVTn58cv+UeV9q1W/+7POwH2Rx31Rwn1RtxUy5/A20FfS3sncQX9gKfAUcGbSZiQwLXk8PXlOsn1W\nREQSH5asZmoHdADmFpCXmZkVSLnfz1XcWfoZMBTYAiwEzic3XzAZ2D+JfSciNklqBPwBOAxYDwyL\niDeS4/wE+G5ynMsiYkZFr92rV6+YP39+lXM/vM+4Ku9bnV6cc2HWKbgv8rgvSrgvdk+SFkREr4ra\nFTKsRESMBcZuF36DMlYbRcSnwFnlHOc64LpCcjEzs+rjb0ibmVmKi4OZmaW4OJiZWYqLg5mZpbg4\nmJlZiouDmZmluDiYmVmKi4OZmaW4OJiZWYqLg5mZpbg4mJlZiouDmZmluDiYmVmKi4OZmaW4OJiZ\nWYqLg5mZpbg4mJlZSkHFQVITSVMlvSJpmaQjJe0vaaak5cmfTZO2knSLpBWSXpJ0eN5xRibtl0sa\nWf4rmplZTSj0zOE3wKMRcSjQHVgGjAGejIgOwJPJc4BBQIfkZxRwO4Ck/cndarQPuduLjt1WUMzM\nLBtVLg6S9gOOBe4CiIjNEfEBMBiYkDSbAAxJHg8GJkbObKCJpFbAAGBmRKyPiA3ATGBgVfMyM7PC\nFXLm0A5YC9wjaaGkOyV9CWgZEWuSNu8ALZPHrYFVefsXJbHy4mZmlpFCikN94HDg9og4DPgXJUNI\nAEREAFHAa5QiaZSk+ZLmr127troOa2Zm2ymkOBQBRRExJ3k+lVyxeDcZLiL5871k+2rgwLz92ySx\n8uIpETE+InpFRK8WLVoUkLqZme1IlYtDRLwDrJJ0SBLqDywFpgPbVhyNBKYlj6cDI5JVS32BD5Ph\np8eAEyU1TSaiT0xiZmaWkfoF7n8xcJ+khsAbwLnkCs79ks4D3gK+nbR9BDgJWAFsTNoSEeslXQPM\nS9r9PCLWF5iXmZkVoKDiEBGLgF5lbOpfRtsARpdznLuBuwvJxczMqo+/IW1mZikuDmZmluLiYGZm\nKS4OZmaW4uJgZmYpLg5mZpbi4mBmZikuDmZmluLiYGZmKS4OZmaW4uJgZmYpLg5mZpbi4mBmZiku\nDmZmluLiYGZmKS4OZmaW4uJgZmYpLg5mZpZScHGQVE/SQkkPJ8/bSZojaYWkKcn9pZG0Z/J8RbK9\nbd4xrkzir0oaUGhOZmZWmOo4c7gUWJb3/Abg1xHRHtgAnJfEzwM2JPFfJ+2Q1AkYBnQGBgLjJNWr\nhrzMzKyKCioOktoAJwN3Js8FHA9MTZpMAIYkjwcnz0m290/aDwYmR8SmiHgTWAEcUUheZmZWmELP\nHG4Gfgx8njxvBnwQEVuS50VA6+Rxa2AVQLL9w6R9cbyMfUqRNErSfEnz165dW2DqZmZWnioXB0mn\nAO9FxIJqzGeHImJ8RPSKiF4tWrSoqZc1M6tz6hew71HAqZJOAhoBjYHfAE0k1U/ODtoAq5P2q4ED\ngSJJ9YH9gHV58W3y9zEzswxU+cwhIq6MiDYR0ZbchPKsiDgbeAo4M2k2EpiWPJ6ePCfZPisiIokP\nS1YztQM6AHOrmpeZmRWukDOH8lwBTJZ0LbAQuCuJ3wX8QdIKYD25gkJELJF0P7AU2AKMjoitOyEv\nMzOrpGopDhHxNPB08vgNylhtFBGfAmeVs/91wHXVkYuZmRXO35A2M7MUFwczM0txcTAzsxQXBzMz\nS3FxMDOzFBcHMzNLcXEwM7MUFwczM0txcTAzs5SdcfkMM7Pdygfn98s6BQCa3Pl0jb2WzxzMzCzF\nxcHMzFJcHMzMLMXFwczMUlwczMwsxcXBzMxSXBzMzCzFxcHMzFKqXBwkHSjpKUlLJS2RdGkS31/S\nTEnLkz+bJnFJukXSCkkvSTo871gjk/bLJY0s/G2ZmVkhCjlz2AL8KCI6AX2B0ZI6AWOAJyOiA/Bk\n8hxgENAh+RkF3A65YgKMBfqQu/f02G0FxczMslHl4hARayLixeTxP4FlQGtgMDAhaTYBGJI8HgxM\njJzZQBNJrYABwMyIWB8RG4CZwMCq5mVmZoWrljkHSW2Bw4A5QMuIWJNsegdomTxuDazK260oiZUX\nL+t1RkmaL2n+2rVrqyN1MzMrQ8HFQdI+wAPAZRHxUf62iAggCn2NvOONj4heEdGrRYsW1XVYMzPb\nTkHFQVIDcoXhvoh4MAm/mwwXkfz5XhJfDRyYt3ubJFZe3MzMMlLIaiUBdwHLIuJ/8jZNB7atOBoJ\nTMuLj0hWLfUFPkyGnx4DTpTUNJmIPjGJmZlZRgq5n8NRwH8AiyUtSmL/F7geuF/SecBbwLeTbY8A\nJwErgI3AuQARsV7SNcC8pN3PI2J9AXmZmVmBqlwcIuI5QOVs7l9G+wBGl3Osu4G7q5qLmZlVL39D\n2szMUlwczMwsxcXBzMxSXBzMzCzFxcHMzFJcHMzMLMXFwczMUlwczMwsxcXBzMxSXBzMzCzFxcHM\nzFJcHMzMLMXFwczMUlwczMwsxcXBzMxSXBzMzCzFxcHMzFJqTXGQNFDSq5JWSBqTdT5mZnVZrSgO\nkuoBtwGDgE7AcEmdss3KzKzuqhXFATgCWBERb0TEZmAyMDjjnMzM6ixFRNY5IOlMYGBEnJ88/w+g\nT0RctF27UcCo5OkhwKs1mmhac+D9jHOoLdwXJdwXJdwXJWpLX3w1IlpU1Kh+TWRSXSJiPDA+6zy2\nkTQ/InplnUdt4L4o4b4o4b4osav1RW0ZVloNHJj3vE0SMzOzDNSW4jAP6CCpnaSGwDBgesY5mZnV\nWbViWCkitki6CHgMqAfcHRFLMk6rMmrNEFct4L4o4b4o4b4osUv1Ra2YkDYzs9qltgwrmZlZLeLi\nYGZmKS4OZmaWUismpM1s1yfp9Eo0+zQiHtnpyVjBPCFdSZJeqkSztRHRf6cnkzFJH1XUBFgTEQfX\nRD5Zcl+UkLQOmEbuPZfn2IgAQuTOAAAL8UlEQVT4eg2llBlJt1Si2UcRcdVOT6aKfOZQefWAk3aw\nXdSd72a8HhGH7aiBpIU1lUzG3BclZkTEd3fUQNIfayqZjA0GflpBmzGAi8Nu4HsR8daOGki6sKaS\nydgZ1dRmd+C+SETEd6qjzW7i1xExYUcNJDWtqWSqwsNKVSBpf4CIWJ91LlmS1BJonTxdHRHvZplP\nltwXOZIOJfepubgvgOkRsSy7rKwqXBwqSdJBwC+B/sAH5IaRGgOzgDERsTK77GqWpB7AHcB+lFwD\nqw25frkwIl7MKrea5r4oIekKYDi5S+4XJeE25C6HMzkirs8qt5omqT5wHnAa8JUkvJrcnMxdEfFZ\nVrlVlotDJUl6AbgZmBoRW5NYPeAs4LKI6JtlfjVJ0iJyw2xztov3BX4XEd2zyazmuS9KSHoN6Lz9\nL77kemlLIqJDNpnVPEmTyH1AmEDpQjkS2D8ihmaVW2V5zqHymkfElPxAUiQmS7omo5yy8qXtfxkC\nRMRsSV/KIqEMuS9KfE7uU/L2c3Otkm11Sc8yVqgVAbOTIlrruThU3gJJ48h9EliVxA4k90mgrqxG\n2WaGpP8HTKR0X4wAHs0sq2y4L0pcBjwpaTklfXEQ0B64qNy9dk/rJZ0FPBARnwNI2oPcSMOGTDOr\nJA8rVVJyanwepSfbioC/kBtD3JRVblmQNIiyJx7r3Bec3Bclkl+AR1C6L+ZtG4qtKyS1BW4Ajqek\nGDQBniI3R/lmNplVnouDmdlOJKkZQESsyzqXL8LXVqoGkk7JOofaIrnPt+G+yCfp4axzyEpErMsv\nDJIOyDKfynJxqB69s06gFtnRpRPqGvdFiQuyTqAWuSvrBCrDw0pmZpbi1UpVJKkdcBiwNCJeyTqf\nmiTpEuDPEbGqwsZ1gKSvAaeTW6W0FXgN+N+IqOiifHWGpBkRMSjrPGpSMjlPRHyeLGjpAqzcVa6s\n4GGlSpL0UN7jweS+Gf0tYJqkc7LKKyPXAHMkPSvpQkktsk4oK0mhvANoRG54cU9yRWK2pH4Zplbj\nJB1ezk9PoEfW+dUkSUOANcDq5PfFs8CNwEuSvpVpcpXkYaVKkrRw29U3Jf0NODsi3pTUHHiyjn0T\ndiHQE/gmMBQ4FVgATAIejIh/ZphejZK0GOgREVsl7Q08EhH9ksutTKvoiq27E0lbgb9S9lxL34jY\nq4ZTykzyf2QQsBfwd6B3RLwq6avkvvvQK9MEK8HDSpWXX0Xrb1unHBHvS6pr3/6M5Is9jwOPS2pA\n7j/CcOAmoK6dSdQnN5y0J7APQES8nfRLXbKM3KVElm+/QVKdG4KMiHcAJL0dEa8msbe2DTfVdi4O\nldc9ubGLgD0ltYqINclYYr2Mc6tppT4ZJtfSmQ5MTz491yV3AvMkzQGOIffFJ5Khtl1ibLkaXU35\nQ9UX12AetYKkPZIPUd/Ni9UDGmaXVeV5WKlAkpoAHSPihaxzqSmSDo6IXeL6MDVBUmegI/ByXVuc\nYGWT1BtYHBGfbhdvCxwdEbX+pkcuDma200k6NyLuyToPq7xdYuzLzHZ5P8s6gdpC0oysc6gMzzmY\nWbWQ9FJ5m4CWNZlL1iQdXt4mdpFlvS4OZlZdWgIDSF+SWsDfaj6dTM2j/GW9TWo4lypxcSiQpAnA\nRuC2iHg563yyJOkJ4DNyfVFnL7QGdbYvHgb2iYhF22+Q9HTNp5OpXX5ZryekC5SsSjgIOCIirsg6\nnyxJ+gq5u371jYjbss4nS+6Luk3SmeRWK71axrYhEfFQGbvVKi4OVhBJ+wPsKteL2ZncF7Y78Wql\nSpK0n6TrJb0iab2kdZKWJbFdYgyxukg6SNJkSWuBOcBcSe8lsbbZZlez3Be2u3JxqLz7yU209YuI\n/SOiGXBcErs/08xq3hTgz8ABEdEhItqTG0J5CJicaWY1z31huyUPK1WSpFcj4pAvum13JGl5RHT4\nott2R+4L2135zKHy3pL0Y0nF67UltZR0BbBLrD6oRgskjZPUR9JXkp8+ksYBC7NOroa5Lyog6QlJ\nM3w7XZDUK1msUOv5zKGSJDUFxgCDgS8n4XfJXXDuhro0CZlcbPA8cn3ROgkXAX8B7oqITVnlVtPc\nFxXzyq0SydL3bsBrETE063x2xMXBzKqdV27tmKR9a/t9TzysVA128FX5OsdDByXqWl945VZpyQrH\noZJ+mPwM3baysbYXBnBxqC4/yDqBWqR31gnUInWtL7xyKyFpBPAi0A/YO/k5jtwc1YgMU6s0DyuZ\nWbXwyq0Skl4F+kTEB9vFmwJzIuLgbDKrPJ85fAGSDpB0QPK4haTTkxu91GmS2iV9cWjWudQ0SadK\napR1HrWEV26VEKVvLbzN55R9Mb5ax2cOlSTpe+RWK4ncrSDPAV4GjgZ+GRF3ZZddzZL0UEQMSR4P\nBm4Gnga+AfwiIu7NLruaJekT4F/ADGAS8FhEbM02q2x45VYJSSOBn5K7z/q2pe4HAScA1+wK/0dc\nHCpJ0mKgD7AX8BbQPiLeSU4Tn4qIXeIa7dVB0sKIOCx5/Dfg7Ih4U1Jz4MmI6J5thjVH0kLgeOBM\nYBjQhdy4+6SI+GuWuVm2kt8NAygplKvJfXjY/pLmtZIv2V15n0XERmCjpNcj4h2AiNggqa5V2Pz3\nWz8i3gSIiPclfZ5RTlmJ5D/774HfJ8OO3waul9QmIg7MNr3aQdIpdejS5UDudwO78ES85xwqLyQ1\nSB6fvC2YjDfXtX7sLukjSf8EekhqBcXDCvWyTa3GlRo/joh3IuKWiDiS3JCj5dS1lVvlkjQ+6xwq\nw8NKlSTpIOAfEbFlu3hroGNEPJFNZrVHsoa7Y0S8kHUuNUVSv4h4Ous8bNchqWdELMg6j4q4OFSS\nJEUFnVWZNrsD90UJ90VpkvYBBgIHAluB14DHI6KuDTfu8uracEghnpJ0cXIGUUxSQ0nHJ9dMGZlR\nbjXNfVHCfZGQ9G1gFrnicBG5oaT/ABZJ6pZlbrWJh5V2M8ncwneBs4F2wAdAI3Jj7I8D4yKiTqzl\ndl+UcF+UkPQSuYvrbUxWrt0XEQOSwnBHRHwj4xRrzLZrS5W1Cfh7RLSpyXyqwsWhCpKJ6ebAJ9t/\nA7KucV+UqOt9kSz37hYRIWkv4G95S55fjogu2WZYcyRtJbfkPX/BQiTPW0dEw0wS+wK8lLUKIuIz\nYE3WedQG7osS7gseAR6V9Ay5oaU/QfGn6F3iW8HV6A2gf0S8vf0GSbvE/V985mBm1UbSSUAnckMn\nM5PYHkCDOvYN6dHAcxHx9zK2XRwRt2aQ1hfi4mBm1cIrt3YvXq1kZtXFK7cqQdIJWedQGT5zMLNq\n4ZVblSPp7Yg4qOKW2XJxMLNq55Vbml7eJuD4iPhSTeZTFS4OZmbVTNIG4DvAx9tvAqZERMuaz+qL\n8VJWM7PqNxvYWNZl25O7xNV6PnMwM7MUr1YyM6tmkir80l9l2mTJxcHMrPrt8st6PaxkZlbNdodl\nvS4OZmY70a66rNfFwczMUjznYGZmKS4OZmaW4uJgVkMkrUzukGZW67k4mBVAkq8yYLsl/8M22wFJ\n/0XuGjlrgVXAAuAUYBFwNDBJ0mvAVUBDYB1wdkS8K6kZMAloDbxA3t3QJH0HuCTZZw5wYURsran3\nZVYRnzmYlUNSb+AMoDswCOiVt7lhRPSKiF8BzwF9k/slTwZ+nLQZS+5uYJ2BPwMHJcftCAwFjoqI\nHsBWcuvhzWoNnzmYle8oYFpEfAp8Kukvedum5D1uA0yR1IrcmcCbSfxY4HSAiPh/yZU6AfoDPYF5\nyRUU9gLe22nvwqwKXBzMquZfeY9vBf4nIqZL6gdcXcG+AiZExJU7KTezgnlYyax8zwPfktRI0j7k\n5hrKsh+wOnmcf72cZ4B/B5A0CGiaxJ8EzpT05WTb/pK+Wt3JmxXCxcGsHBExD5gOvATMABYDH5bR\n9GrgT5IWAO/nxX8GHCtpCbnhpbeT4y4lN4H9uKSXgJlAq530NsyqxJfPMNsBSftExMeS9iZ3JjAq\nIl7MOi+znc1zDmY7Nl5SJ3JX1JzgwmB1hc8czMwsxXMOZmaW4uJgZmYpLg5mZpbi4mBmZikuDmZm\nlvL/AZqxpOZ3Kt+VAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bal_df = xai.balance(df, \"grade\", upsample=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Vfzzl41ObEw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "include_colab_link": true,
   "name": "Data Science - Machine Learning - Deep Learning - AI - Algorithms.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
